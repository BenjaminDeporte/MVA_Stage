{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80222970",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "A neural ODE toy model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timeit\n",
    "from torch.distributions import Normal, Independent, kl_divergence, MultivariateNormal\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acec511",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16339feb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "Data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461bedb9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 16px; color: black; font-weight: bold;\">\n",
    "Ground truth\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e327e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiralFlow(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines the gradient flow of the 2D Spiral as a nn.Module to be used in odeint_adjoint from torchdiffeq\n",
    "    Inputs:\n",
    "        - t (scalar tensor): time. Here, the flow is time-invariant, so t is not used. However it is required by the ODE solver.\n",
    "        - x (tensor of shape (2,)): current position in the 2D plane.\n",
    "        - mu (float): parameter of the spiral.\n",
    "    Outputs:\n",
    "        - x_dot (tensor of shape (2,)): time derivative of the position.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu=0.01):\n",
    "        super(SpiralFlow, self).__init__()\n",
    "        self.mu = mu\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        x1, x2 = x[0], x[1]\n",
    "        r  = x1**2 + x2**2\n",
    "        x1_dot = self.mu * x1 - x2 - x1 * r\n",
    "        x2_dot = x1 + self.mu * x2 - x2 * r\n",
    "        return torch.stack([x1_dot, x2_dot])\n",
    "    \n",
    "spiral_flow = SpiralFlow().to(device)\n",
    "\n",
    "x = torch.tensor([2., 0.], device=device, requires_grad=True)\n",
    "t = torch.tensor([10.], device=device)\n",
    "dx = spiral_flow(t, x)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4708e2",
   "metadata": {},
   "source": [
    "Trajectory parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0289610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point\n",
    "x0 = torch.tensor([2.0, 0.0], dtype=torch.float, requires_grad=True).to(device)\n",
    "\n",
    "# number of points in the trajectory\n",
    "n_steps = 100\n",
    "\n",
    "# time span\n",
    "# t_0 = 0.0  # time of the latent prior z0\n",
    "t_start = 0.0\n",
    "t_end = 20.0\n",
    "ts = torch.linspace(t_start, t_end, n_steps).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the trajectory\n",
    "gt_trajectory = odeint_adjoint(spiral_flow, x0, ts, rtol=1e-2, atol=1e-2, method='rk4')\n",
    "\n",
    "# compute gradients along the trajectory\n",
    "gradients = []\n",
    "x = x0.detach().to(device)\n",
    "\n",
    "for t,x in zip(ts, gt_trajectory):\n",
    "    gradients.append(spiral_flow(t,x).detach().cpu().numpy())\n",
    "    \n",
    "gt_gradients = torch.tensor(np.array(gradients)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory_2D(ts, trajectory, gradients, sampled_ts=None, sampled_trajectory=None, sampled_gradients=None, interval=5, scale=5.0, title=\"2D Trajectory\"):\n",
    "    \"\"\"\n",
    "    Plot the trajectory and the vector field.\n",
    "    Inputs:\n",
    "        ground truth:\n",
    "        - ts (tensor of shape (n_steps,)): time points.\n",
    "        - trajectory (tensor of shape (n_steps, 2)): trajectory points.\n",
    "        - gradients (tensor of shape (n_steps, 2)): gradients at each trajectory point.\n",
    "        sampled points (optional):\n",
    "        - sampled_ts (tensor of shape (n_sampled,)): sampled time points.\n",
    "        - sampled_trajectory (tensor of shape (n_sampled, 2)): sampled trajectory points.\n",
    "        - sampled_gradients (tensor of shape (n_sampled, 2)): gradients\n",
    "        visualization parameters:\n",
    "        - interval (int): interval for quiver plot.\n",
    "        - scale (float): scale for quiver plot.\n",
    "        - title (str): title of the plot.\n",
    "    Outputs:\n",
    "        - fig, ax: matplotlib figure and axis.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "    X,Y = trajectory[:,0].detach().cpu().numpy(), trajectory[:,1].detach().cpu().numpy()\n",
    "    U,V = gradients[:,0].detach().cpu().numpy(), gradients[:,1].detach().cpu().numpy()\n",
    "\n",
    "    if sampled_trajectory is not None and sampled_gradients is not None:\n",
    "        X_s, Y_s = sampled_trajectory[:,0].detach().cpu().numpy(), sampled_trajectory[:,1].detach().cpu().numpy()\n",
    "        U_s, V_s = sampled_gradients[:,0].detach().cpu().numpy(), sampled_gradients[:,1].detach().cpu().numpy()\n",
    "        s = [50.0] * len(X_s)  # Set a fixed size for all points\n",
    "        ax.scatter(X_s, Y_s, color='b', marker='x', s=s, label='Sampled Trajectory')\n",
    "        ax.quiver(X_s, Y_s, U_s, V_s, angles='xy', scale_units='xy', scale=scale, color='b', alpha=0.5, label='Sampled Vector Field')\n",
    "    \n",
    "    ax.plot(X,Y, label='GT Trajectory', alpha=0.2, marker='.')\n",
    "    ax.plot(X[0], Y[0], 'go', label='Start', alpha=0.5)\n",
    "    ax.plot(X[-1], Y[-1], 'ro', label='End', alpha=0.5)\n",
    "    ax.quiver(X[::interval], Y[::interval], U[::interval], V[::interval], angles='xy', scale_units='xy', scale=scale, alpha=0.2, label='GT Vector Field')\n",
    "    ax.set_xlabel(\"X axis\")\n",
    "    ax.set_ylabel(\"Y axis\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_trajectory_2D(ts, gt_trajectory, gt_gradients, title=f\"Spiral Attractor (Ground Truth) with {n_steps} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2302cda",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 16px; color: black; font-weight: bold;\">\n",
    "Create data batch by adding noise and sampling random points from the ground truth trajectory\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch data of noisy samples of ground truth trajectory\n",
    "batch_size = 256\n",
    "\n",
    "batch_ts = ts.unsqueeze(0).repeat((batch_size,1))\n",
    "batch_gt_trajectory = gt_trajectory.unsqueeze(0).repeat((batch_size,1,1))\n",
    "batch_gt_gradients = gt_gradients.unsqueeze(0).repeat((batch_size,1,1))\n",
    "\n",
    "# ratio of points to sample from the entire trajectory\n",
    "ratio = 0.50\n",
    "n_points = int(ratio * n_steps)\n",
    "\n",
    "# indices to pick : (batch_size, n_points) array of indices\n",
    "idx = [ np.sort(np.random.choice(n_steps, size=n_points, replace=False)) for _ in range(batch_size) ]\n",
    "indices = np.array(idx)\n",
    "\n",
    "# sample subset of points in the GT trajectory and gradients and form a batch\n",
    "indices = torch.from_numpy(indices).long().to(ts.device)\n",
    "batch_sampled_ts = ts[indices]\n",
    "batch_sampled_trajectory = gt_trajectory[indices]\n",
    "batch_sampled_gradients = gt_gradients[indices]\n",
    "\n",
    "# add noise to the sampled points\n",
    "noise_level = 0.025\n",
    "noise = noise_level * torch.randn_like(batch_sampled_trajectory)\n",
    "batch_sampled_noisy_trajectory = batch_sampled_trajectory + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "\n",
    "print(f\"batch_ts shape: {batch_ts.shape}\")\n",
    "print(f\"batch_gt_trajectory shape: {batch_gt_trajectory.shape}\")\n",
    "print(f\"batch_gt_gradients shape: {batch_gt_gradients.shape}\")\n",
    "print(f\"batch_sampled_ts shape: {batch_sampled_ts.shape}\")\n",
    "print(f\"batch_sampled_trajectory shape: {batch_sampled_trajectory.shape}\")\n",
    "print(f\"batch_sampled_noisy_trajectory shape: {batch_sampled_noisy_trajectory.shape}\")\n",
    "print(f\"batch_sampled_gradients shape: {batch_sampled_gradients.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fda554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some samples\n",
    "N = 3\n",
    "\n",
    "for i in range(N):\n",
    "    fig, ax = plot_trajectory_2D(batch_ts[i], batch_gt_trajectory[i], batch_gt_gradients[i], \n",
    "                                 batch_sampled_ts[i], batch_sampled_noisy_trajectory[i], batch_sampled_gradients[i], \n",
    "                                 title=f\"Sample {i+1} from batch of noisy samples - {n_points} points in {n_steps}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb078c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "Model - Step by step pipeline\n",
    "</div>\n",
    "\n",
    "from: [ArviX Latent ODEs for Irregularly-Sampled Time Series](https://arxiv.org/abs/1907.03907)\n",
    "\n",
    "We want to learn the flow dynamics from the batch sampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f130afe3",
   "metadata": {},
   "source": [
    "![Alt text](/home/benjamin/Folders_Python/MVA_Stage/images/Neural_ODE_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10ea47",
   "metadata": {},
   "source": [
    "Computing the ELBO:\n",
    "\n",
    "Data is $x_{t_0}, x_{t_2},...,x_{t_N}$.\n",
    "\n",
    "Model:\n",
    "\\begin{align}\n",
    "    z_{t_0} = z_0 &\\sim \\mathcal{N}(0,1) \\\\\n",
    "    z_1, z_2, ..., z_N &= \\text{ODESolve}(z_0, f_{\\theta}, t_0, ..., t_N) \\\\\n",
    "    x_i \\vert z_i &\\sim \\mathcal{N}(\\mu_{\\theta_x}(z_i), \\text{diag}\\, \\sigma_x(z_i)) \\\\\n",
    "    q_\\phi(z_0 \\vert x_{0:N}) &= \\mathcal{N}(\\mu_\\phi(x_{0:N}), \\text{diag} \\, \\sigma_\\phi(x_{0:N})) \\\\\n",
    "    [ \\mu_\\phi, \\sigma_\\phi ](x_{0:N}) &= \\text{RNN} \\, (x_{0:N}, t_{0:N})\n",
    "\\end{align}\n",
    "\n",
    "ELBO:\n",
    "\\begin{align}\n",
    "    p(x_{0:N}) &= \\frac{p(x_{0:N}, z_{0:N})}{p(z_{0:N} \\vert x_{0:N})} \\\\\n",
    "    \\log{p(x_{0:N})} &= \\mathbb{E}_{q_{\\phi}(z_0 \\vert x_{0:N})} \\log{\\frac{p(x_{0:N}, z_{0:N})}{q_{\\phi}(z_0 \\vert x_{0:N})}\\frac{q_{\\phi}(z_0 \\vert x_{0:N})}{p(z_{0:N} \\vert x_{0:N})}} \\\\\n",
    "    &= \\mathbb{E}_{q_{\\phi}(z_0 \\vert x_{0:N})} \\log{\\frac{p(x_{0:N}, z_{0:N})}{q_{\\phi}(z_0 \\vert x_{0:N})}} + \\mathbb{KL}(q_{\\phi}(z_0 \\vert x_{0:N}) \\vert\\vert p(z_{0:N} \\vert x_{0:N}) ) \\\\\n",
    "    &\\geq \\mathcal{L}(x_{0:N}, \\theta, \\phi) = \\mathbb{E}_{q_{\\phi}(z_0 \\vert x_{0:N})} \\log{\\frac{p(x_{0:N}, z_{0:N})}{q_{\\phi}(z_0 \\vert x_{0:N})}} \\\\\n",
    "    \\mathcal{L}(x_{0:N}, \\theta, \\phi) &= \\mathbb{E}_{q_{\\phi}(z_0 \\vert x_{0:N})} \\log{\\frac{\\prod_{i=0}^{n}p_{\\theta_x}(x_i \\vert z_i) p(z_0)}{q_{\\phi}(z_0 \\vert x_{0:N})}} \\\\\n",
    "    &= \\sum_{i=0}^{n} \\mathbb{E}_{q_{\\phi}(z_0 \\vert x_{0:N})} \\log{p_{\\theta_x}(x_i \\vert z_i)} - \\mathbb{KL}(q_{\\phi}(z_0 \\vert x_{0:N}) \\vert\\vert p(z_0))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410db749",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = 2  # dimension of the data\n",
    "Dz = 8  # dimension of the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ea757",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ac223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have created above, a batch of batch_size samples of n_points taken randmomly\n",
    "# in the ground truth trajectory of n_steps points,\n",
    "# and added some noise to the sampled points\n",
    "\n",
    "x = batch_sampled_noisy_trajectory\n",
    "print(f\"Data x: {x.shape}\")\n",
    "print(f\"\\tBatch size: {x.shape[0]}\")\n",
    "print(f\"\\tNumber of sampled points: {x.shape[1]}\")\n",
    "print(f\"\\tData dimension: {x.shape[2]} (should be {Dx})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f42ad93",
   "metadata": {},
   "source": [
    "Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec03694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the model, the only stochastic prior variable is z0, the latent state at time t_start\n",
    "# the random variable z0 has prior p(z0) = N(0, I)\n",
    "\n",
    "p_theta_z = MultivariateNormal(torch.zeros(Dz).to(device), torch.eye(Dz).to(device))\n",
    "\n",
    "# we sample one z0 for each element in the batch\n",
    "z0_samples = p_theta_z.sample((batch_size,))\n",
    "\n",
    "print(f\"Priors z0 : {z0_samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f519c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the latent variables z1 to z_{n_points} are computed deterministically from z0 and the time points\n",
    "# with the ODE defined below with a neural net.\n",
    "\n",
    "# here is the flow neural net for the latent ODE\n",
    "# it is assumed to be time-invariant, so t is not used in the forward pass\n",
    "class LatentODEFunc(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines the latent ODE to compute deterministically the latent variables from z0 and the times steps.\n",
    "    Inputs:\n",
    "        - Dz (int): dimension of the latent space.\n",
    "        - hidden_dim (int): dimension of the hidden layers.\n",
    "        - n_layers (int): number of hidden layers.\n",
    "    Outputs:\n",
    "        - z_dot (tensor of shape (batch_size, Dz)): time derivative of the latent variable.\n",
    "    \"\"\"\n",
    "    def __init__(self, Dz, hidden_dim=32, n_layers=1):\n",
    "        super(LatentODEFunc, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        self.n_layers = n_layers\n",
    "        self.Dz = Dz\n",
    "        self.hidden_dim = hidden_dim\n",
    "        input_size = Dz\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(input_size, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            input_size = hidden_dim\n",
    "        layers.append(nn.Linear(hidden_dim, Dz))  # output mean and logvar\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, t, z):\n",
    "        # here we assume time invariance, so t is not used\n",
    "        return self.net(z)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        msg = f\"Flow function for latent ODE - (Dz={Dz}, hidden_dim={self.hidden_dim}, n_layers={self.n_layers})\"\n",
    "        msg += f\"\\n{self.net}\"\n",
    "        return msg\n",
    "\n",
    "latent_ode_func = LatentODEFunc(Dz, hidden_dim=64, n_layers=4).to(device)\n",
    "print(latent_ode_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd82856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test shape of the flow function for the latent ODE\n",
    "z = torch.randn((batch_size, Dz)).to(device)\n",
    "outputs = latent_ode_func(t_start, z)\n",
    "print(f\"Latent ODE function input: {z.shape} (should be ({batch_size}, {Dz}))\")\n",
    "print(f\"Latent ODE function output: {outputs.shape} (should be ({batch_size}, {Dz}))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95057e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the whole sequence of latent variables z1 to z_{n_points},\n",
    "# from z0 and the sampled time points,\n",
    "# with one ODE solve per batch element\n",
    "\n",
    "# those are the time stamps to use in the bacth\n",
    "print(batch_sampled_ts.shape)\n",
    "\n",
    "# run one ODE per batch dimension\n",
    "for i in range(batch_size):\n",
    "    # compute sequence of latent variables for this batch element with ODE solver\n",
    "    z_sample = odeint_adjoint(latent_ode_func, z0_samples[i], batch_sampled_ts[i], rtol=1e-2, atol=1e-2, method='rk4')\n",
    "    if i == 0:\n",
    "        z_samples = z_sample.unsqueeze(0)\n",
    "    else:\n",
    "        z_samples = torch.cat([z_samples, z_sample.unsqueeze(0)], dim=0)\n",
    "        \n",
    "print(f\"z_samples: {z_samples.shape}\")\n",
    "\n",
    "print(f\"\\tBatch size: {z_samples.shape[0]} (should be {batch_size})\")\n",
    "print(f\"\\tNumber of time points: {z_samples.shape[1]} (should be {n_points})\")\n",
    "print(f\"\\tLatent dimension: {z_samples.shape[2]} (should be {Dz})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b09c336",
   "metadata": {},
   "source": [
    "Likelihood \\ decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a simple Gaussian liklehood with diagonal covariance\n",
    "#\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder to map the latent state z to the data space x.\n",
    "    Inputs:\n",
    "        - latent_dim (int): dimension of the latent space (Dz).\n",
    "        - output_dim (int): dimension of the output data (Dx).\n",
    "        - hidden_dim (int): dimension of the hidden layer.\n",
    "        - n_layers (int): number of layers in the MLP.\n",
    "    Outputs:\n",
    "        - x_recon (tensor of shape (batch_size, seq_len, Dx)): reconstructed data points.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, output_dim, hidden_dim=32, n_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.Dz = latent_dim\n",
    "        self.Dx = output_dim\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            input_dim = self.hidden_dim\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim * 2))  # output mean and logvar\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # z: latent states (batch_size, seq_len, latent_size)\n",
    "        mu_x = self.mlp(z)[:,:,:self.Dx]  # (batch_size, seq_len, output_size)\n",
    "        logvar_x = self.mlp(z)[:,:,self.Dx:]  # (batch_size, seq_len, output_size)\n",
    "        return mu_x, logvar_x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Decoder(latent_dim={self.Dz}, output_dim={self.Dx}, hidden_dim={self.hidden_dim}, n_layers={self.n_layers}) \\n {self.mlp}\"\n",
    "    \n",
    "decoder = Decoder(Dz, Dx, n_layers=4).to(device)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x, logvar_x = decoder(z_samples)\n",
    "\n",
    "print(f\"Inputs to Decoder: z_samples {z_samples.shape}\")\n",
    "print(f\"Outputs of Decoder: mu_x {mu_x.shape}, logvar_x {logvar_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_x = torch.exp(0.5 * logvar_x).to(device)\n",
    "\n",
    "# p_theta_x = MultivariateNormal(mu_x, sigma_x)\n",
    "p_theta_x = Independent(Normal(mu_x, sigma_x),1)\n",
    "print(f\"p_theta_x: {p_theta_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2587d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction loss:\n",
    "print(f\"batch_sampled_noisy_trajectory: {batch_sampled_noisy_trajectory.shape}\")\n",
    "\n",
    "rec_loss = -p_theta_x.log_prob(batch_sampled_noisy_trajectory)\n",
    "print(f\"Reconstruction loss: mean {rec_loss.mean():.4e} of shape {rec_loss.shape}\")\n",
    "print(f\"\\tBatch size: {rec_loss.shape[0]} (should be {batch_size})\")\n",
    "print(f\"\\tNumber of sampled points: {rec_loss.shape[1]} (should be {n_points})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c362d3a",
   "metadata": {},
   "source": [
    "Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b42f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the posterior q_phi(z0 | x0:N) is modeled with an RNN encoder\n",
    "# it is a Gaussian with mean and logvar given by the RNN output at time N\n",
    "# the forward pass of the RNN takes also as input the sequence of time stamps\n",
    "\n",
    "class RNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Encoder to infer the initial latent state z0 from the observed data.\n",
    "    Inputs:\n",
    "        - input_dim (int): dimension of the input data (Dx).\n",
    "        - hidden_dim (int): dimension of the hidden state in the RNN.\n",
    "        - latent_dim (int): dimension of the latent space (Dz).\n",
    "        - n_layers (int): number of layers in the RNN.\n",
    "    Outputs:\n",
    "        - z0_mean (tensor of shape (batch_size, Dz)): mean of the inferred initial latent state.\n",
    "        - z0_logvar (tensor of shape (batch_size, Dz)): log-variance of the inferred initial latent state.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_layers=1):\n",
    "        super(RNNEncoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.Dx = input_dim\n",
    "        self.Dz = latent_dim\n",
    "        # NB : the input size of the RNN is Dx + 1 for the time stamp concatenated to the data point\n",
    "        self.rnn = nn.LSTM(input_dim + 1, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # t: sequence of time stamps (batch_size, seq_len)\n",
    "        # x: sequence of data points (batch_size, seq_len, input_dim)\n",
    "        times = t.unsqueeze(-1)  # (batch_size, seq_len, 1)\n",
    "        x_ext = torch.cat([x, times], dim=-1)  # (batch_size, seq_len, input_dim + 1)\n",
    "        _, (h_n, c_n) = self.rnn(x_ext)  # h_n: (n_layers, batch_size, hidden_dim)\n",
    "        h_n = h_n[-1]  # take the last layer's hidden state: (batch_size, hidden_dim)\n",
    "        z0_mean = self.fc_mean(h_n)  # (batch_size, latent_dim)\n",
    "        z0_logvar = self.fc_logvar(h_n)  # (batch_size, latent_dim)\n",
    "        return z0_mean.squeeze(0), z0_logvar.squeeze(0)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        msg = f\"RNNEncoder(input_dim={self.Dx} (+1 for time stamps), hidden_dim={self.hidden_dim}, latent_dim={self.Dz}, n_layers={self.n_layers}), \\n\"\n",
    "        msg += f\"LSTM : {self.rnn}, Mean : {self.fc_mean}, Logvar : {self.fc_logvar}\"\n",
    "        return msg\n",
    "\n",
    "rnn_encoder = RNNEncoder(input_dim=Dx, hidden_dim=64, latent_dim=Dz, n_layers=4).to(device)\n",
    "print(rnn_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_mean, z0_logvar = rnn_encoder(batch_sampled_ts, batch_sampled_noisy_trajectory)\n",
    "\n",
    "print(f\"Inputs to RNN Encoder: batch_sampled_ts {batch_sampled_ts.shape}, batch_sampled_trajectory {batch_sampled_noisy_trajectory.shape}\")\n",
    "print(f\"outputs of RNN Encoder: z0_mean {z0_mean.shape} z0_logvar {z0_logvar.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25799c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_phi = z0_mean.to(device)\n",
    "print(f\"mu_phi : {mu_phi.shape}\")\n",
    "sigma_phi = torch.diag_embed(torch.exp(0.5 * z0_logvar).to(device))\n",
    "print(f\"sigma_phi : {sigma_phi.shape}\")\n",
    "\n",
    "q_phi = MultivariateNormal(mu_phi, sigma_phi)\n",
    "print(f\"q_phi: {q_phi}\")\n",
    "print(f\"\\tbatch shape: {q_phi.batch_shape}, event shape: {q_phi.event_shape}\")\n",
    "\n",
    "z0_samples = q_phi.rsample().to(device).squeeze()\n",
    "print(f\"z0_samples: {z0_samples.shape}\")\n",
    "print(f\"\\tBatch size: {z0_samples.shape[0]}\")\n",
    "print(f\"\\tDimension: {z0_samples.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = kl_divergence(q_phi, p_theta_z).to(device)\n",
    "print(f\"KL loss: mean {kl_loss.mean():.4e} of shape {kl_loss.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6e2f9",
   "metadata": {},
   "source": [
    "Total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d95ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = rec_loss.mean() + kl_loss.mean()\n",
    "print(f\"Total loss: {loss.item():.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74845171",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0cdc5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "Model - Training loop\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ed322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form datasets and dataloaders for PyTorch training\n",
    "# we store the full times, trajectories and gradients for reference\n",
    "# but only the sampled noisy trajectories and sampled times are used for training\n",
    "\n",
    "class SpiralDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, t, X, flows, all_t=None, all_X=None, all_flows=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - all_t (numpy array of shape (n_samples, n_steps)): full time points.\n",
    "            - all_X (numpy array of shape (n_samples, n_steps, Dx)): full trajectory points.\n",
    "            - all_flows (numpy array of shape (n_samples, n_steps, Dx)): full gradients points.\n",
    "            - t (numpy array of shape (n_samples, n_points)): time points of sampled data\n",
    "            - X (numpy array of shape (n_samples, n_points, Dx)): data points of sampled data\n",
    "            - flows (numpy array of shape (n_samples, n_points, Dx)): gradients points of sampled data\n",
    "        \"\"\"\n",
    "        self.t = torch.tensor(t, dtype=torch.float32)\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.flows = torch.tensor(flows, dtype=torch.float32)\n",
    "        self.all_t = torch.tensor(all_t, dtype=torch.float32) if all_t is not None else None\n",
    "        self.all_X = torch.tensor(all_X, dtype=torch.float32) if all_X is not None else None\n",
    "        self.all_flows = torch.tensor(all_flows, dtype=torch.float32) if all_flows is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.t[idx], self.X[idx], self.flows[idx], self.all_t[idx], self.all_X[idx], self.all_flows[idx]\n",
    "    \n",
    "# form train and test datasets\n",
    "train_ratio = 0.80\n",
    "train_id = int(train_ratio * batch_size)\n",
    "\n",
    "# train\n",
    "t_train_all = batch_ts[:train_id].detach().cpu().numpy().reshape(-1, n_steps)\n",
    "X_train_all = batch_gt_trajectory[:train_id].detach().cpu().numpy().reshape(-1, n_steps, Dx)\n",
    "flows_train_all = batch_gt_gradients[:train_id].detach().cpu().numpy().reshape(-1, n_steps, Dx)\n",
    "t_train = batch_sampled_ts[:train_id].detach().cpu().numpy().reshape(-1, n_points)\n",
    "X_train = batch_sampled_noisy_trajectory[:train_id].detach().cpu().numpy().reshape(-1, n_points, Dx)\n",
    "flows_train = batch_sampled_gradients[:train_id].detach().cpu().numpy().reshape(-1, n_points, Dx)\n",
    "\n",
    "# test\n",
    "t_test_all = batch_ts[train_id:].detach().cpu().numpy().reshape(-1, n_steps)\n",
    "X_test_all = batch_gt_trajectory[train_id:].detach().cpu().numpy().reshape(-1, n_steps, Dx)\n",
    "flows_test_all = batch_gt_gradients[train_id:].detach().cpu().numpy().reshape(-1, n_steps, Dx)\n",
    "t_test = batch_sampled_ts[train_id:].detach().cpu().numpy().reshape(-1, n_points)\n",
    "X_test = batch_sampled_noisy_trajectory[train_id:].detach().cpu().numpy().reshape(-1, n_points, Dx)\n",
    "flows_test = batch_sampled_gradients[train_id:].detach().cpu().numpy().reshape(-1, n_points, Dx)\n",
    "\n",
    "# datasets\n",
    "train_dataset = SpiralDataset(t_train, X_train, flows_train, t_train_all, X_train_all, flows_train_all)\n",
    "test_dataset = SpiralDataset(t_test, X_test, flows_test, t_test_all, X_test_all, flows_test_all)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "bs = 32 # batch size for dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "Dx = 2  # dimension of the data\n",
    "Dz = 8  # dimension of the latent space\n",
    "\n",
    "# model bricks\n",
    "# prior\n",
    "p_theta_z = MultivariateNormal(torch.zeros(Dz).to(device), torch.eye(Dz).to(device))\n",
    "# latent ODE flow\n",
    "latent_ode_func = LatentODEFunc(Dz, hidden_dim=64, n_layers=4).to(device)\n",
    "# decoder\n",
    "decoder = Decoder(Dz, Dx, n_layers=4).to(device)\n",
    "# encoder / approximate posterior\n",
    "rnn_encoder = RNNEncoder(input_dim=Dx, hidden_dim=64, latent_dim=Dz, n_layers=4).to(device)\n",
    "\n",
    "# report out\n",
    "print(f\"Model components:\")\n",
    "print(f\"Prior : {p_theta_z}\")\n",
    "print(f\"Latent ODE function : {latent_ode_func}\")\n",
    "print(f\"Decoder : {decoder}\")\n",
    "print(f\"RNN Encoder : {rnn_encoder}\")\n",
    "\n",
    "# training loop parameters\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(rnn_encoder.parameters()) + list(latent_ode_func.parameters()) + list(decoder.parameters()), \n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "# report out\n",
    "print(f\"Training parameters:\")\n",
    "print(f\"Learning rate : {learning_rate}\")\n",
    "print(f\"Optimizer : {optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "def train_step(batch_sampled_ts, batch_sampled_noisy_trajectory, optimizer, rnn_encoder, latent_ode_func, decoder):\n",
    "    \"\"\"\n",
    "    Perform one training step (ie one epoch)\n",
    "    Inputs:\n",
    "        - batch_sampled_ts (tensor of shape (batch_size, n_points)): batch of time points.\n",
    "        - batch_sampled_noisy_trajectory (tensor of shape (batch_size, n_points, Dx)): batch of noisy trajectory points.\n",
    "        - optimizer: optimizer to use.\n",
    "        - rnn_encoder: RNN encoder model.\n",
    "        - latent_ode_func: latent ODE function model.\n",
    "        - decoder: decoder model.\n",
    "    Outputs:\n",
    "        - loss (float): total loss (reconstruction + KL).\n",
    "        - rec_loss (float): reconstruction loss.\n",
    "        - kl_loss (float): KL divergence loss.\n",
    "        - rnn_encoder, latent_ode_func, decoder: models in train mode.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get in train mode\n",
    "    rnn_encoder.train()\n",
    "    latent_ode_func.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # encode to get q_phi(z0 | x0:N)\n",
    "    z0_mean, z0_logvar = rnn_encoder(batch_sampled_ts, batch_sampled_noisy_trajectory)\n",
    "    mu_phi = z0_mean.to(device)\n",
    "    sigma_phi = torch.diag_embed(torch.exp(0.5 * z0_logvar).to(device))\n",
    "    q_phi = MultivariateNormal(mu_phi, sigma_phi)\n",
    "    \n",
    "    # sample z0 from q_phi\n",
    "    z0_samples = q_phi.rsample().to(device).squeeze()\n",
    "    \n",
    "    # compute latent trajectory z1:N from z0 and t1:N with latent ODE\n",
    "    batch_size, n_points = batch_sampled_ts.shape\n",
    "    for i in range(batch_size):\n",
    "        z_sample = odeint_adjoint(latent_ode_func, z0_samples[i], batch_sampled_ts[i], rtol=1e-3, atol=1e-3, method='rk4')\n",
    "        if i == 0:\n",
    "            z_samples = z_sample.unsqueeze(0)\n",
    "        else:\n",
    "            z_samples = torch.cat([z_samples, z_sample.unsqueeze(0)], dim=0)\n",
    "    \n",
    "    # decode to get p_theta(x | z)\n",
    "    mu_x, logvar_x = decoder(z_samples)\n",
    "    sigma_x = torch.exp(0.5 * logvar_x).to(device)\n",
    "    p_theta_x = Independent(Normal(mu_x, sigma_x),1)\n",
    "    \n",
    "    # reconstruction loss\n",
    "    rec_loss = -p_theta_x.log_prob(batch_sampled_noisy_trajectory).mean()\n",
    "    \n",
    "    # KL loss\n",
    "    kl_loss = kl_divergence(q_phi, p_theta_z).mean()\n",
    "    \n",
    "    # total loss\n",
    "    loss = rec_loss + kl_loss\n",
    "    \n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return rnn_encoder, latent_ode_func, decoder, loss.item(), rec_loss.item(), kl_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test step\n",
    "def test_step(batch_sampled_ts, batch_sampled_noisy_trajectory, rnn_encoder, latent_ode_func, decoder):\n",
    "    \"\"\"\n",
    "    Perform one test step (ie one epoch)\n",
    "    Inputs:\n",
    "        - batch_sampled_ts (tensor of shape (batch_size, n_points)): batch of time points.\n",
    "        - batch_sampled_noisy_trajectory (tensor of shape (batch_size, n_points, Dx)): batch of noisy trajectory points.\n",
    "        - rnn_encoder: RNN encoder model.\n",
    "        - latent_ode_func: latent ODE function model.\n",
    "        - decoder: decoder model.\n",
    "    Outputs:\n",
    "        - loss (float): total loss (reconstruction + KL).\n",
    "        - rec_loss (float): reconstruction loss.\n",
    "        - kl_loss (float): KL divergence loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get in eval mode\n",
    "    rnn_encoder.eval()\n",
    "    latent_ode_func.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # encode to get q_phi(z0 | x0:N)\n",
    "        z0_mean, z0_logvar = rnn_encoder(batch_sampled_ts, batch_sampled_noisy_trajectory)\n",
    "        mu_phi = z0_mean.to(device)\n",
    "        sigma_phi = torch.diag_embed(torch.exp(0.5 * z0_logvar).to(device))\n",
    "        q_phi = MultivariateNormal(mu_phi, sigma_phi)\n",
    "\n",
    "        # sample z0 from q_phi\n",
    "        z0_samples = q_phi.rsample().to(device).squeeze()\n",
    "\n",
    "        # compute latent trajectory z1:N from z0 and t1:N with latent ODE\n",
    "        batch_size, n_points = batch_sampled_ts.shape\n",
    "        for i in range(batch_size):\n",
    "            z_sample = odeint_adjoint(latent_ode_func, z0_samples[i], batch_sampled_ts[i], rtol=1e-3, atol=1e-3, method='rk4')\n",
    "            if i == 0:\n",
    "                z_samples = z_sample.unsqueeze(0)\n",
    "            else:\n",
    "                z_samples = torch.cat([z_samples, z_sample.unsqueeze(0)], dim=0)\n",
    "\n",
    "        # decode to get p_theta(x | z)\n",
    "        mu_x, logvar_x = decoder(z_samples)\n",
    "        sigma_x = torch.exp(0.5 * logvar_x).to(device)\n",
    "        p_theta_x = Independent(Normal(mu_x, sigma_x),1)\n",
    "\n",
    "        # reconstruction loss\n",
    "        rec_loss = -p_theta_x.log_prob(batch_sampled_noisy_trajectory).mean()\n",
    "        \n",
    "        # KL loss\n",
    "        kl_loss = kl_divergence(q_phi, p_theta_z).mean()\n",
    "        \n",
    "        # total loss\n",
    "        loss = rec_loss + kl_loss\n",
    "        \n",
    "    return loss.item(), rec_loss.item(), kl_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir = '/home/benjamin/Folders_Python/MVA_Stage/models/spiral_ODE/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "save_file = save_dir + f'spiral_vae_ode_{timestamp}.pth'\n",
    "print(f'Model will be saved to: {save_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfac938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 100\n",
    "print(f\"Number of epochs : {n_epochs}\")\n",
    "\n",
    "train_rec_losses = []\n",
    "train_kl_losses = []\n",
    "train_total_losses = []\n",
    "    \n",
    "test_rec_losses = []\n",
    "test_kl_losses = []\n",
    "test_total_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # train on all batches\n",
    "    train_total_loss = 0.0\n",
    "    train_rec_loss = 0.0\n",
    "    train_kl_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (batch_ts, batch_trajectory, _, _, _, _) in enumerate(train_loader):\n",
    "        batch_ts = batch_ts.to(device)\n",
    "        batch_trajectory = batch_trajectory.to(device)\n",
    "        \n",
    "        rnn_encoder, latent_ode_func, decoder, total_loss, rec_loss, kl_loss = train_step(\n",
    "            batch_ts, batch_trajectory, optimizer, rnn_encoder, latent_ode_func, decoder\n",
    "        )\n",
    "        \n",
    "        train_rec_loss += rec_loss * batch_ts.shape[0]\n",
    "        train_kl_loss += kl_loss * batch_ts.shape[0]\n",
    "        train_total_loss += total_loss * batch_ts.shape[0]\n",
    "        \n",
    "        print(f\"TRAINING : Epoch {epoch+1} Batch {batch_idx+1}/{len(train_loader)} - Train Loss: {total_loss:+.4e} (Rec: {rec_loss:+.4e}, KL: {kl_loss:+.4e})\", end='\\r')\n",
    "    \n",
    "    train_rec_loss /= len(train_loader)\n",
    "    train_kl_loss /= len(train_loader)\n",
    "    train_total_loss /= len(train_loader)\n",
    "    \n",
    "    train_rec_losses.append(train_rec_loss)\n",
    "    train_kl_losses.append(train_kl_loss)\n",
    "    train_total_losses.append(train_total_loss)\n",
    "    \n",
    "    # test on all batches\n",
    "    test_total_loss = 0.0\n",
    "    test_rec_loss = 0.0\n",
    "    test_kl_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (batch_ts, batch_trajectory, _, _, _, _) in enumerate(test_loader):\n",
    "        batch_ts = batch_ts.to(device)\n",
    "        batch_trajectory = batch_trajectory.to(device)\n",
    "        \n",
    "        total_loss, rec_loss, kl_loss = test_step(\n",
    "            batch_ts, batch_trajectory, rnn_encoder, latent_ode_func, decoder\n",
    "        )\n",
    "        \n",
    "        test_rec_loss += rec_loss * batch_ts.shape[0]\n",
    "        test_kl_loss += kl_loss * batch_ts.shape[0]\n",
    "        test_total_loss += total_loss * batch_ts.shape[0]\n",
    "        \n",
    "        print(f\"TEST : Epoch {epoch+1} Batch {batch_idx+1}/{len(test_loader)} - Test Loss: {total_loss:+.4e} (Rec: {rec_loss:+.4e}, KL: {kl_loss:+.4e})\", end='\\r')\n",
    "        \n",
    "    test_rec_loss /= len(test_loader)\n",
    "    test_kl_loss /= len(test_loader)\n",
    "    test_total_loss /= len(test_loader)\n",
    "    \n",
    "    # save best model\n",
    "    if test_total_loss < best_val_loss:\n",
    "        best_val_loss = test_total_loss\n",
    "        torch.save({\n",
    "            'rnn_encoder_state_dict': rnn_encoder.state_dict(),\n",
    "            'latent_ode_func_state_dict': latent_ode_func.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'train_total_loss': train_total_loss,\n",
    "            'test_total_loss': test_total_loss,\n",
    "        }, save_file)\n",
    "        msg = f\" - Model saved at epoch {epoch+1} with test loss {best_val_loss:+.4e}\"\n",
    "    else:\n",
    "        msg = \"\"\n",
    "    \n",
    "    test_rec_losses.append(test_rec_loss)\n",
    "    test_kl_losses.append(test_kl_loss)\n",
    "    test_total_losses.append(test_total_loss)\n",
    "    \n",
    "    # summary of epoch    \n",
    "    print(f\"Epoch {epoch+1:<3}/ {n_epochs:<3} - Train Loss: {train_total_loss:+.4e} (Rec: {train_rec_loss:+.4e}, KL: {train_kl_loss:+.4e}) | Test Loss: {test_total_loss:+.4e} (Rec: {test_rec_loss:+.4e}, KL: {test_kl_loss:+.4e})\" + msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "fig, ax = plt.subplots(figsize=(16,4), nrows=1, ncols=3)\n",
    "epochs = np.arange(1, n_epochs+1)\n",
    "\n",
    "# reconstruction loss\n",
    "ax[0].plot(epochs, train_rec_losses, label='Train Rec Loss')\n",
    "ax[0].plot(epochs, test_rec_losses, label='Test Rec Loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Reconstruction Loss')\n",
    "ax[0].set_title('Reconstruction Loss over Epochs')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "# KL loss\n",
    "ax[1].plot(epochs, train_kl_losses, label='Train KL Loss')\n",
    "ax[1].plot(epochs, test_kl_losses, label='Test KL Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('KL Loss')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_title('KL Loss over Epochs')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "# total loss\n",
    "ax[2].plot(epochs, train_total_losses, label='Train Total Loss')\n",
    "ax[2].plot(epochs, test_total_losses, label='Test Total Loss')\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].set_ylabel('Total Loss')\n",
    "ax[2].set_title('Total Loss over Epochs')\n",
    "ax[2].legend()\n",
    "ax[2].grid(True)\n",
    "\n",
    "fig.suptitle(f'Losses - Dz = {Dz}', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "checkpoint = torch.load(save_file, map_location=device)\n",
    "rnn_encoder.load_state_dict(checkpoint['rnn_encoder_state_dict'])\n",
    "latent_ode_func.load_state_dict(checkpoint['latent_ode_func_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "train_loss = checkpoint['train_total_loss']\n",
    "test_loss = checkpoint['test_total_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e17994",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "Reconstruction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa818f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples we want to reconstruct and visualize\n",
    "N_VIZ = 3\n",
    "\n",
    "# get N_VIZ random indices in the test dataset\n",
    "idx = np.random.choice(len(test_dataset), size=N_VIZ, replace=False)\n",
    "\n",
    "# number of time steps for reconstruction\n",
    "n_steps = 100\n",
    "t_end = 20.0\n",
    "\n",
    "for i, id in enumerate(idx):\n",
    "    # get the spiral sample from the test dataset\n",
    "    ts, xs, flows, ts_all, xs_all, flows_all = test_dataset[id]\n",
    "    ts = ts.to(device)\n",
    "    xs = xs.to(device)\n",
    "    # print(ts[0], ts[-1])\n",
    "    # print(xs[0], xs[-1])\n",
    "    flows = flows.to(device)\n",
    "    ts_all = ts_all.to(device)\n",
    "    xs_all = xs_all.to(device)\n",
    "    flows_all = flows_all.to(device)\n",
    "    \n",
    "    # reconstruct the trajectory with the trained model\n",
    "    with torch.no_grad():\n",
    "        # get the initial latent state z0 according to the learnt posterior q_phi(z0 | x0:N)\n",
    "        z0_mean, z0_logvar = rnn_encoder(ts, xs)\n",
    "        mu_phi = z0_mean.to(device)\n",
    "        sigma_phi = torch.diag_embed(torch.exp(0.5 * z0_logvar).to(device))\n",
    "        q_phi = MultivariateNormal(mu_phi, sigma_phi)\n",
    "        # get 1 sample of z0 from q_phi\n",
    "        # we could also use z0_mean directly\n",
    "        z0_sample = q_phi.rsample().to(device).squeeze()\n",
    "        # z0_sample = z0_mean.to(device)  # alternatively use the mean\n",
    "        # print(z0_sample)\n",
    "        # compute the latent trajectory z1:N from z0 and t1:N with latent ODE on ALL time steps from our t0 to t_end\n",
    "        times = torch.linspace(ts[0], t_end, n_steps).to(device)\n",
    "        z_sample = odeint_adjoint(latent_ode_func, z0_sample, times, rtol=1e-2, atol=1e-2, method='rk4')\n",
    "        # decode the full latent trajectory to get p_theta(x | z)\n",
    "        mu_x, logvar_x = decoder(z_sample.unsqueeze(0))\n",
    "        sigma_x = torch.exp(0.5 * logvar_x).to(device)\n",
    "        p_theta_x = Independent(Normal(mu_x, sigma_x),1)\n",
    "        # get the mean trajectory\n",
    "        x_recon = mu_x.squeeze(0)\n",
    "        # print(x_recon[0], x_recon[-1])\n",
    "    \n",
    "    # plot the reconstructed trajectory against the ground truth\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.plot(xs_all[:,0].detach().cpu().numpy(), xs_all[:,1].detach().cpu().numpy(), label='GT Trajectory', alpha=0.2, marker='.')\n",
    "    ax.quiver(xs_all[::5,0].detach().cpu().numpy(), xs_all[::5,1].detach().cpu().numpy(), \n",
    "                flows_all[::5,0].detach().cpu().numpy(), flows_all[::5,1].detach().cpu().numpy(), \n",
    "                angles='xy', scale_units='xy', scale=5.0, alpha=0.2, label='GT Vector Field')\n",
    "    ax.scatter(xs[:,0].detach().cpu().numpy(), xs[:,1].detach().cpu().numpy(), color='b', marker='x', s=50.0, label='Sampled Noisy Points')\n",
    "    ax.plot(x_recon[:,0].detach().cpu().numpy(), x_recon[:,1].detach().cpu().numpy(), marker='x', label='Reconstructed Trajectory', alpha=0.8)\n",
    "    ax.set_xlabel(\"X axis\")\n",
    "    ax.set_ylabel(\"Y axis\")\n",
    "    ax.set_title(f\"Test Sample {i+1} - id = {id} - Reconstructed Trajectory vs GT\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c4201",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "Gnration\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911939ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trajectories to generate\n",
    "N_GEN = 3\n",
    "\n",
    "for i in range(N_GEN):\n",
    "    # sample prior z0 ~ p(z0)\n",
    "    z0_sample = p_theta_z.sample().to(device)\n",
    "    # compute the latent trajectory z1:N from z0 and t1:N with latent ODE on ALL time steps from our t0 to t_end\n",
    "    times = torch.linspace(t_start, t_end, n_steps).to(device)\n",
    "    z_sample = odeint_adjoint(latent_ode_func, z0_sample, times,rtol=1e-2, atol=1e-2, method='rk4')\n",
    "    # decode the full latent trajectory to get p_theta(x | z)\n",
    "    mu_x, logvar_x = decoder(z_sample.unsqueeze(0))\n",
    "    sigma_x = torch.exp(0.5 * logvar_x).to(device)\n",
    "    p_theta_x = Independent(Normal(mu_x, sigma_x),1)\n",
    "    # get the mean trajectory\n",
    "    x_gen = mu_x.squeeze(0)\n",
    "    \n",
    "    # plot the generated trajectory\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.plot(x_gen[:,0].detach().cpu().numpy(), x_gen[:,1].detach().cpu().numpy(), marker='x', label='Generated Trajectory', alpha=0.8)\n",
    "    ax.set_xlabel(\"X axis\")\n",
    "    ax.set_ylabel(\"Y axis\")\n",
    "    ax.set_title(f\"Generated Sample {i+1} from Prior\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149425f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "torchy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
