@misc{nalisnick_detecting_2019,
	title = {Detecting {Out}-of-{Distribution} {Inputs} to {Deep} {Generative} {Models} {Using} {Typicality}},
	url = {http://arxiv.org/abs/1906.02994},
	doi = {10.48550/arXiv.1906.02994},
	abstract = {Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data (Nalisnick et al., 2019; Choi et al., 2019). We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density. In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed. To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods. The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated. We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. (2019).},
	urldate = {2025-01-19},
	publisher = {arXiv},
	author = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Lakshminarayanan, Balaji},
	month = oct,
	year = {2019},
	note = {arXiv:1906.02994},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
}

@misc{bergamin_model-agnostic_2022,
	title = {Model-agnostic out-of-distribution detection using combined statistical tests},
	url = {http://arxiv.org/abs/2203.01097},
	doi = {10.48550/arXiv.2203.01097},
	abstract = {We present simple methods for out-of-distribution detection using a trained generative model. These techniques, based on classical statistical tests, are model-agnostic in the sense that they can be applied to any differentiable generative model. The idea is to combine a classical parametric test (Rao's score test) with the recently introduced typicality test. These two test statistics are both theoretically well-founded and exploit different sources of information based on the likelihood for the typicality test and its gradient for the score test. We show that combining them using Fisher's method overall leads to a more accurate out-of-distribution test. We also discuss the benefits of casting out-of-distribution detection as a statistical testing problem, noting in particular that false positive rate control can be valuable for practical out-of-distribution detection. Despite their simplicity and generality, these methods can be competitive with model-specific out-of-distribution detection algorithms without any assumptions on the out-distribution.},
	urldate = {2025-01-19},
	publisher = {arXiv},
	author = {Bergamin, Federico and Mattei, Pierre-Alexandre and Havtorn, Jakob D. and Senetaire, Hugo and Schmutz, Hugo and Maaløe, Lars and Hauberg, Søren and Frellsen, Jes},
	month = mar,
	year = {2022},
	note = {arXiv:2203.01097},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
}

@misc{nalisnick_deep_2019,
	title = {Do {Deep} {Generative} {Models} {Know} {What} {They} {Don}'t {Know}?},
	url = {http://arxiv.org/abs/1810.09136},
	doi = {10.48550/arXiv.1810.09136},
	abstract = {A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data. A plethora of work has demonstrated that it is easy to find or synthesize inputs for which a neural network is highly confident yet wrong. Generative models are widely viewed to be robust to such mistaken confidence as modeling the density of the input features can be used to detect novel, out-of-distribution inputs. In this paper we challenge this assumption. We find that the density learned by flow-based models, VAEs, and PixelCNNs cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former. Moreover, we find evidence of this phenomenon when pairing several popular image data sets: FashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN. To investigate this curious behavior, we focus analysis on flow-based generative models in particular since they are trained and evaluated via the exact marginal likelihood. We find such behavior persists even when we restrict the flows to constant-volume transformations. These transformations admit some theoretical analysis, and we show that the difference in likelihoods can be explained by the location and variances of the data and the model curvature. Our results caution against using the density estimates from deep generative models to identify inputs similar to the training distribution until their behavior for out-of-distribution inputs is better understood.},
	urldate = {2025-01-19},
	publisher = {arXiv},
	author = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
	month = feb,
	year = {2019},
	note = {arXiv:1810.09136},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
}

@misc{girin_dynamical_2022,
	title = {Dynamical {Variational} {Autoencoders}: {A} {Comprehensive} {Review}},
	shorttitle = {Dynamical {Variational} {Autoencoders}},
	url = {http://arxiv.org/abs/2008.12595},
	doi = {10.48550/arXiv.2008.12595},
	abstract = {Variational autoencoders (VAEs) are powerful deep generative models widely used to represent high-dimensional complex data through a low-dimensional latent space learned in an unsupervised manner. In the original VAE model, the input data vectors are processed independently. Recently, a series of papers have presented different extensions of the VAE to process sequential data, which model not only the latent space but also the temporal dependencies within a sequence of data vectors and corresponding latent vectors, relying on recurrent neural networks or state-space models. In this paper, we perform a literature review of these models. We introduce and discuss a general class of models, called dynamical variational autoencoders (DVAEs), which encompasses a large subset of these temporal VAE extensions. Then, we present in detail seven recently proposed DVAE models, with an aim to homogenize the notations and presentation lines, as well as to relate these models with existing classical temporal models. We have reimplemented those seven DVAE models and present the results of an experimental benchmark conducted on the speech analysis-resynthesis task (the PyTorch code is made publicly available). The paper concludes with a discussion on important issues concerning the DVAE class of models and future research guidelines.},
	urldate = {2025-01-19},
	publisher = {arXiv},
	author = {Girin, Laurent and Leglaive, Simon and Bie, Xiaoyu and Diard, Julien and Hueber, Thomas and Alameda-Pineda, Xavier},
	month = jul,
	year = {2022},
	note = {arXiv:2008.12595},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{bergamin_model-agnostic_2022-1,
	title = {Model-agnostic out-of-distribution detection using combined statistical tests},
	url = {http://arxiv.org/abs/2203.01097},
	doi = {10.48550/arXiv.2203.01097},
	abstract = {We present simple methods for out-of-distribution detection using a trained generative model. These techniques, based on classical statistical tests, are model-agnostic in the sense that they can be applied to any differentiable generative model. The idea is to combine a classical parametric test (Rao's score test) with the recently introduced typicality test. These two test statistics are both theoretically well-founded and exploit different sources of information based on the likelihood for the typicality test and its gradient for the score test. We show that combining them using Fisher's method overall leads to a more accurate out-of-distribution test. We also discuss the benefits of casting out-of-distribution detection as a statistical testing problem, noting in particular that false positive rate control can be valuable for practical out-of-distribution detection. Despite their simplicity and generality, these methods can be competitive with model-specific out-of-distribution detection algorithms without any assumptions on the out-distribution.},
	urldate = {2025-01-19},
	publisher = {arXiv},
	author = {Bergamin, Federico and Mattei, Pierre-Alexandre and Havtorn, Jakob D. and Senetaire, Hugo and Schmutz, Hugo and Maaløe, Lars and Hauberg, Søren and Frellsen, Jes},
	month = mar,
	year = {2022},
	note = {arXiv:2203.01097},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
}

@misc{cai_hybrid_2023,
	title = {Hybrid {Variational} {Autoencoder} for {Time} {Series} {Forecasting}},
	url = {http://arxiv.org/abs/2303.07048},
	doi = {10.48550/arXiv.2303.07048},
	abstract = {Variational autoencoders (VAE) are powerful generative models that learn the latent representations of input data as random variables. Recent studies show that VAE can flexibly learn the complex temporal dynamics of time series and achieve more promising forecasting results than deterministic models. However, a major limitation of existing works is that they fail to jointly learn the local patterns (e.g., seasonality and trend) and temporal dynamics of time series for forecasting. Accordingly, we propose a novel hybrid variational autoencoder (HyVAE) to integrate the learning of local patterns and temporal dynamics by variational inference for time series forecasting. Experimental results on four real-world datasets show that the proposed HyVAE achieves better forecasting results than various counterpart methods, as well as two HyVAE variants that only learn the local patterns or temporal dynamics of time series, respectively.},
	urldate = {2025-01-19},
	publisher = {arXiv},
	author = {Cai, Borui and Yang, Shuiqiao and Gao, Longxiang and Xiang, Yong},
	month = mar,
	year = {2023},
	note = {arXiv:2303.07048},
	keywords = {Computer Science - Machine Learning},
}

@article{pincus_approximate_1991,
	title = {Approximate entropy as a measure of system complexity.},
	volume = {88},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.88.6.2297},
	doi = {10.1073/pnas.88.6.2297},
	abstract = {Techniques to determine changing system complexity from data are evaluated. Convergence of a frequently used correlation dimension algorithm to a finite value does not necessarily imply an underlying deterministic model or chaos. Analysis of a recently developed family of formulas and statistics, approximate entropy (ApEn), suggests that ApEn can classify complex systems, given at least 1000 data values in diverse settings that include both deterministic chaotic and stochastic processes. The capability to discern changing complexity from such a relatively small amount of data holds promise for applications of ApEn in a variety of contexts.},
	language = {en},
	number = {6},
	urldate = {2025-01-20},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Pincus, S M},
	month = mar,
	year = {1991},
	pages = {2297--2301},
}

@article{delgado-bonal_approximate_2019,
	title = {Approximate {Entropy} and {Sample} {Entropy}: {A} {Comprehensive} {Tutorial}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	shorttitle = {Approximate {Entropy} and {Sample} {Entropy}},
	url = {https://www.mdpi.com/1099-4300/21/6/541},
	doi = {10.3390/e21060541},
	abstract = {Approximate Entropy and Sample Entropy are two algorithms for determining the regularity of series of data based on the existence of patterns. Despite their similarities, the theoretical ideas behind those techniques are different but usually ignored. This paper aims to be a complete guideline of the theory and application of the algorithms, intended to explain their characteristics in detail to researchers from different fields. While initially developed for physiological applications, both algorithms have been used in other fields such as medicine, telecommunications, economics or Earth sciences. In this paper, we explain the theoretical aspects involving Information Theory and Chaos Theory, provide simple source codes for their computation, and illustrate the techniques with a step by step example of how to use the algorithms properly. This paper is not intended to be an exhaustive review of all previous applications of the algorithms but rather a comprehensive tutorial where no previous knowledge is required to understand the methodology.},
	language = {en},
	number = {6},
	urldate = {2025-01-20},
	journal = {Entropy},
	author = {Delgado-Bonal, Alfonso and Marshak, Alexander},
	month = jun,
	year = {2019},
	keywords = {approximate entropy, sample entropy, information theory, chaos theory},
	pages = {541},
}