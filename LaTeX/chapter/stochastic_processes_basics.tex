\chapter{Stochastic processes main theory}\label{sec:Stochastic_Processes}
    
% \section{Definition and properties of a stochastic process}

We posit the following in the rest of the doc, unless specified otherwise:
% \begin{tcolorbox}[colback=blue!5!white,colframe=black!75!black,title=]
\asum{Main assumptions}{
\begin{enumerate}
    \item $(\Omega, \mathcal{F}, \mathbb{P})$ is a probabilistic space, with $\Omega$ the universe, $\mathcal{F}$ the tribe ($\sigma$-algebra) of events, $\mathbb{P}$ a probability measure on $(\Omega,\mathbb{F})$.
    \item $(E, \mathbb{B}(E))$ is a measurable space, endowed with its Borelian $\sigma$-algebra. $E$ will sometimes be referred to as the \textit{state space}. It is typically the space where random variables will live, most of the time $(\mathbb{R}, \mathcal{B}(\mathbb{R})).$
    \item $T$ is the set of \textit{times}, typically $T = [0, a]$ with $a>0$, or $T=[0, +\infty[$.
\end{enumerate}
}

% \subsection{Intuition and definitions }

We view a stochastic process as a two-variable function from $T \times \Omega$ to $(E, \mathcal{B}(E))$:
\begin{align}
    X : T \times \Omega &\longrightarrow (E, \mathcal{B}(E)) \\
    (t, \omega) &\longmapsto X(t, \omega)
\end{align}

This leads to two complementary views:

\textbf{Stochastic process as a collection of random variables indexed by time}
We view $X$ as a collection of random variables $(X_t)_{t \in T}$:
\begin{align}
    \forall t \in T, X_t : \omega \mapsto X_t(\omega)
\end{align}
\begin{enumerate}
    \item Each random variable $X_t$ is defined on $(\Omega, \mathcal{F}, \mathbb{P}$
    \item In practice, only some events $A \in \mathcal{F}$ can occur during the times $[0, t] \in T$. We will note $\mathcal{F}_t$ the smallest $\sigma$-algebra that contains the set of events $A$ that can occur during $[0, t]$.
    \item As a result, $X_t$ must be $\mathcal{F}_t$-measurable.
\end{enumerate}
% }

An alternate view arises when we fix $\omega$ and allow $t \in T$:

\textbf{Stochastic process as a set of random trajectories}
We view $X$ as
\begin{align}
    X : \Omega &\longrightarrow \mathbb{R}^T \\
    \omega &\longmapsto X(\omega) : t \mapsto X(t,\omega)
\end{align}
\begin{enumerate}
    \item $\forall \omega \in \Omega$, $X(\omega) \in \mathbb{R}^T$ is a random trajectory from $T$ into $\mathbb{R}$
    \item $\mathbb{R}^T$ should be endowed with an appropriate $\sigma$-algebra.
\end{enumerate}

Those intuitions lead to a formal definition :

\defn{Stochastic process}{
A stochastic process $\textbf{X}$ is defined as:
\begin{align}
    X &= (\Omega, \mathcal{F}, (X_t)_{t \in T}, \mathbb{P}) \\
    &= (\Omega, \mathcal{F}, (\mathcal{F}_t)_{t \in T}, (X_t)_{t \in T}, \mathbb{P})
\end{align}
where:
    \begin{itemize}
        \item $\Omega$ is a set (universe of possibles).
        \item $\mathcal{F}$ is a $\sigma$-algebra of parts of $\Omega$
        \item $\mathbb{P}$ is a probability measure on $(\Omega, \mathcal{F})$
        \item $T \subset \mathbb{R}_+$ represents time
        \item $(\mathcal{F}_t)_{t \in T}$ is a \textbf{filtration}, ie an increasing family of sub-$\sigma$-algebras of $\mathcal{F}$ indexed by $t$ : $\forall 0 \leq s \leq t \in T$, $\mathcal{F}_s \subset \mathcal{F}_t \subset \mathcal{F}$.
        \item $(X_t)_{t \in T}$ is a family of RV defined on $(\Omega, \mathcal{F})$ with values in a measurable space $(E, \mathcal{E})$ or more simply $(E, \mathcal{B}(E))$ (set $E$ endowed with its Borelian $\sigma$-algebra).
        \item $(X_t)_{t \in T}$ is assumed \textbf{adapted to the filtration} $(\mathcal{F}_t)_{t \in T}$, meaning $\forall t \in T$, $X_t$ is $\mathcal{F}_t$-measurable
    \end{itemize}
}

Often, we will have $(E, \mathcal{B}(E)) = (\mathbb{R}^d, \mathcal{B}(\mathbb{R}^d))$, and $T = [0,a]$ or $T=[0, +\infty[$ or $T=\mathbb{N}$.

Other important notions:
\begin{itemize}
    \item \textbf{$\sigma$-algebra generated by a random variable}. Let $X : (\Omega, \mathcal{F}, \mathbb{P}) \rightarrow (E, \mathcal{E})$ a random variable. The $\sigma$-algebra generated by $X$ is the smallest $\sigma$-algebra that makes $X$-measurable. It is the set of "pre-images" of $\mathcal{B}(E)$ by $X$. Formally;
    \begin{align}
        \sigma(X) = \{ A = X^{-1}(B), B \in \mathcal{E} \}
    \end{align}
    \item \textbf{natural filtration of $(X_t)_{t \in T}$}. The set of $\mathcal{F}_t = \sigma(X_s, s \leq t), \forall t \in T$, ie the set of $\sigma$-algebras generated by the RV $X_s$ for $s \leq t$, is called the natural filtration of $(X_t)$
\end{itemize}

% \subsection{Other definitions and properties}

\defn{Finite dimension laws of a stochastic process}{
Let $X$ be a stochastic process, $I = \{t_1,t_2,...,t_n\}, t_1<t_2<...<t_n$ a finite part of $T$, and $X_I = (X_{t_1}, X_{t_2},...,X_{t_n}) \in E^I$ a random vector.

Then, the \textbf{law of the random vector $X_I$} is the probability measure $\mu_I$ image of $\mathbb{P}$ by $X_I : \Omega \rightarrow (E^I, \mathcal{B}(E^I))$
}

We also remind of Gaussian processes -with a view different from \cite{rasmussen_gaussian_2008}.

% \section{Gaussian vector and gaussian process}

\defn{Gaussian vector}{
Let $\xi = (X_1,X_2,...,X_n)$ be a \textbf{centered} random vector in $\mathbb{R}^n$ ($\mathbb{E}(\xi)=0$), verifying $\xi \in L^2(\Omega, \mathcal{F}, \mathbb{P})$ (ie $\forall i, \mathbb{E}(X_i^2)< \infty$). Let $\Gamma = \mathbb{E}(X_i X_j)\vert_{i,j}$ its covariance matrix (definite positive).

\textbf{$\xi$ is a Gaussian vector} iff, equivalently:
\begin{enumerate}
    \item $\forall a_1,a_2,...,a_n \in \mathbb{R}^n$, $\sum_{i=1}^n a_i X_i$ follows a normal law (ie is Gaussian)
    \item or : the characteristic function of $\xi$, $\Phi_\xi(t)=\mathbb{E}(e^{i<\xi \vert t>})$, can be written
    \begin{align*}
        \Phi_\xi(t)=e^{-\frac{1}{2}<t \vert \Gamma t>} \,\, (t \in \mathbb{R}^n)
    \end{align*}
\end{enumerate}
With notation $\xi \sim \mathcal{N}(0,\Gamma)$.

More generally,
\begin{align*}
    Z \sim \mathcal{N}(m,\Gamma) \iff \Phi_Z(t) = e^{i <m \vert t>} e^{-\frac{1}{2}<t \vert \Gamma t>}
\end{align*}
}

\defn{Gaussian Process}{
Let $X$ be a stochastic process taking its values in $E = \mathbb{R}^n$. 

\textbf{$X$ is said to be a Gaussian process iff all its finite dimension laws are Gaussian}.

If $X = (X_t)_{t\in T}$ is a real-valued Gaussian process ($E=\mathbb{R}$), we define $\forall s,t \in T$:
\begin{itemize}
    \item $m(t)= \mathbb{E}(X_t)$ is the \textbf{mean of the Gaussian process}
    \item $\Gamma(t,s)= \mathbb{E}((X_t-m(t))(X_s-m(s))$ is the \textbf{covariance of the Gaussian process}
\end{itemize}
}

Reciprocally,
\thmp{Existence of a Gaussian process}{
\textbf{Let} $m:T \rightarrow \mathbb{R}$, and $\Gamma : T \times T \rightarrow \mathbb{R}$ be two functions such that:
\[
\forall I = \{t_1,t_2,...,t_n\} \,\, \text{finite part of T} \,\, \Gamma_I = \Gamma(t_i,t_j)\vert_{i,j} \,\, \text{is \textbf{symetric definite positive}}
\]
\textbf{then} there exists a Gaussian process $X = (X_t)_{t \in T}$, that is unique at a near equivalence, such that:
\begin{align*}
\forall I = \{t_1,t_2,...,t_n\} \subset T, X_I &= \{ X_{t_1}, X_{t_2},...,X_{t_n}\} \sim \mathcal{N}(m_I, \Gamma_I), \,\, \\
m_I &= ( m(t_1), m(t_2),..., m(t_n))
\end{align*}
}{p19}

\textbf{We will not cover notion such as stopping times or martingales, even they are central in stochastic calculus}. Please refer to \cite{mouvement-brownien-calcul-ito} for a detailed presentation.

The foundational stochastic process for stochastic calculus is the \textbf{brownian motion}:

\defn{Brownian motion}{
A real-valued stochastic process $B = \brownian$ is called \textbf{Brownian motion} iff:
\begin{itemize}
    \item $B_0 = 0$ $\mathbb{P}$-a.s.
    \item $\forall 0 \leq s \leq t$, the random variable $B_t-B_s$ is independent from $\mathcal{F}_t$.
    \item $\forall 0 \leq s \leq t$, $B_t - B_s \sim \mathcal{N}(0,t-s)$
\end{itemize}
}

Meaning : the process $B$ starts from 0, its increments are independent from the past, and follow a centered normal law of variance equal to the length of the time interval.

When $(\mathcal{F}_t)_{t \geq 0}$ is the natural filtration of $(B_t)_{t \geq 0}$, $B$ is said to be a \textbf{natural Brownian motion}

A fundamental property of the Brownian motion is the following:

\thmp{Gaussian characterization of the Brownian motion}{
\begin{enumerate}
    \item Let $B = \brownian$ be a Brownian motion. Then $B$ verifies:
    \begin{itemize}
        \item $B_0 = 0$ $\mathbb{P}$-a.s.
        \item $\forall 0 \leq t_1 < t_2 < .. < t_n$, $(B_{t_1}, B_{t_2},...,B_{t_n})$ is a centered Gaussian vector.
        \item $\forall s,t \geq 0$, $\mathbb{E}(B_s B_t) = \text{min}(s,t)$
    \end{itemize}
    This means that $B$ is a real centered Gaussian process, of covariance function $\Gamma(t,s) = \text{min}(s,t)$
    \item Conversely, if $B$ verifies the three properties above, then $(\Omega, \mathcal{F}, (\tilde{\mathcal{F}}_t)_{t \geq 0}, (B_t)_{t \geq 0}, \mathbb{P})$ is a natural Brownian motion (with $(\tilde{\mathcal{F}}_t)_{t \geq 0}$ the natural filtration of the family $(B_t)_{t \geq 0})$.
\end{enumerate}
}{see \cite{mouvement-brownien-calcul-ito}}

A second fundamental property of the Brownian motion is that its \textbf{quadratic variation} is non-zero.
More formally,

\defn{Variations of a function}{
Let $f : [a,b] \rightarrow \mathbb{R}$ a function (with $a,b \in \mathbb{R}$).
Let $\pi = \{ a=t_0 < t_1 < ... < t_n = b \}$ a subdivision of $[a,b]$.

\begin{enumerate}
    \item The \textbf{variation of $f$ along $\pi$} is $V_{\pi}=\sum_{k=0}^{n-1} \vert f(t_{k+1}-f(t_k)\vert$
    \item The \textbf{total variation of $f$ on $[a,b]$} is $V_{[a,b]}^{\pi} = \underset{\pi}{\text{sup}}\, V_{\pi}$. $f$ is said to have a \textbf{bounded variation} if $V_{[a,b]}^{\pi} < \infty$.
    \item The \textbf{quadratic variation of $f$ along $\pi$} is $V_{\pi}^{(2)} = \sum_{k=0}^{n-1} \vert f(t_{k+1}-f(t_k)\vert^{2}$
    \item The \textbf{total quadratic variation of $f$ along $[a,b]$} is :
    \begin{align*}
    [f]_{a,b} &= \underset{\vert \pi \vert \rightarrow 0}{\text{lim}}\,\, V_{\pi}^{(2)} \\
    \text{with} \,\, \vert \pi \vert &= \underset{k}{\text{max}}\,\, \vert t_{k+1}-t_k \vert
    \end{align*}
    The total quadratic variation has a slightly different definition from the total variation.
\end{enumerate}
}

\thmp{Quadratic variation of a Brownian motion}{
Let $B = \brownian$ a Brownian motion. Then $\forall \,  0<s\leq t $
\begin{align}
    &\underset{\vert \pi \vert \rightarrow 0}{\text{lim}}\,\, V_{\pi}^{(2)} = t-s \,\, \text{in} \,\, L^{2} \\
    &\underset{\vert \pi \vert \rightarrow 0}{\text{lim}}\,\, \mathbb{E}\left( \vert V_{\pi}^{(2)} - (t-s) \vert^{2} \right) = 0
\end{align}
}{see \cite{mouvement-brownien-calcul-ito}}

The reader will refer to \cite{mouvement-brownien-calcul-ito} for proofs of existence, continuity, and nowhere-differentiability of the Brownian motion.

Last, we introduce the notion of \textbf{Markov Process}, which is a generalization of the Markov Chains to continuous time.

Intuitively, building on the discrete-time Markov chain, a \textbf{Markov Process} is a stochastic process in which the behavior at time $t$ given the information available up to time $s$ (with $0 < s < t$) depends only on the most recent past, ie the information at time $s$ only. 
    
    In other words, for $s < t, \in T$, the law of $X_t \vert \mathcal{F}_s$ depends only on $X_s$.
    
    The intuition is then:
    \asum{Intuition of a Markov Process}{
        The stochastic process $X$ is called a \textbf{Markov Process} if:\\        
        $\forall s,t \in T, \, s<t, \,\, \forall A \in \mathcal{B}_E, \,\, \mathbb{P}(X_t \in A \vert \mathcal{F}_s) = \mathbb{P}(X_t \in A \vert X_s)$
        }

    We note \textbf{the transition probability of, given a start from $x$ at time $s$, to reach $A \in \mathcal{B}_E$ at time $t$};
    \begin{align}
    \label{prob_trans_01}
        \mathbb{P}(X_t \in A \vert X_s=x) = P_{s,t}(x, A)
    \end{align}
    We see that $A \mapsto P_{s,t}(x,A)$ is a \textbf{probability measure} on $\mathcal{B}_E$, that we note:
    \begin{align}
        P_{s,t}(x,dy) : & \, \mathcal{B}_E \rightarrow [0,1] \\
        &\, A \mapsto P_{s,t}(x,A)
    \end{align}
    We now consider the space $\mathcal{C} = \{ f:E\rightarrow \mathbb{R}, \text{borelian, bounded} \}$, and the operator $P_{s,t}$ from $\mathcal{C}$ into $\mathcal{C}$ defined by:
    \begin{align}
        P_{s,t} : & \, \mathcal{C} \rightarrow \mathcal{C} \\
        &\, f \mapsto P_{s,t}f : x \mapsto P_{s,t}f(x) = \int_E P_{s,t}(x, dy)f(y) \\
        \label{prob_trans_02}
        P_{s,t}f(x) &= \int_E f(y) P_{s,t}(x, dy) = \mathbb{E}(f(X_t) \vert X_s=x)
    \end{align}
    Taking $f =  \mathbbm{1}_A$, we recover \ref{prob_trans_01} from \ref{prob_trans_02}.

   
    % \section{Transition kernels}

    We are now equipped to define:
    \defn{Transition kernels}{
        A family $(P_{s,t})_{s<t, \in T}$ of applications $(E, \mathcal{B}_E) \rightarrow [0,1]$ is said to be a family of \textbf{transition kernels} iff:
        \begin{itemize}
            \item $\forall s<t, \forall A \in \mathcal{B}_E, P_{s,t}(\bullet, A) : x \mapsto P_{s,t}(x,A)$ is measurable. 
            \item $\forall s<t, \forall x \in E, P_{s,t}(x, \bullet) : A \mapsto P_{s,t}(x,A)$ is a probability measure on $\mathcal{B}_E$.
            \item The \textbf{Chapman Kolmogorov} property holds:
            \begin{align}
                \label{chapman_kolmogorov}
                \forall x \in E, \forall A \in \mathcal{B}_E, \forall s<t<u, P_{s,u}(x,A) = \int_E P_{s,t}(x,dy)P_{t,u}(y,A)
            \end{align}
            That is : we start from $x$ at time $s$, we arrive at a random $y$ (with some probability distribution over $y$) at some intermediate time $t$, and then we start from $y$ to reach $A$ at time $u$.\\
            Considering $P_{s,t}$ as operators (\ref{prob_trans_02}), then Chapman-Kolmogorov writes:
            \begin{align}
                P_{s,u} = P_{s,t}P_{t,u}
            \end{align}
        \end{itemize}
        }

    And define a \textbf{Markov Process}:
    \defn{Markov Process}{
    A stochastic process $X$ is said to be a Markov Process with transition kernels $\{P_{s,t}; s,t \in T, s<t\}$ iff $\forall f:E \rightarrow \mathbb{R}$ Borelian and bounded, and $\forall s<t \in T$ we have:
    \begin{align}
        \label{markov_process_definition_equation}
        \mathbb{E}(f(X_t) \vert \mathcal{F}_s) = P_{s,t}f(X_s) \,\,\, \mathbb{P}-\text{a.s}
    \end{align}
    The transition kernels $P_{s,t}$ are also called transition probabilities.\\
    The law of $X_0$ is a probability measure $\nu$ over $\mathcal{B}_E$ defined by:
    \begin{align}
        \nu(A) = \mathbb{P}(X_0 \in A)
    \end{align}
    }
    and called \textbf{initial law of the process}.\\
    Again, if we take $f = \mathbbm{1}_A$, we recover $\mathbb{P}(X_t \in A \vert \mathcal{F}_s) = \mathbb{P}(X_t \in A \vert X_s)$.
    
    \defn{Homogeneous Markov Process}{
    A Markov Process $X$ is said to be $\textbf{homogeneous}$ if its transition kernels family $P_{s,t}$ depends only on $t-s$. ie:
    \begin{align}
        \forall s<t, P_{s,t} = P_{0,t-s} := P_{u}  \,\, (u=t-s).
    \end{align}    
    }

    We can now compute the finite dimension laws of a Markov Process:
    \thmp{Finite dimension laws of a Markov Process}{
    Let $X$ be a Markov Process of initial law $\nu$ and probability transitions $P_{s,t}$. For all finite sequence of times $0=t_0 < t_1 < ... < t_k$, and for all set of borelian bounded functions $f_i : E \rightarrow \mathbb{R}, 0 \leq i \leq k$, we have:
    \begin{align}
        \mathbb{E}(f_0(X_0)f_1(X_1)...f_k(X_{t_k})) &= \\
            \int_E \nu(dx_0)f(x_0) \int_E P_{0,t_1}(x_0,dx_1)f_1(x_1) ... \int_E P_{t_{k-1},t_k}(x_{k-1},dx_k)f_{k}(x_k)
    \end{align}
    And $\forall A_0,A_1,...,A_k \in \mathcal{B}_E$, with $f_i = \mathbbm{1}_{A_i}$:
    \begin{align}
            \mathbb{P}(X_0 \in A_0, X_1 \in A_1, ..., X_k \in A_k) &= \int_{A_0}\nu(dx_0) \int_{A_1} P_{0,t_1}(x_0,dx_1) ... \int_{A_k} P_{t_{k-1},t_k}(x_{k-1},dx_k)
    \end{align}
    }{see \cite{mouvement-brownien-calcul-ito} p92}

    
    % \section{Feller semi-group, infinitesimal generator}

    Let $(\mathcal{C}_o(E), \vert\vert \cdot \vert\vert_{\infty})$ be the Banach space \footnote[1]{Banach space : complete normed vector space} of functions $f:E \rightarrow \mathbb{R}$ continuous, s.t. $f \underset{\infty}{\rightarrow} 0$.\\
    Let $(P_t)_{t \geq 0}$ be a family of positive operators \footnote[2]{$f \geq 0 \implies P_tf \geq 0$}.

    \defn{Feller semi-group}{
    $(P_t)_{t \geq 0}$ is said to be a \textbf{Feller semi-group} if:
    \begin{itemize}
        \item $P_0=I_d$ and $\forall t\geq 0, \vert\vert P_t\vert\vert \leq 1$
        \item $\forall t, t' \geq 0, P_tP_{t'} = P_{t+t'}$
        \item $\forall f \in \mathcal{C}_o(E), \underset{t \downarrow 0}{\lim} \vert\vert P_t f - f \vert\vert_{\infty} = 0$
    \end{itemize}
    }
    An homogeneous Markov process on $E$ is said process of Feller if its semi-group is of Feller.

    \defn{Infinitesimal Generator}{
    $X$ a process of Feller. Let $f \in \mathcal{C}_o(E)$ be such that the limit below exists in $\mathcal{C}_o(E)$:
    \begin{align}
        \label{operator_defintion}
        \underset{t \downarrow 0}{\lim} \frac{1}{t}(P_tf - f) = Af
    \end{align}
    then $f$ is said to be in the domain $D_A$ of $A$ operator defined by \ref{operator_defintion}.\\
    \textbf{A is called infinitesimal generator of the semi-group $(P_t)_{t \geq 0}$}.\\
    Then we can write:
    \begin{align}
        \mathbb{E}(f(X_{s+h}\vert \mathcal{F}_s) = f(X_s) + hAf(X_s) + o(h)
    \end{align}
    where $o(h)$ depends only on $f$.
    }

    Regarding the Brownian motion, we have:
    \thmp{Semi-group of the Brownian motion}{
    Let $B = (\Omega, \mathcal{F}, (\mathcal{F}_t)_{t \in T}, ({B_t})_{t \in T}, \mathbb{P})$ be a Brownian motion on $\mathbb{R}$. 
    Then \textbf{B is an homogeneous Markov Process on $\mathbb{R}$}, of initial law $\nu = \delta_0$, and whose semi-group is given by (for any $f:E \rightarrow \mathbb{R}$ Borelian bounded):
    \begin{align}
        P_tf(x) = \int_{\mathbb{R}} \frac{1}{\sqrt{2 \pi t}}\exp \left( {-\frac{1}{2}\frac{(x-y)^2}{t}} \right) f(y)dy
    \end{align}\\
    Or equivalently:
    \begin{align}
        \forall A \in \mathcal{B}_\mathbb{R}, \,\, P_t(x,A) = \int_A \frac{1}{\sqrt{2 \pi t}}\exp \left( {-\frac{1}{2}\frac{(x-y)^2}{t}} \right)dy
    \end{align}
    That is, $P_t(x,dy)$ is the Gaussian measure centered in $x$, of variance $t$.
    }{see \cite{mouvement-brownien-calcul-ito} p93}