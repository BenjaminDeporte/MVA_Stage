{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273af21f",
   "metadata": {},
   "source": [
    "VAEs dynamiques : https://arxiv.org/abs/2008.12595\n",
    "\n",
    "# Training Deep Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f61dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tests.unit_tests import test_brick_1, test_brick_2, test_brick_3, test_brick_4, test_brick_5, test_brick_6\n",
    "# from libs.dkf import DeepKalmanFilter, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eba1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484759d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49afe4e",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b08db",
   "metadata": {},
   "source": [
    "### Structure SSM (Single State Model pour variables latentes + VAE pour observations):\n",
    "\n",
    "- $z_t$ variables latentes forment une chaîne de Markov, transition $p(z_t \\vert z_{t-1})$\n",
    "- $x_t$ observations, modèle $p_{\\theta_x}(x_t \\vert z_t)$\n",
    "- NB : pas de commande/input $u_t$ ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59c3e4",
   "metadata": {},
   "source": [
    "### Deep Kalman Filter :\n",
    "\n",
    "\\begin{align}\n",
    "p_{\\theta_z}(z_t \\vert z_{t-1}) &= \\mathcal{N}(z_t \\vert \\mu_{\\theta_z}(z_{t-1}), \\text{diag}(\\sigma_{\\theta_z}^{2}(z_{t-1}))) \\\\\n",
    "d_z(z_{t-1}) &= [ \\mu_{\\theta_z}(z_{t-1}), \\sigma_{\\theta_z}(z_{t-1}) ] \\\\\n",
    "p_{\\theta_x}(x_t \\vert z_{t}) &= \\mathcal{N}(x_t \\vert \\mu_{\\theta_x}(z_{t}), \\text{diag}(\\sigma_{\\theta_x}^{2}(z_{t}))) \\\\\n",
    "d_x(z_{t}) &= [ \\mu_{\\theta_x}(z_{t}), \\sigma_{\\theta_x}(z_{t}) ] \\\\\n",
    "\\end{align}\n",
    "\n",
    "où $d_x, d_z$ sont des réseaux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118ab0a",
   "metadata": {},
   "source": [
    "### Modèle inférence\n",
    "\n",
    "Le \"true posterior\" s'écrit :\n",
    "\\begin{align}\n",
    "p_{\\theta}(z_{1:T} \\vert x_{1:T}) &= \\prod_{t=1}^T p_{\\theta} (z_t \\vert z_{1:t-1}, x_{1:T} ) \\\\\n",
    "&= \\prod_{t=1}^T p_{\\theta} (z_t \\vert z_{t-1}, x_{t:T} )\n",
    "\\end{align}\n",
    "\n",
    "où la première écriture est l'application de la chain rule, et la deuxième est un résultat de D-séparation (latentes à dépendance Markovienne).\n",
    "\n",
    "On choisit comme approximation du posterior (=encodeur) une formulation calquée sur le vrai posterior :\n",
    "\n",
    "\\begin{align}\n",
    "q_{\\phi}(z_{1:T} \\vert x_{1:T}) &= \\prod_{t=1}^T q_{\\phi} (z_{t} \\vert z_{t-1}, x_{t:T})\n",
    "\\end{align}\n",
    "\n",
    "On voit que l'inférence prend en compte les observations futures $x_{t:T}$ (comme le Kalman smoother par exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ff007",
   "metadata": {},
   "source": [
    "# Implémentation de l'inférence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945b1b3",
   "metadata": {},
   "source": [
    "- **backward RNN** (dans les faits, un LSTM) pour encoder les $x_{t:T}$ par les hidden states $h_t$ : \n",
    "\n",
    "\\begin{align}\n",
    "h_t = \\text{LSTM}(h_{t+1}, x_t)\n",
    "\\end{align}\n",
    "\n",
    "- **combiner** (réseau MLP) pour aggréger $h_t$ et $z_{t-1}\n",
    "\n",
    "\\begin{align}\n",
    "g_t = \\text{Combiner}(h_t, z_{t-1})\n",
    "\\end{align}\n",
    "\n",
    "- **Encoder** (réseau MLP) pour inférer les paramètres du posterior:\n",
    "\n",
    "\\begin{align}\n",
    "e_z(g_t) &= [ \\mu_\\phi(g_t), \\sigma_\\phi(g_t)] \\\\\n",
    "q_\\phi(z_t \\vert g_t) &= \\mathcal{N}(z_t \\vert \\mu_{\\phi}(g_t), \\text{diag}(\\sigma_\\phi^2(g_t)))\n",
    "\\end{align}\n",
    "\n",
    "NB : il existe d'autres formulations du posterior approximé $q_\\phi$, qui peuvent faire intervenir un forward LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d1c6e0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f957c3",
   "metadata": {},
   "source": [
    "Le modèle s'entraîne en maximisant un ELBO, dont la formulation générique se simplifie dans le cas du DKF en :\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta, \\phi; X) &= \\sum_{t=1}^T \\mathbb{E}_{q_\\phi(z_t \\vert x_{1:T})} \\log(p_{\\theta_x}(x_t \\vert z_t)) -\n",
    "\\sum_{t=1}^T \\mathbb{E}_{q_\\phi(z_{t-1} \\vert x_{1:T})} \\text{D}_{\\text{KL}} \\left[ q_\\phi(z_t \\vert z_{t-1}, x_{t:T}) \\vert\\vert \n",
    "p_{\\theta_z}(z_t \\vert z_{t-1}) \\right]\n",
    "\\end{align}\n",
    "\n",
    "Les deux termes s'explicitent de la façon suivante (avec $D$ dimension de l'espace des observations) :\n",
    "\n",
    "\\begin{align}\n",
    "p_{\\theta_x}(x_t \\vert z_t) &= \\mathcal{N}(x_t \\vert \\mu_{\\theta_x}(z_t), \\text{diag}(\\sigma_{\\theta_x}^2(z_t))) \\\\\n",
    "\\log{p_{\\theta_x}(x_t \\vert z_t)} &= -\\frac{D}{2} \\log{2\\pi} - \\frac{1}{2}\\log{\\vert \\text{diag}(\\sigma_{\\theta_x}^2(z_t)) \\vert} - \n",
    "\\frac{1}{2} \\left[ (x_t - \\mu_{\\theta_x}(z_t))^T (\\text{diag}(\\sigma_{\\theta_x}^2(z_t)))^{-1} (x_t - \\mu_{\\theta_x}(z_t)) \\right] \\\\\n",
    "&= \\frac{1}{2} \\left( \\sum_{i=1}^D \\log{\\sigma_{\\theta_x}^2(z_t)}\\vert_{i} + (x_t - \\mu_{\\theta_x}(z_t))^T \\text{diag} \\frac{1}{\\sigma_{\\theta_x}^2(z_t)} (x_t - \\mu_{\\theta_x}(z_t)) \\right)\n",
    "\\end{align}\n",
    "\n",
    "Et la KL entre les deux Gaussiennes:\n",
    "\n",
    "\\begin{align}\n",
    "q_\\phi(z_t \\vert z_{t-1}, x_{t:T}) &= \\mathcal{N}(z_t \\vert \\mu_{\\phi}(g_t), \\text{diag}(\\sigma_\\phi^2(g_t))) \\\\\n",
    "p_{\\theta_z}(z_t \\vert z_{t-1}) &= \\mathcal{N}(z_t \\vert \\mu_{\\theta_z}(z_{t-1}), \\text{diag}(\\sigma_{\\theta_z}^{2}(z_{t-1}))) \\\\\n",
    "\\end{align}\n",
    "\n",
    "a une close form (avec $Z$ dimension de l'espace latent):\n",
    "\n",
    "\\begin{align}\n",
    "\\text{D}_{\\text{KL}}(q_\\phi \\vert\\vert p_{\\theta_z}) &= \\frac{1}{2} \\left[ \\text{Tr}(\\text{diag}(\\sigma_{\\theta_z}^{2})^{-1} \\text{diag}(\\sigma_\\phi^2) ) + (\\mu_{\\theta_z} - \\mu_\\phi)^T (\\text{diag}(\\sigma_{\\theta_z}^{2})^{-1}) (\\mu_{\\theta_z} - \\mu_\\phi) +\n",
    "\\log{\\frac{\\vert \\text{diag}(\\sigma_{\\theta_z}^{2})\\vert}{\\vert \\text{diag}(\\sigma_\\phi^2) \\vert} } \\right] \\\\\n",
    "&= \\frac{1}{2}\\left[ \\sum_{i=1}^Z \\log{\\sigma_{\\theta_z}^{2}}\\vert_i - \\sum_{i=1}^Z \\log{\\sigma_{\\phi}^{2}}\\vert_i +\n",
    " (\\mu_{\\theta_z} - \\mu_\\phi)^T \\text{diag}(\\frac{1}{\\sigma_{\\theta_z}^{2}}) (\\mu_{\\theta_z} - \\mu_\\phi) + \\sum_{i=1}^Z \\frac{\\sigma_{\\phi}^{2}\\vert_i} {\\sigma_{\\theta_z}^{2}\\vert_i} - Z \n",
    "\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a4e53",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcfdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 1 # Dimension of the observation space\n",
    "Z_DIM = 2 # Dimension of the latent space\n",
    "H_DIM = 16 # Dimension of the hidden state of the LSTM network(s)\n",
    "G_DIM = 2 # Dimension of the output of the combiner\n",
    "INTERMEDIATE_LAYER_DIM = 16 # Dimension of the intermediate layers of the MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951cab4",
   "metadata": {},
   "source": [
    "### Briques de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 1 : backward LSTM -----------------------------\n",
    "\n",
    "class BackwardLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Backward LSTM module.\n",
    "    Creates a unidirectional LSTM, with num_layers layers, hidden state\n",
    "    of dimension hidden_size, and input of dimension input_size.\n",
    "    The LSTM is used to process the input sequence in reverse order.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super(BackwardLSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,   # dimension of the observation space\n",
    "            hidden_size,  # dimension of the hidden state of the LSTM network\n",
    "            num_layers=num_layers, # number of layers of the LSTM network\n",
    "            batch_first=False, # using the default PyTorch LSTM implementation, expecting input shape (seq_len, batch, input_size)\n",
    "            bidirectional=False # unidirectional LSTM to start with\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the backward LSTM module. The sequence x\n",
    "        is reversed via a torch.flip operation, then passed through the LSTM.\n",
    "        The output sequence is reversed again to get the final output.\n",
    "        \n",
    "        Args:\n",
    "            x: input sequence\n",
    "            shape (seq_len, batch, input_size)\n",
    "        Returns:\n",
    "            out: output sequence\n",
    "            shape (seq_len, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        # Reverse the input sequence - axis 0 is the time axis here\n",
    "        x_reversed = torch.flip(x, [0])\n",
    "        # Pass through LSTM\n",
    "        # using initial hidden state and cell state as zeros\n",
    "        out, _ = self.lstm(x_reversed)\n",
    "        # Reverse the output sequence\n",
    "        out_reversed = torch.flip(out, [0])\n",
    "        # return output shape (seq_len, batch, hidden_size)\n",
    "        \n",
    "        return out_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 2 : combiner -----------------------------\n",
    "#\n",
    "# this combines the latent variable at time t-1\n",
    "# with the hidden state from the backward LSTM at time t,\n",
    "# to compute a t\n",
    "    # X_DIM = 1 # Dimension of the observation space\n",
    "    # Z_DIM = 16 # Dimension of the latent space\n",
    "    # H_DIM = 16 # Dimension of the hidden state of the LSTM network(s)\n",
    "    # G_DIM = 8 # Dimension of the output of the combiner\n",
    "    # INTERMEDIATE_LAYER_DIM = 16 # Dimension of the intermediate layers of the MLPsensor g at time t, that will be used\n",
    "# to compute the parameters of the approximate posterior distribution\n",
    "# of the latent variable\n",
    "#\n",
    "\n",
    "class CombinerMLP(nn.Module):\n",
    "    \"\"\"Combiner module. Takes the hidden state of the backward LSTM at time t\n",
    "    and the (sampled) latent variable at time t-1, to compute a tensor g at time t,\n",
    "    that will be used to compute the parameters of the approximate posterior\n",
    "    distribution of the latent variable.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, \n",
    "                 hidden_dim=H_DIM, \n",
    "                 output_dim=G_DIM,\n",
    "                 layers_dim = None,  # list of layers dimensions, without the input dimnesion, without the output dimension\n",
    "                 activation = 'tanh',\n",
    "                 inter_dim = INTERMEDIATE_LAYER_DIM,\n",
    "                 ):\n",
    "        \"\"\"Creates a combiner module, ie a MLP layer, to combine h_t (the output of the backward lstm at time t\n",
    "        and (sampled) z_t-1, the latent variable at time t-1.\n",
    "        The input_dimension is the sum of the latent dimension (dimension of z_t-1) and the hidden dimension\n",
    "        (dimension of h_t).\n",
    "        The output dimension is the dimension of the combiner output, which is a parameter.\n",
    "        The list of intermediate layers is passed in the list layers_dim.\n",
    "        The activation function is passed as a string, either 'tanh' or 'relu'. (default = 'tanh')\n",
    "        \n",
    "        Inputs:\n",
    "            latent_dim : dimension of the latent space\n",
    "            hidden_dim : dimension of the hidden state of the LSTM network\n",
    "            output_dim : dimension of the combiner output\n",
    "            layers_dim : list of layers dimensions, without the input dimension, without the output dimension\n",
    "            activation : activation function (default = 'tanh')\n",
    "            inter_dim : dimension of the intermediate layers (default = INTERMEDIATE_LAYER_DIM)\n",
    "        \"\"\"\n",
    "        super(CombinerMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        self.inter_dim = inter_dim\n",
    "        self.layers_dim = layers_dim\n",
    "        \n",
    "        if self.layers_dim is None:\n",
    "            self.layers_dim = [self.inter_dim] * 2\n",
    "        else:\n",
    "            self.layers_dim = layers_dim\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(self.layers_dim):\n",
    "            if i==0:  #first layer, latent_dim + hidden_dim => layers_dim[0]\n",
    "                layers.append(nn.Linear(latent_dim + hidden_dim, dim))\n",
    "            else:  # all other layers\n",
    "                layers.append(nn.Linear(self.layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "        # last layer : layers_dim[-1] => output_dim\n",
    "        layers.append(nn.Linear(self.layers_dim[-1], output_dim))\n",
    "            \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "            \n",
    "        \n",
    "    def forward(self, h, z):\n",
    "        \"\"\"\n",
    "        Forward pass of the combiner module.\n",
    "        The use of the combiner module is sequential, so there is no seq_len dimension.\n",
    "        \n",
    "        Args:\n",
    "            h: hidden state of the backward LSTM at time t\n",
    "            shape (batch, hidden_dim)\n",
    "            z: latent variable at time t-1\n",
    "            shape (batch, latent_dim)\n",
    "        Returns:\n",
    "            g: tensor g at time t\n",
    "            shape (batch, output_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Concatenate the hidden state and the latent variable on their dimension\n",
    "        x = torch.cat((h, z), dim=-1) # shape (batch, hidden_dim + latent_dim)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        g = self.mlp(x) # output shape (batch, output_dim)\n",
    "        \n",
    "        return g     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c62086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 3 : Encoder -----------------------------\n",
    "#\n",
    "# This computes the parameters of the approximate posterior distribution\n",
    "# of the latent vatiable at time t.\n",
    "# The approximate posterior distribution is a Gaussian distribution,\n",
    "# we use a MLP to compute the mean and the log of the variance.\n",
    "#\n",
    "\n",
    "class EncoderMLP(nn.Module):\n",
    "    \"\"\"Encoder module. \n",
    "    Computes the parameters of the approximate posterior\n",
    "    distribution of the latent variable at time t. \n",
    "    The approximate posterior distribution is a Gaussian distribution, we use a MLP to compute the mean\n",
    "    and the log of the variance.\n",
    "    The input variables are g_t (the output of the combiner module at time t) and\n",
    "    z_t-1 (the -sampled- latent variable at time t-1).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 combiner_dim=G_DIM, # Dimension of the combiner output\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 layers_dim = None, # Dimension of the MLP layers (without inout nor output)\n",
    "                 activation = 'tanh', # Activation function\n",
    "    ):\n",
    "        \"\"\"Creates the encoder module.\n",
    "        This is a MLP, that takes as input the combiner output g_t (combining h_t and z_t-1).\n",
    "        The input dimension is the combiner dimension.\n",
    "        The output dimension is the 2 * dimension of the latent space (mean, and log variance).\n",
    "        The list of intermediate layers is passed in the list layers_dim.\n",
    "        The activation function is passed as a string, either 'tanh' or 'relu'. (default = 'tanh')\n",
    "        \n",
    "        Inputs:\n",
    "            latent_dim : dimension of the latent space\n",
    "            combiner_dim : dimension of the combiner output\n",
    "            inter_dim : dimension of the intermediate layers (default = INTERMEDIATE_LAYER_DIM)\n",
    "            layers_dim : list of layers dimensions, without the input dimension, without the output dimension\n",
    "            activation : activation function (default = 'tanh')\n",
    "        \"\"\"\n",
    "        super(EncoderMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.combiner_dim = combiner_dim\n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        self.inter_dim = inter_dim\n",
    "        \n",
    "        if layers_dim is None:\n",
    "            self.layers_dim = [self.inter_dim] * 2\n",
    "        else:\n",
    "            self.layers_dim = layers_dim\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(self.layers_dim):\n",
    "            if i==0:\n",
    "                layers.append(nn.Linear(combiner_dim, dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(self.layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "            \n",
    "        # last layer is linear, no activation\n",
    "        layers.append(nn.Linear(self.layers_dim[-1], 2 * latent_dim)) \n",
    "                    \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, g):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder module.\n",
    "        Takes g_t (the output of the combiner module at time t) as input, returns the parameters of the\n",
    "        approximate posterior distribution of the latent variable at time t.\n",
    "        The encoder module is used sequentially, so there is no seq_len dimension.\n",
    "        The output is a tuple (mu, logvar), where mu is the mean of the approximate posterior distribution\n",
    "        and logvar is the log of the variance of the approximate posterior distribution.\n",
    "        \n",
    "        Args:\n",
    "            g: tensor g at time t\n",
    "            shape (batch, combiner_dim)\n",
    "            \n",
    "        Returns:\n",
    "            mu: mean of the approximate posterior distribution\n",
    "            shape (batch, latent_dim)\n",
    "            logvar: log of the variance of the approximate posterior distribution\n",
    "            shape (batch, latent_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass through MLP\n",
    "        out = self.mlp(g)\n",
    "        \n",
    "        # Split the output into mean and log variance\n",
    "        # each with shape (batch, latent_dim)\n",
    "        mu, logvar = out[:, :self.latent_dim], out[:, self.latent_dim:]\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2609c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 4 : Latent Space Transition -----------------------------       \n",
    "#\n",
    "# This computes the parameters of the transition distribution\n",
    "# of the latent variable at time t. Ie the prior distribution, \n",
    "# before inference.\n",
    "# The transition distribution is a Gaussian distribution,\n",
    "# we use a MLP to compute the mean and the log of the variance.\n",
    "#\n",
    "\n",
    "class LatentSpaceTransitionMLP(nn.Module):\n",
    "    \"\"\"Latent space transition module. \n",
    "    Computes the parameters of the transition distribution of the latent variable at time t (ie \"prior\").\n",
    "    The transition distribution is a Gaussian distribution, we use a MLP to compute the mean\n",
    "    and the log of the variance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 layers_dim = None, # Dimension of the MLP layers\n",
    "                 activation = 'tanh', # Activation function\n",
    "    ):\n",
    "        \"\"\"Creates the latent space transition MLP.\n",
    "        This is a MLP, that takes as input the -sampled- lagged latent variable z_t-1,\n",
    "        and computes the parameters of the transition distribution p(z_t|z_{t-1}).\n",
    "        The input dimension is the latent dimension.\n",
    "        The output dimension is the 2 * dimension of the latent space (mean, and log variance).\n",
    "        The list of intermediate layers is passed in the list layers_dim.\n",
    "        The activation function is passed as a string, either 'tanh' or 'relu'. (default = 'tanh')\n",
    "        Inputs:\n",
    "            latent_dim : dimension of the latent space\n",
    "            inter_dim : dimension of the intermediate layers (default = INTERMEDIATE_LAYER_DIM)\n",
    "            layers_dim : list of layers dimensions, without the input dimension, without the output dimension\n",
    "            activation : activation function (default = 'tanh')\n",
    "        \"\"\"\n",
    "        super(LatentSpaceTransitionMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        self.inter_dim = inter_dim\n",
    "        \n",
    "        if layers_dim is None:\n",
    "            layers_dim = [self.inter_dim]\n",
    "        self.layers_dim = layers_dim\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(self.layers_dim):\n",
    "            if i==0:\n",
    "                layers.append(nn.Linear(self.latent_dim, dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(self.layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "            \n",
    "        # last layer is linear, no activation\n",
    "        layers.append(nn.Linear(self.layers_dim[-1], 2 * self.latent_dim)) \n",
    "                    \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "               \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass of the latent space transition module.\n",
    "        This takes as input a whole set of lagged -sampled- latent variables z_t-1,\n",
    "        and computes the parameters of the transition distribution p(z_t|z_{t-1}) for each time step t.\n",
    "        \n",
    "        Args:\n",
    "            z: latent variables lagged(set of latent variables at time t-1)\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "            \n",
    "        Returns:\n",
    "            mu: means of the transition distribution\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "            logvar: log of the variances of the transition distribution\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass through MLP\n",
    "        out = self.mlp(z)\n",
    "        \n",
    "        # Split the output into mean and log variance\n",
    "        # each with shape (batch, latent_dim)\n",
    "        mu, logvar = out[:, :, :self.latent_dim], out[:, :, self.latent_dim:]\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 5 : Decoder (ie Observation Model) -----------------------------\n",
    "#\n",
    "# This computes the parameters of the distribution of \n",
    "# the observed variable 'x', given the latent variable 'z'.\n",
    "# The distribution is a Gaussian distribution,\n",
    "# we use a MLP to compute the mean and the log of the variance.\n",
    "#\n",
    "\n",
    "class DecoderMLP(nn.Module):\n",
    "    \"\"\"Decoder module. Computes the parameters of the distribution of the\n",
    "    observed variable 'x', given the latent variable 'z' sampled from the approximate\n",
    "    posterior distribution.\n",
    "    The distribution is a Gaussian distribution, we use a MLP to compute the mean and the log of\n",
    "    the variance.   \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 observation_dim=X_DIM, # Dimension of the observation space\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 layers_dim = None, # Dimension of the MLP layers\n",
    "                 activation = 'tanh', # Activation function\n",
    "    ):\n",
    "        \"\"\"Creates the decoder module.\n",
    "        This is a MLP, that takes as input a set of -sampled- latent variables z_t,\n",
    "        and computes the parameters of the distribution of the observed variable 'x'.\n",
    "        The input dimension is the latent dimension.\n",
    "        The output dimension is the 2 * dimension of the observation space (mean, and log variance).\n",
    "        The list of intermediate layers is passed in the list layers_dim.\n",
    "        The activation function is passed as a string, either 'tanh' or 'relu'. (default = 'tanh')\n",
    "        \n",
    "        Inputs:\n",
    "            latent_dim : dimension of the latent space\n",
    "            observation_dim : dimension of the observation space\n",
    "            inter_dim : dimension of the intermediate layers (default = INTERMEDIATE_LAYER_DIM)\n",
    "            layers_dim : list of layers dimensions, without the input dimension, without the output dimension\n",
    "            activation : activation function (default = 'tanh')\n",
    "        \"\"\"\n",
    "        super(DecoderMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.observation_dim = observation_dim\n",
    "        self.inter_dim = inter_dim\n",
    "        \n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        \n",
    "        if layers_dim is None:\n",
    "            layers_dim = [self.inter_dim] # one layer per default\n",
    "        self.layers_dim = layers_dim\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(self.layers_dim):\n",
    "            if i==0:\n",
    "                layers.append(nn.Linear(self.latent_dim, dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(self.layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "            \n",
    "        # last layer is linear, no activation\n",
    "        layers.append(nn.Linear(self.layers_dim[-1], 2 * self.observation_dim)) \n",
    "                    \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder module.\n",
    "        This takes as input the set of -sampled- latent variables z_t, and \n",
    "        computes the set of parameters of the distribution of the observed variable 'x'.\n",
    "        The decoder module is used after the sequential loop, so there is a seq_len dimension.\n",
    "        \n",
    "        Args:\n",
    "            z: latent variable at time t\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "        Returns:\n",
    "            mu: means of the distribution of the observed variable\n",
    "            shape (seq_len, batch, observation_dim)\n",
    "            logvar: log of the variances of the distribution of the observed variable\n",
    "            shape (seq_len, batch, observation_dim)\n",
    "        \"\"\"\n",
    "        # Pass through MLP\n",
    "        out = self.mlp(z)\n",
    "        \n",
    "        # Split the output into mean and log variance\n",
    "        # each with shape (batch, observation_dim)\n",
    "        mu, logvar = out[:, :, :self.observation_dim], out[:, :, self.observation_dim:]\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- brick 6 : Sampler with reparameterization trick -----------------------------\n",
    "#\n",
    "# This samples from a normal distribution of given mean and log variance\n",
    "# using the reparameterization trick.\n",
    "\n",
    "class Sampler(nn.Module):\n",
    "    \"\"\"Sampler module. Samples from a normal distribution of given mean and\n",
    "    log variance using the reparameterization trick.\n",
    "    \n",
    "    NB : to be replaced by batch of tf.distributions.Normal(mu, logvar) ?\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Sampler, self).__init__()\n",
    "        \n",
    "    def forward(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Forward pass of the sampler module.\n",
    "        \n",
    "        Args:\n",
    "            mu: mean of the distribution\n",
    "            shape (batch, dim)\n",
    "            logvar: log of the variance of the distribution\n",
    "            shape (batch, dim)\n",
    "            \n",
    "        Returns:\n",
    "            v: sampled variables\n",
    "            shape (batch, dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample from a normal distribution using the reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)  # standard deviation\n",
    "        eps = torch.randn_like(std)  # random noise\n",
    "        v = mu + eps * std  # sampled variables\n",
    "        \n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea75e3",
   "metadata": {},
   "source": [
    "# Class DeepKalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ddc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepKalmanFilter(nn.Module):\n",
    "    \"\"\"Deep Kalman Filter (DKF) module. Implements the DKF algorithm.\n",
    "    \n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "        \n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dim=X_DIM, # Dimension of the observation space\n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 hidden_dim=H_DIM, # Dimension of the hidden state of the LSTM network\n",
    "                 combiner_dim=G_DIM, # Dimension of the combiner output\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 activation='tanh', # Activation function\n",
    "                 num_layers=1, # Number of layers of the LSTM network\n",
    "                 device='cpu' # Device to use (cpu or cuda)\n",
    "                 ):\n",
    "        super(DeepKalmanFilter, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.combiner_dim = combiner_dim\n",
    "        self.inter_dim = inter_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # define the modules\n",
    "        \n",
    "        self.backward_lstm = BackwardLSTM(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        self.combiner = CombinerMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=self.combiner_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "            inter_dim=self.inter_dim\n",
    "        )\n",
    "        \n",
    "        self.encoder = EncoderMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            combiner_dim=self.combiner_dim,\n",
    "            inter_dim=self.inter_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "        )\n",
    "        \n",
    "        self.latent_space_transition = LatentSpaceTransitionMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            inter_dim=self.inter_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "        )\n",
    "        \n",
    "        self.decoder = DecoderMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            observation_dim=self.input_dim,\n",
    "            inter_dim=self.inter_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "        )\n",
    "        \n",
    "        self.sampler = Sampler()\n",
    "        \n",
    "    def forward(self, x_t):\n",
    "        # \"\"\"Forward pass of the Deep Kalman Filter.\n",
    "        # Runs one step inference :\n",
    "        # 0- Initialization are run (sampled latent variable)\n",
    "        # 1- The input sequence x_t (seq_len, batch, input_dimension) is passed through the backward LSTM \n",
    "        #    to get the hidden states h_t (seq_len, batch, hidden_dim).\n",
    "        # 2- A sequential loop is run from time t=1 to t=T (seq_len):\n",
    "        #     2.1- the sampled latent variable at previous time step z_t-1, and the hidden state h_t, are run\n",
    "        #          through the combiner module to get the tensor g_t.\n",
    "        #     2.2- the tensor g_t is passed through the encoder module to get the parameters of the approximate posterior \n",
    "        #          distribution mu_phi and logvar_phi of the latent variable z_t.\n",
    "        #     2.3- the  latent variable z_t at time t is sampled from the approximate posterior distribution\n",
    "        #          using the reparameterization trick. The sampled latent variable z_t is stored in the sequence of\n",
    "        #          sampled latent variables z_t_s.\n",
    "        # 3- The whole sequence of sampled latent variables z_t_s is passed through the decoder module\n",
    "        #    to get the parameters of the distribution of the observed variables x_t.\n",
    "        # 4- The whole sequence of sampled latent variables z_t_s, lagged by one time step, is passed through the\n",
    "        #    transition module to get the parameters of the transition distribution of the latent variable z_t. \n",
    "        \n",
    "        # Args:\n",
    "        #     x_t: input sequence - shape (seq_len, batch, input_dim)\n",
    "            \n",
    "        # Intermediate variables:\n",
    "        #     sampled_z_t : sequence of sampled latent variables - shape (seq_len, batch, latent_dim).\n",
    "        #     NB : z_0 is set to 0.\n",
    "        #     h_t : hidden state of the backward LSTM at time t - shape (seq_len, batch, hidden_dim)\n",
    "            \n",
    "        # Returns:\n",
    "        #     mu_x_t: means of the distribution of the observed variables - shape (seq_len, batch, input_dim)\n",
    "        #     logvar_x_t: log of the variances of the distribution of the observed variables - shape (seq_len, batch, input_dim)\n",
    "        #     mu_phi_z_t: means of the approximate posterior distribution (q_\\phi) of the latent variable - shape (seq_len, batch, latent_dim)\n",
    "        #     logvar_phi_z_t: log of the variances of the approximate posterior distribution (q_\\phi) of the latent variable - shape (seq_len, batch, latent_dim)\n",
    "        #     mu_theta_z_t: means of the transition distribution (p_\\theta_z) of the latent variable - shape (seq_len, batch, latent_dim)\n",
    "        #     logvar_theta_z_t: log of the variances of the transition distribution (p_\\theta_z) of the latent variable - shape (seq_len, batch, latent_dim)\n",
    "        # \"\"\"\n",
    "        \n",
    "        # we assume that the input sequence is of shape (seq_len, batch, input_dim) and check some\n",
    "        seq_len, batch_size, input_dim = x_t.shape\n",
    "        assert input_dim == self.input_dim, f\"Input dimension {input_dim} does not match the expected dimension {self.input_dim}\"\n",
    "        \n",
    "        # initializations of the tensors for the sequential loop\n",
    "                # NB : in INRIA code : self.register_buffer\n",
    "                # \"If you have parameters in your model, which should be saved and restored in the state_dict, \n",
    "                # but not trained by the optimizer, you should register them as buffers.\n",
    "                # Buffers won’t be returned in model.parameters(), \n",
    "                # so that the optimizer won’t have a change to update them.#\n",
    "        sampled_z_t = torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device)\n",
    "        z0 = torch.zeros(batch_size, self.latent_dim).to(self.device)  # initial latent variable z_0\n",
    "        mu_phi_z_t = torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device)\n",
    "        logvar_phi_z_t = torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device)\n",
    "        \n",
    "        # step 1 : run the backward LSTM on the input sequence\n",
    "        # outputs are the hidden states, shape (seq_len, batch, hidden_dim)\n",
    "        h_t = self.backward_lstm(x_t)\n",
    "        \n",
    "        # step 2 : loop from t=1 to t=T (seq_len) to compute and sampled the latent variables z_t\n",
    "        for t in range(seq_len):\n",
    "            \n",
    "            # step 2.1 : at time t, get the sampled latent variable z_t-1 and the hidden state h_t\n",
    "            if t == 0:\n",
    "                sampled_z_t_1 = z0\n",
    "            else:\n",
    "                sampled_z_t_1 = sampled_z_t[t-1]\n",
    "            # combine them to compute g_t\n",
    "            g_t = self.combiner(h_t[t], sampled_z_t_1) # shpae is (batch_size, combiner_dim)\n",
    "            \n",
    "            # step 2.2 : compute the parameters of the approximate posterior distribution\n",
    "            mu_phi, logvar_phi = self.encoder(g_t) \n",
    "            mu_phi_z_t[t], logvar_phi_z_t[t] = mu_phi, logvar_phi\n",
    "            \n",
    "            # step 2.3 : sample z_t from the approximate posterior distribution and store it\n",
    "            sampled_z_t[t] = self.sampler(mu_phi, logvar_phi)\n",
    "            \n",
    "        # step 3 : compute the parameters of the observation distribution\n",
    "        mu_x_t, logvar_x_t = self.decoder(sampled_z_t)\n",
    "        \n",
    "        # step 4 : compute the parameters of the transition distribution\n",
    "        # form the lagged sampled latent variable z_t : z_t[0:seq_len-1]\n",
    "        lagged_sampled_z_t = torch.cat([z0.unsqueeze(0), sampled_z_t[:-1]])\n",
    "        mu_theta_z_t, logvar_theta_z_t = self.latent_space_transition(lagged_sampled_z_t) \n",
    "                        \n",
    "        # return the outputs\n",
    "        return x_t, mu_x_t, logvar_x_t, mu_phi_z_t, logvar_phi_z_t, mu_theta_z_t, logvar_theta_z_t\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        msg = f\"DeepKalmanFilter(input_dim={self.input_dim}, latent_dim={self.latent_dim}, hidden_dim={self.hidden_dim}, combiner_dim={self.combiner_dim}, inter_dim={self.inter_dim})\"\n",
    "        msg += f\"\\n{self.backward_lstm}\"\n",
    "        msg += f\"\\n{self.combiner}\"\n",
    "        msg += f\"\\n{self.encoder}\"\n",
    "        msg += f\"\\n{self.latent_space_transition}\"\n",
    "        msg += f\"\\n{self.decoder}\"\n",
    "        msg += f\"\\n{self.sampler}\"\n",
    "        \n",
    "        return msg\n",
    "    \n",
    "    def predict(self, x, num_steps):\n",
    "        \"\"\"\n",
    "        Predicts future steps based on the input sequence.\n",
    "\n",
    "        Args:\n",
    "            x_t (torch.Tensor): Input tensor of shape (seq_len, batch_size, x_dim).\n",
    "            num_steps (int): Number of future steps to predict.\n",
    "\n",
    "        Returns:\n",
    "            mu_predictions (torch.Tensor): Tensor of shape (num_steps, batch_size, x_dim)\n",
    "            containing the means of the predicted observations at future steps.\n",
    "            logvar_predictions (torch.Tensor): Tensor of shape (num_steps, batch_size, x_dim)\n",
    "            containing the log variances of the predicted observations at future steps.\n",
    "            \n",
    "            mu_full_x (torch.Tensor): Tensor of shape (seq_len + num_steps, batch_size, x_dim)\n",
    "            containing the reconstructed input sequence and the means of the predicted future steps.\n",
    "            logvar_full_x (torch.Tensor): Tensor of shape (seq_len + num_steps, batch_size, x_dim)\n",
    "            containing the log variances of the reconstructed input sequence and the predicted future steps.\n",
    "        \"\"\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # get hyperparameters\n",
    "            seq_len, batch_size, input_dim = x.shape\n",
    "            assert input_dim == self.input_dim, f\"Input dimension {input_dim} does not match the expected dimension {self.input_dim}\"\n",
    "            \n",
    "            # run an inference forward pass to get the parameters of the observation distribution,\n",
    "            # the approximate posterior distribution of the latent variable,\n",
    "            # and the transition distribution of the latent variable            \n",
    "            x_t, mu_x_t, logvar_x_t, mu_phi_z_t, logvar_phi_z_t, mu_theta_z_t, logvar_theta_z_t = self.forward(x)\n",
    "            \n",
    "            \n",
    "            # use mu_x_t as the first known values of reconstructed x\n",
    "            x_hat = mu_x_t\n",
    "            \n",
    "            # Then, start with the last inferred latent state\n",
    "            z_pred = mu_phi_z_t[-1:, :, :]\n",
    "\n",
    "            # Start to predict x at the end of the given sequence\n",
    "            mu_predictions = torch.zeros(num_steps, batch_size, self.input_dim).to(self.device)\n",
    "            logvar_predictions = torch.zeros(num_steps, batch_size, self.input_dim).to(self.device)\n",
    "            \n",
    "            for s in range(num_steps):\n",
    "                # Get the parameters (mean and variance) of the transition\n",
    "                # distribution p(z_t|z_{t-1})\n",
    "                z_pred_mean, z_pred_logvar = self.latent_space_transition(z_pred)\n",
    "\n",
    "                # Sample from p(z_t|z_{t-1}) distribution\n",
    "                z_pred = self.sampler(z_pred_mean, z_pred_logvar)\n",
    "                \n",
    "                # get the parameters of the predicted observation distribution\n",
    "                mu_x_pred, logvar_x_pred = self.decoder(z_pred)\n",
    "                \n",
    "                # store those parameters\n",
    "                mu_predictions[s,:,:] = mu_x_pred\n",
    "                logvar_predictions[s,:,:] = logvar_x_pred\n",
    "\n",
    "        # Append predictions to the reconstructed x\n",
    "        mu_full_x = torch.cat([x_hat, mu_predictions], dim=0)\n",
    "        logvar_full_x = torch.cat([logvar_x_t, logvar_predictions], dim=0)\n",
    "        \n",
    "        return mu_predictions, logvar_predictions, mu_full_x, logvar_full_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4654938",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff334c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x_t, mu_x_t, logvar_x_t, mu_phi_z_t, logvar_phi_z_t, mu_theta_z_t, logvar_theta_z_t, beta=None):\n",
    "    # \"\"\"\n",
    "    # Version 2.0 of the loss function for the Deep Kalman Filter.\n",
    "    # All distributions parameters are assumed to have been computed from K samples of each z_t.\n",
    "    # The K samples are used to compute the expectations within the loss function.\n",
    "\n",
    "    # Args:\n",
    "    #     x_t (tensor): the original input sequence - shape (seq_len, batch_size, x_dim)\n",
    "\n",
    "    #     mu_x_t (tensor): the mean of the distribution of the observed variable - shape (seq_len, batch_size, x_dim, K)\n",
    "    #     logvar_x_t (tensor): the log of the variance of the distribution of the observed variable - shape (seq_len, batch_size, x_dim, K)\n",
    "    #     mu_phi_z_t (tensor): the mean of the approximate posterior distribution (q_\\phi) of the latent variable - shape (seq_len, batch_size, x_dim, K)\n",
    "    #     logvar_phi_z_t (tensor): the log of the variance of the approximate posterior distribution (q_\\phi) of the latent variable - shape (seq_len, batch_size, x_dim, K)\n",
    "    #     mu_theta_z_t (tensor): the mean of the transition distribution (p_\\theta_z) of the latent variable - shape (seq_len, batch_size, x_dim, K)\n",
    "    #     logvar_theta_z_t (tensor): the log of the variance of the transition distribution (p_\\theta_z) of the latent variable - shape (seq_len, batch_size, x_dim, K)\n",
    "\n",
    "    #     beta (float, optional): the weight of the KL divergence term in the loss function. Defaults to None.\n",
    "        \n",
    "    # Returns:\n",
    "    #     rec_loss (tensor): the reconstruction loss - shape (1,)\n",
    "    #     kl_loss (tensor): the KL divergence loss - shape (1,)\n",
    "    #     total_loss (tensor): the total loss - shape (1,)\n",
    "    # \"\"\"\n",
    "    \n",
    "    seq_len, batch_size, x_dim = x_t.shape\n",
    "    \n",
    "    # choose beta\n",
    "    if beta is None:\n",
    "        beta = 1.0\n",
    "        \n",
    "    # check whether there is a K dimension or not, add K=1 if none given\n",
    "    if mu_x_t.dim() == 3:\n",
    "        K = 1\n",
    "        mu_x_t = mu_x_t.unsqueeze(-1)\n",
    "        logvar_x_t = logvar_x_t.unsqueeze(-1)\n",
    "        mu_phi_z_t = mu_phi_z_t.unsqueeze(-1)\n",
    "        logvar_phi_z_t = logvar_phi_z_t.unsqueeze(-1)\n",
    "        mu_theta_z_t = mu_theta_z_t.unsqueeze(-1)\n",
    "        logvar_theta_z_t = logvar_theta_z_t.unsqueeze(-1)\n",
    "    else:\n",
    "        K = mu_x_t.shape[-1]\n",
    "        \n",
    "    z_dim = mu_phi_z_t.shape[-2]\n",
    "        \n",
    "    # compute the expectation of the reconstruction loss with K samples\n",
    "    \n",
    "    x_t_extended = x_t.unsqueeze(-1)  # (seq_len, batch_size, x_dim, K)\n",
    "    var_x = logvar_x_t.exp() # (seq_len, batch_size, x_dim, K)\n",
    "    \n",
    "    rec_loss = torch.div((x_t_extended - mu_x_t)**2, var_x)  # (seq_len, batch_size, x_dim, K) - x_t_extended is broadcasted along last axis\n",
    "    rec_loss += logvar_x_t # (seq_len, batch_size, x_dim, K)\n",
    "    \n",
    "    rec_loss = torch.mean(rec_loss, dim=3)  # Mean over the K samples - (seq_len, batch_size, x_dim)\n",
    "    rec_loss = torch.sum(rec_loss, dim=2)  # Sum over the x_dim - (seq_len, batch_size)\n",
    "    rec_loss = torch.sum(rec_loss, dim=0)  # Sum over the sequence length - (batch_size)\n",
    "    rec_loss = torch.mean(rec_loss)  # Mean over the batch - ()\n",
    "    \n",
    "    rec_loss = 1/2 * (rec_loss / seq_len)\n",
    "    \n",
    "    # compute the expectation of the KL divergence loss with K samples\n",
    "    \n",
    "    kl_loss = logvar_theta_z_t - logvar_phi_z_t  # (seq_len, batch_size, z_dim, K)\n",
    "    kl_loss += torch.div(logvar_phi_z_t.exp(), logvar_theta_z_t.exp()) # (seq_len, batch_size, z_dim, K)\n",
    "    kl_loss += torch.div((mu_theta_z_t - mu_phi_z_t).pow(2), logvar_theta_z_t.exp())\n",
    "    # kl_loss -= z_dim # shape (seq_len, batch_size, z_dim, K)\n",
    "       \n",
    "    kl_loss = torch.mean(kl_loss, dim=3)  # Mean over the K samples - (seq_len, batch_size, z_dim)\n",
    "    kl_loss = torch.sum(kl_loss, dim=2)  # Sum over the z_dim - (seq_len, batch_size)\n",
    "    kl_loss = torch.sum(kl_loss, dim=0)  # Sum over the sequence length - (batch_size)\n",
    "    kl_loss = torch.mean(kl_loss)  # Mean over the batch\n",
    "    \n",
    "    kl_loss = 1/2 * kl_loss / seq_len\n",
    "    \n",
    "    return rec_loss, kl_loss, rec_loss + beta * kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca53cc",
   "metadata": {},
   "source": [
    "# Toy Case : Data Generation for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ce750",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "n_ahead = 10\n",
    "n_series = 100\n",
    "\n",
    "def generate_time_series(batch_size, n_steps, noise=0.05):\n",
    "    \"\"\"Utility function to generate time series data.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): number of time series to generate (btach size)\n",
    "        n_steps (_type_): length of each time series\n",
    "    \"\"\"\n",
    "    \n",
    "    f1,f2,o1,o2 = np.random.rand(4, batch_size, 1)  # return 4 values for each time series\n",
    "    time = np.linspace(0, 1, n_steps)  # time vector\n",
    "    \n",
    "    series = 0.8 * np.sin((time - o1) * (f1 * 40 + 10)) # first sine wave\n",
    "    series += 0.2 * np.sin((time - o1) * (f1 * 20 + 20)) # second sine wave\n",
    "    series += noise * (np.random.randn(batch_size, n_steps) - 0.5)  # add noise\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64391527",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = generate_time_series(n_series, n_steps+n_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cdb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "fig, axs = plt.subplots(N, 1, figsize=(16, 3 * N))\n",
    "for i in range(N):\n",
    "    axs[i].plot(s[i], color='blue', marker=\"x\", linewidth=1)\n",
    "    axs[i].set_title(f\"Time series {i+1}\")\n",
    "    axs[i].set_xlabel(\"Time\")\n",
    "    axs[i].set_ylabel(\"Value\")\n",
    "    axs[i].grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(0.8 * n_series)\n",
    "\n",
    "X_train, y_train = s[:cutoff,:n_steps], s[:cutoff,n_steps:]\n",
    "X_valid, y_valid = s[cutoff:,:n_steps], s[cutoff:,n_steps:]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c067913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form datasets, dataloaders, etc\n",
    "\n",
    "BATCH_SIZE = 16   # 8192 ok sur RTX3080 et 150 time steps\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X).to(device)\n",
    "        self.y = torch.tensor(y).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "test_dataset = TimeSeriesDataset(X_valid, y_valid)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea0e76",
   "metadata": {},
   "source": [
    "# Baseline : RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelLookAhead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, n_ahead=n_ahead, num_layers=1, batch_first=True, device=device, dtype=dtype):\n",
    "        \"\"\"Constructor for RNN.\n",
    "\n",
    "        Args:\n",
    "            input_dim (_type_): dimensionality of the input\n",
    "            hidden_dim (_type_): dimensionality of the hidden state\n",
    "            n_ahead (_type_, optional): number of time steps to predict. Defaults to N_AHEAD.\n",
    "            output_dim (_type_, optional): dimensionality of the output.\n",
    "            num_layers (int, optional): number of recurrent layers. Defaults to 1.\n",
    "            batch_first (bool, optional): whether batch dim is first or not. Defaults to True.\n",
    "                1. batch_first=True: (batch, seq, feature_dimension)\n",
    "                2. batch_first=False: (seq, batch, feature_dimension)\n",
    "            bidirectional (bool, optional): if True, becomes a bidriectional RNN. Defaults to False.\n",
    "                1. bidirectional=True: num_directions=2, (batch, seq, hidden_dim * 2)\n",
    "                2. bidirectional=False: num_directions=1, (batch, seq, hidden_dim)\n",
    "            device (_type_, optional): _description_. Defaults to device.\n",
    "            dtype (_type_, optional): _description_. Defaults to dtype.\n",
    "        \"\"\"\n",
    "        super(RNNModelLookAhead, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = False\n",
    "        self.n_ahead = n_ahead\n",
    "        \n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=batch_first,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, n_ahead*output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # first, initialize the hidden state\n",
    "        h0 = torch.zeros((self.num_layers, x.size(0), self.hidden_dim), requires_grad=True).to(device)\n",
    "        # INPUT : x : (batch, sequence_length, input_feature_dimension)\n",
    "        x, _ = self.rnn(x, h0) \n",
    "        # OUTPUT: \n",
    "        # - output : (batch, sequence_length, hidden_dimension * num_directions)\n",
    "        # - h_n : (num_layers * num_directions, batch, hidden_dimension) (hidden state for last time step)\n",
    "        x = self.fc(x[:, -1, :])  # take the last time step\n",
    "        x = x.view(-1, self.n_ahead, self.output_dim)\n",
    "        # OUTPUT: x : (batch, output_dimension)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949607b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNNModelLookAhead(\n",
    "    input_dim=1,\n",
    "    output_dim=1,\n",
    "    n_ahead=n_ahead,\n",
    "    hidden_dim=128,\n",
    "    num_layers=4,\n",
    "    batch_first=True,\n",
    "    device=device,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dimensions\n",
    "\n",
    "x = torch.randn(BATCH_SIZE, 50, 1).to(device)\n",
    "y = rnn(x)\n",
    "print(f\"input shape: {x.shape}\")\n",
    "print(f\"output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_rnn(y, y_hat):\n",
    "    \"\"\"\n",
    "    Compute the loss for the RNN model.\n",
    "    \n",
    "    Args:\n",
    "        y: target values - shape is (seq_len, batch_size, output_dim)\n",
    "        y_hat: predicted values - shape is (seq_len, batch_size, output_dim)\n",
    "    Returns:\n",
    "        loss: MSE loss\n",
    "    \"\"\"\n",
    "    \n",
    "    seq_len = y.shape[0]\n",
    "    batch_size = y.shape[1]\n",
    "    output_dim = y.shape[2]\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = (y - y_hat)**2\n",
    "    # print(loss.shape)\n",
    "    loss = torch.sum(loss, dim=2)  # Sum over the output dimension\n",
    "    loss = torch.sum(loss, dim=0)  # Sum over the sequence length\n",
    "    loss = torch.sqrt(loss)  # Square root of the sum\n",
    "    loss = torch.mean(loss)  # Mean over the batch\n",
    "    loss = loss / seq_len\n",
    "    \n",
    "    return loss\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = loss_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e892aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "print(f\"Start training RNN model for {num_epochs} epochs\")\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # loop on training data\n",
    "    rnn.train()\n",
    "    optimizer.zero_grad()\n",
    "    ### loop on training data\n",
    "    epoch_loss = 0\n",
    "    for input, target in train_loader:\n",
    "        input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "        # print(f\"input has shape {input.shape}\")\n",
    "        target = target.to(device).view(-1, n_ahead, 1)\n",
    "        # print(f\"target has shape {target.shape}\")\n",
    "        output = rnn(input)\n",
    "        # print(F\"output has shape {output.shape}\")\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(train_loader) \n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # test step\n",
    "    rnn.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for input, target in test_loader:\n",
    "            input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "            target = target.to(device).view(-1, n_ahead, 1)\n",
    "            output = rnn(input)\n",
    "            loss = criterion(output, target)\n",
    "            epoch_loss += loss.item()\n",
    "    epoch_loss /= len(test_loader)\n",
    "    valid_losses.append(epoch_loss)\n",
    "    \n",
    "    # report out\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"epoch {i+1:>4}/{num_epochs}, training loss = {train_losses[-1]:.4e}, validation loss = {valid_losses[-1]:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f32d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 3))\n",
    "ax.plot(train_losses, label=\"train\")\n",
    "ax.plot(valid_losses, label=\"valid\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_xticks(np.arange(0, num_epochs+1, 10))\n",
    "ax.set_xticklabels(np.arange(0, num_epochs+1, 10))\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training and Validation Loss\")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rnn(torch.tensor(X_valid).to(device).unsqueeze(-1))\n",
    "y_target = torch.tensor(y_valid).to(device).unsqueeze(-1)\n",
    "\n",
    "# print(f\"y_target shape: {y_target.shape}\")\n",
    "# print(f\"y_pred shape: {y_pred.shape}\")\n",
    "\n",
    "print(f\"Loss finale = {criterion(y_pred, y_target):.4e}\")\n",
    "\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "y_target = y_target.cpu().detach().numpy()\n",
    "\n",
    "# print(f\"\\n{np.mean(np.sqrt((y_target - y_pred) ** 2)):.4f} RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc467d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "fig, ax  = plt.subplots(N, 1, figsize=(14, 2 * N))\n",
    "x_shift = X_valid.shape[-1]\n",
    "\n",
    "for i in range(N):\n",
    "    input = torch.tensor(X_valid[i], device=device).unsqueeze(0).unsqueeze(-1)\n",
    "    # input = input.permute(1, 0, 2)  # permute to (seq_len, batch_size, input_dim)\n",
    "    # print(f\"input has shape {input.shape}\")\n",
    "    target = torch.tensor(y_valid[i], device=device).view(-1, n_ahead, 1)\n",
    "    # target = target.permute(1, 0, 2)  # permute to (seq_len, batch_size, output_dim)\n",
    "    # print(f\"target has shape {target.shape}\")\n",
    "    output = rnn(input)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    # print(f\"output has shape {output.shape}\")\n",
    "    target = target.cpu().detach().numpy()\n",
    "    \n",
    "    ax[i].plot(input.squeeze().cpu().detach().numpy(), color='blue', marker=\"x\", linewidth=1, label=\"input\")\n",
    "    ax[i].plot(np.arange(len(target.squeeze()))+x_shift, target.squeeze(), color='red', marker=\"o\", linewidth=1, label=\"ground truth\")\n",
    "    ax[i].plot(np.arange(len(target.squeeze()))+x_shift, output.squeeze(), color='green', marker=\"*\", linewidth=1, label=\"prediction\")\n",
    "    ax[i].set_title(f\"Time series {i+1}\")\n",
    "    ax[i].set_xlabel(\"Time\")\n",
    "    ax[i].set_ylabel(\"Value\")\n",
    "    ax[i].legend()\n",
    "    ax[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54c5d6",
   "metadata": {},
   "source": [
    "# Training DKF - XP 1\n",
    "\n",
    "https://www.youtube.com/watch?v=rz76gYgxySo&list=WL&index=1&t=1618s&ab_channel=SimonLeglaive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb74eb9",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"/home/benjamin.deporte/MVA/MVA_Stage/DKF_Training.png\" width=\"1500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, criterion, train_loader=train_loader, device=device, beta=None, K=None):\n",
    "    ### training step\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    ### loop on training data\n",
    "    rec_loss = 0\n",
    "    kl_loss = 0\n",
    "    epoch_loss = 0\n",
    "    ### check on K\n",
    "    if K is None:\n",
    "        K=1\n",
    "        \n",
    "    x_dim = model.input_dim\n",
    "    latent_dim = model.latent_dim\n",
    "    \n",
    "    for input, _ in train_loader:\n",
    "        input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "        input = input.permute(1, 0, 2)  # permute to (seq_len, batch_size, input_dim)\n",
    "\n",
    "        \n",
    "        mu_x_t = torch.zeros(input.shape[0], input.shape[1], x_dim, K).to(device)\n",
    "        logvar_x_t = torch.zeros(input.shape[0], input.shape[1], x_dim, K).to(device)\n",
    "        mu_phi_z_t = torch.zeros(input.shape[0], input.shape[1], latent_dim, K).to(device)\n",
    "        logvar_phi_z_t = torch.zeros(input.shape[0], input.shape[1], latent_dim, K).to(device)\n",
    "        mu_theta_z_t = torch.zeros(input.shape[0], input.shape[1], latent_dim, K).to(device)\n",
    "        logvar_theta_z_t = torch.zeros(input.shape[0], input.shape[1], latent_dim, K).to(device)\n",
    "\n",
    "        # get K samples of the parameters of each distribution\n",
    "        for k in range(K):\n",
    "            # get the parameters of the distributions\n",
    "            _, mu_x_t[:, :, :, k], logvar_x_t[:, :, :, k], mu_phi_z_t[:, :, :, k], logvar_phi_z_t[:, :, :, k], mu_theta_z_t[:, :, :, k], logvar_theta_z_t[:, :, :, k] = model(input)\n",
    "        \n",
    "        rec_loss, kl_loss, total_loss = criterion(input, mu_x_t, logvar_x_t, mu_phi_z_t, logvar_phi_z_t, mu_theta_z_t, logvar_theta_z_t, beta=beta)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "              \n",
    "        rec_loss += rec_loss.item()\n",
    "        kl_loss += kl_loss.item()\n",
    "        epoch_loss += total_loss.item()\n",
    "        \n",
    "    epoch_loss /= len(train_loader)\n",
    "    rec_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    \n",
    "    return rec_loss, kl_loss, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test step : perform validation test for one epoch\n",
    "\n",
    "def test_step(model, optimizer, loss_fn, test_loader=test_loader, device=device, beta=None):\n",
    "    ### test step\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ### loop on test data\n",
    "        rec_loss = 0\n",
    "        kl_loss = 0\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for input, _ in test_loader:\n",
    "            input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "            input = input.permute(1, 0, 2)  # permute to (seq_len, batch_size, input_dim)\n",
    "\n",
    "            _, mu_x_s, logvar_x_s, mu_z_s, logvar_z_s, mu_z_transition_s, logvar_z_transition_s = model(input)\n",
    "            \n",
    "            rec_loss, kl_loss, total_loss = loss_fn(input, mu_x_s, logvar_x_s, mu_z_s, logvar_z_s, mu_z_transition_s, logvar_z_transition_s, beta=beta)\n",
    "                \n",
    "            rec_loss += rec_loss.item()\n",
    "            kl_loss += kl_loss.item()\n",
    "            epoch_loss += total_loss.item()\n",
    "            \n",
    "        epoch_loss /= len(train_loader)\n",
    "        rec_loss /= len(train_loader)\n",
    "        kl_loss /= len(train_loader)\n",
    "    \n",
    "    return rec_loss, kl_loss, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, num_epochs=100, beta=None, beta_scheduler=None, display_frequency=10, K=None):\n",
    "    \n",
    "    rec_losses = []\n",
    "    kl_losses = []\n",
    "    epoch_losses = []\n",
    "\n",
    "    val_rec_losses = []\n",
    "    val_kl_losses = []\n",
    "    val_epoch_losses = []\n",
    "    \n",
    "    if K is None:\n",
    "        K = 1\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        # use the beat scheduler if provided\n",
    "        if beta_scheduler is not None:\n",
    "            beta = beta_scheduler(i)\n",
    "        \n",
    "        # run the training step\n",
    "        rec_loss, kl_loss, epoch_loss = train_step(model, optimizer, loss_fn, beta=beta, K=K)\n",
    "        # log results\n",
    "        rec_losses.append(rec_loss)\n",
    "        kl_losses.append(kl_loss)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        # run test step\n",
    "        val_rec_loss, val_kl_loss, val_epoch_loss = test_step(model, optimizer, loss_fn, beta=beta)\n",
    "        # log results\n",
    "        val_rec_losses.append(val_rec_loss)\n",
    "        val_kl_losses.append(val_kl_loss)\n",
    "        val_epoch_losses.append(val_epoch_loss)\n",
    "        \n",
    "        # Print the losses for this epoch\n",
    "        if (i+1) % display_frequency == 0:\n",
    "            print(f\"Epoch {i+1:>5}/{num_epochs} with beta = {beta:.2e} - TRAINING : Rec Loss: {rec_loss:.4e}, KL Loss: {kl_loss:.4e}, Total Loss: {epoch_loss:.4e} - TEST : Rec Loss: {val_rec_loss:.4e}, KL Loss: {val_kl_loss:.4e}, Total Loss: {val_epoch_loss:.4e}\")\n",
    "            \n",
    "    return rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = 1\n",
    "latent_dim = 2\n",
    "h_dim = 16\n",
    "combiner_dim = 2\n",
    "num_layers_rnn = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkf = DeepKalmanFilter(\n",
    "    input_dim = xdim,\n",
    "    latent_dim = latent_dim,\n",
    "    hidden_dim = h_dim,\n",
    "    combiner_dim = combiner_dim,\n",
    "    num_layers = num_layers_rnn,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "print(dkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(dkf.parameters(), lr=1e-4)\n",
    "loss_fn = loss_function\n",
    "beta = 1e-3\n",
    "\n",
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23628e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "n_displays = 20\n",
    "display_frequency = int(num_epochs / n_displays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses = train(\n",
    "    dkf, optimizer, loss_fn, num_epochs=num_epochs, beta=beta, display_frequency=display_frequency, K=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses):\n",
    "    \n",
    "    # Plot the losses\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "    axs[0].plot(torch.tensor(rec_losses).cpu().detach(), label='Training', color='blue')\n",
    "    axs[0].plot(torch.tensor(val_rec_losses).cpu().detach(), label='Test', color='green')\n",
    "    axs[0].set_title('Reconstruction Loss')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    axs[1].plot(torch.tensor(kl_losses).cpu().detach(), label='Training', color='blue')\n",
    "    axs[1].plot(torch.tensor(val_kl_losses).cpu().detach(), label='Test', color='green')\n",
    "    axs[1].set_title('KL Loss')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    axs[2].plot(torch.tensor(epoch_losses).cpu().detach(), label='Training', color='blue')\n",
    "    axs[2].plot(torch.tensor(val_epoch_losses).cpu().detach(), label='Test', color='green')\n",
    "    axs[2].set_title('Total Loss')\n",
    "    axs[2].set_xlabel('Epochs')\n",
    "    axs[2].set_ylabel('Loss')\n",
    "    axs[2].legend()\n",
    "    axs[2].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d4f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30200725",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predictions(N_SAMPLES=3, model=dkf):\n",
    "    \n",
    "    idx = np.random.randint(0, len(X_valid), N_SAMPLES)\n",
    "    X_valid_subset = X_valid[idx]\n",
    "    y_valid_subset = y_valid[idx]\n",
    "    \n",
    "    fig, axs = plt.subplots(N_SAMPLES, 1, figsize=(16, 3 * N_SAMPLES))\n",
    "    for i in range(N_SAMPLES):\n",
    "        input = torch.tensor(X_valid_subset[i], device=device).unsqueeze(1).unsqueeze(2)\n",
    "        # print(f\"input shape : {input.shape}\")\n",
    "        target = torch.tensor(y_valid_subset[i], device=device)\n",
    "        target = target.cpu().detach().numpy()\n",
    "        mu_predictions, logvar_predictions, mu_full_x, logvar_full_x = model.predict(input, n_ahead)\n",
    "              \n",
    "        # display data\n",
    "        axs[i].plot(input.squeeze().cpu().detach().numpy(), color='blue', marker=\"x\", linewidth=1, label=\"input\")\n",
    "        axs[i].plot(np.arange(len(target))+n_steps, target, color='red', marker=\"o\", linewidth=1, label=\"ground truth\")\n",
    "        \n",
    "        # display predictions and credible intervals\n",
    "        all_times = np.arange(n_steps+n_ahead)\n",
    "        mu_full_x = mu_full_x.squeeze().cpu().detach().numpy()\n",
    "        logvar_full_x = logvar_full_x.squeeze().cpu().detach().numpy()\n",
    "        std_full_x = np.exp(logvar_full_x / 2)\n",
    "        \n",
    "        axs[i].scatter(all_times, mu_full_x, color='green', marker=\"*\", linewidth=1, label=\"reconstructed and predicted\")\n",
    "        axs[i].fill_between(all_times, mu_full_x-2*std_full_x, mu_full_x+2*std_full_x, color='orange', label='+/- 2 std', alpha=0.2)\n",
    "        \n",
    "        axs[i].set_title(f\"Time series {idx[i]}\")\n",
    "        axs[i].set_xlabel(\"Time\")\n",
    "        axs[i].set_ylabel(\"Value\")\n",
    "        axs[i].legend()\n",
    "        axs[i].grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a59a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predictions(N_SAMPLES=5, model=dkf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bb062",
   "metadata": {},
   "source": [
    "# XP 2\n",
    "\n",
    "$\\beta = 1.0$, n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7bec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = 1\n",
    "latent_dim = 2\n",
    "h_dim = 16\n",
    "combiner_dim = 2\n",
    "num_layers_rnn = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkf = DeepKalmanFilter(\n",
    "    input_dim = xdim,\n",
    "    latent_dim = latent_dim,\n",
    "    hidden_dim = h_dim,\n",
    "    combiner_dim = combiner_dim,\n",
    "    num_layers = num_layers_rnn,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "print(dkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(dkf.parameters(), lr=1e-4)\n",
    "loss_fn = loss_function\n",
    "beta = 1.0\n",
    "\n",
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "n_displays = 25\n",
    "display_frequency = int(num_epochs / n_displays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78099d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses = train(\n",
    "    dkf, optimizer, loss_fn, num_epochs=num_epochs, beta=beta, display_frequency=display_frequency, K=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predictions(N_SAMPLES=5, model=dkf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78867c9",
   "metadata": {},
   "source": [
    "# XP 3\n",
    "\n",
    "Réseau plus expressif, $\\beta = 1.0$, 500 epochs, K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = 1\n",
    "latent_dim = 8\n",
    "h_dim = 32\n",
    "combiner_dim = 4\n",
    "num_layers_rnn = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c06284",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkf = DeepKalmanFilter(\n",
    "    input_dim = xdim,\n",
    "    latent_dim = latent_dim,\n",
    "    hidden_dim = h_dim,\n",
    "    combiner_dim = combiner_dim,\n",
    "    num_layers = num_layers_rnn,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "print(dkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(dkf.parameters(), lr=1e-4)\n",
    "loss_fn = loss_function\n",
    "beta = 1.0\n",
    "\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "n_displays = 25\n",
    "display_frequency = int(num_epochs / n_displays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses = train(\n",
    "    dkf, optimizer, loss_fn, num_epochs=num_epochs, beta=beta, display_frequency=display_frequency, K=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predictions(N_SAMPLES=5, model=dkf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d929d",
   "metadata": {},
   "source": [
    "# Commentaires à ce stade :\n",
    "\n",
    "~~C1 - REVOIR LE TRAINING ! cf https://dynamicalvae.github.io/tuto_icassp2021/DVAE_tutorial.html (slide training DKF)~~\n",
    "\n",
    "Q1 - L'ELBO contient une expectation de KLs entre les vraies posterieures et les approximées. Une méthode est mentionnée p64 du papier de l'INRIA. \n",
    "\n",
    "#### Mon codage de la loss est-il correct ?\n",
    "\n",
    "Q2 - A priori plus de problème de stabilité ? Mais on constate un changement de régime pendant le training. Est-ce que cela correspond à un maximum d'expressivité du modèle ? Ou autre chose (ie $\\sigma_{\\theta_x} \\longrightarrow 0$?)\n",
    "\n",
    "Q3 - Je calcule la prédiction en utilisant la moyenne de $p_{\\theta_z}$ plutôt que celle de $q_\\phi$ ... Mais ça se discute ?\n",
    "\n",
    "Q4 - Comment arbitrer entre la KL et la reconstruction ? Piste 1 : faire un scheduler sur $\\beta$ ? (cf papiers plus bas)\n",
    "\n",
    "Q5 - Choix des différents paramètres ? Grid-search ? Early stopping + train till end of patience ? Autre ?\n",
    "\n",
    "Q6 - Influence de K ? (nombre de samples pour calculer les expectations dans la loss)\n",
    "\n",
    "Q7 - Architecture des réseaux : drop outs ? batch norms ? softplus pour sortir var plutôt qu'une linéaire pour sortir logvar ?\n",
    "\n",
    "Articles sur le sujet (biblio papier INRIA):\n",
    "- https://arxiv.org/pdf/1602.02282 (Ladder VAE)\n",
    "- https://arxiv.org/pdf/2007.03898 (NVAE: A Deep Hierarchical Variational Autoencoder)\n",
    "  \n",
    "Tuto (slides extrêmement bien faites):\n",
    "- https://dynamicalvae.github.io/tuto_icassp2021/DVAE_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261a001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50623dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eecadbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ebb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d468bf5e",
   "metadata": {},
   "source": [
    "## Piste 1 : Implementing a simple linear Beta scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1afb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaLinearScheduler():\n",
    "    \"\"\"Scheduler linéaire simple du beta, rapport entre la loss de reconstruction et la loss KL\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, beta_start=0.0, beta_end=1.0, num_epochs=100):\n",
    "        \"\"\"Constructeur\n",
    "\n",
    "        Args:\n",
    "            beta_start (float, optional): coefficient beta au démarrage. Defaults to 0.0.\n",
    "            beta_end (float, optional): coefficient beta en fin de schedule. Defaults to 1.0.\n",
    "            num_epochs (int, optional): nombre d'epochs sur lequel se fait l'évolution du beta. Defaults to 100.\n",
    "        \"\"\"\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "    def __call__(self, epoch):\n",
    "        \"\"\"Calcul du beta à l'epoch donnée\n",
    "\n",
    "        Args:\n",
    "            epoch (int): epoch courante\n",
    "\n",
    "        Returns:\n",
    "            float: beta\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.beta_start + (self.beta_end - self.beta_start) * (np.min([epoch, self.num_epochs]) / self.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fcac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dkf = DeepKalmanFilter(\n",
    "#     input_dim = xdim,\n",
    "#     latent_dim = latent_dim,\n",
    "#     hidden_dim = h_dim,\n",
    "#     combiner_dim = combiner_dim,\n",
    "#     num_layers = num_layers_rnn,\n",
    "#     device=device\n",
    "# ).to(device)\n",
    "\n",
    "# print(dkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(dkf.parameters(), lr=1e-3)\n",
    "# loss_fn = loss_function\n",
    "\n",
    "# num_epochs = 250\n",
    "# n_displays = 20  # nombre d'affichages souhaités\n",
    "# display_frequency = int(num_epochs / n_displays)\n",
    "\n",
    "# beta_scheduler = BetaLinearScheduler(beta_start=0.0, beta_end=1.0, num_epochs=50)  # warm up beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239568e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses = train(\n",
    "#     dkf, optimizer, loss_fn, num_epochs=num_epochs, beta_scheduler=beta_scheduler, display_frequency=display_frequency\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_losses(rec_losses, kl_losses, epoch_losses, val_rec_losses, val_kl_losses, val_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_predictions(N_SAMPLES=5, model=dkf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
