{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273af21f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "This is a notebook to describe the step by step logic of training a GP-VAE on dataset Sprites\n",
    "</div>\n",
    "\n",
    "VAEs dynamiques : https://arxiv.org/abs/2008.12595\n",
    "\n",
    "Papiers GP-VAE :\n",
    "- Deep Probabilistic Time Series Imputation https://arxiv.org/abs/1907.04155\n",
    "- Gaussian Process Prior Variational Autoencoders : https://arxiv.org/abs/1810.11738\n",
    "- Bayesian Gaussian Process Latent Variable Model : https://proceedings.mlr.press/v9/titsias10a/titsias10a.pdf\n",
    "- Markovian Gaussian Process Variational Autoencoders : https://arxiv.org/abs/2207.05543"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cd491",
   "metadata": {},
   "source": [
    "Imports and set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f61dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from libs.load_sprites import sprites_act\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "import timeit\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path to find the libs module\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "# print(f\"Added {parent_dir} to Python path\")\n",
    "# print(f\"Current working directory: {os.getcwd()}\")\n",
    "# print(f\"Python path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484759d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aafd025",
   "metadata": {},
   "source": [
    "# Sprites dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, A_train, A_test, D_train, D_test = sprites_act('data/sprites/', return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5254304",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = X_train[0,0,:]\n",
    "\n",
    "plt.imshow(e)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "N = X_train.shape[0]\n",
    "T = X_train.shape[1]\n",
    "N_SAMPLES = 5\n",
    "\n",
    "idx = np.random.choice(N, N_SAMPLES, replace=False)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=N_SAMPLES, ncols=T, figsize=(T*2, N_SAMPLES*2))\n",
    "\n",
    "for i, id_seq in enumerate(idx):\n",
    "    images = X_train[id_seq]\n",
    "    for t in range(T):\n",
    "        ax[i, t].imshow(images[t])\n",
    "        ax[i, t].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fa842",
   "metadata": {},
   "source": [
    "Dataset / Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f242328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form datasets and dataloaders for PyTorch training\n",
    "class CSRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "    \n",
    "train_dataset = CSRDataset(X_train)\n",
    "test_dataset = CSRDataset(X_test)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aedcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of outputs\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "x = next(train_iter).to(device)\n",
    "print(f\"loader shape : batch_size x 8 x 64 x 64 x 3 = {x.shape}\")  # should be (batch_size, T, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deba265",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090285be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the latent space\n",
    "Dz = 32\n",
    "\n",
    "# for encoder and decoder models\n",
    "hidden_dim = 256\n",
    "\n",
    "# Time stamps (B,T)\n",
    "t = torch.linspace(0, 1, x.size()[1]).to(device).unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "# Number of samples\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e8b34d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Encoder\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e17db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import EncoderCNN\n",
    "\n",
    "encoder = EncoderCNN(Dz=Dz, hidden_dim=hidden_dim).to(device)\n",
    "\n",
    "print(f\"encoder input shape : (B,T,64,64,3) = {x.shape}\")  # should be (batch_size, T, 64, 64, 3)\n",
    "\n",
    "mu_x, logcovar_x = encoder(x.to(device))\n",
    "\n",
    "print(\n",
    "    f\"encoder output shape :\\n\" \\\n",
    "    f\"\\tmean (B, T, Dz) = {mu_x.shape}\\n\" \\\n",
    "    f\"\\tlogcovar data (B,T,Dz) = {logcovar_x.shape}\")  # should be (batch_size, T, Dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0cc93",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Posterior\n",
    "</div>\n",
    "\n",
    "For a given time serie, the approximate posterior $q_{\\phi}$ is a set of $D_z$ independent -but not identical- multivariate Gaussians of dimension $N$. \n",
    "\n",
    "This encodes a temporal dependency over each dimension of the latent variables, but no dependency between dimensions.\n",
    "\n",
    "$q_{\\phi}$ is a tf.distribution.MultivariateNormal object with batch_shape = $(B, D_z)$ and event_shape = ($N$)\n",
    "\n",
    "\\begin{align}\n",
    "q_{\\phi}(z_{1:N} \\vert x_{1:N}) &= \\mathcal{N}(\\mu_{\\phi}(z_{1:N} \\vert x_{1:N}), \\Sigma_{\\phi}(z_{1:N} \\vert x_{1:N}))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16870c",
   "metadata": {},
   "source": [
    "Here we compute\n",
    "\n",
    "\\begin{align}\n",
    "q_{\\phi}(z_{1:N} \\vert x_{1:N}) &= \\mathcal{N}(\\mu_{\\phi}(z_{1:N} \\vert x_{1:N}), \\text{diag} \\,\\, \\sigma_{\\phi}^{2}(z_{1:N} \\vert x_{1:N}))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute a posterior over Dz independent multivariate Gaussians of dimension T\n",
    "mu_phi = mu_x.permute(0,2,1)  # (B, Dz, T)\n",
    "\n",
    "# assume diagonal covariance matrices for each of the Dz independent Gaussians here\n",
    "covar_phi = torch.diag_embed(torch.exp(logcovar_x).permute(0,2,1))  # (B, Dz, T, T) diagonal matrices\n",
    "\n",
    "q_phi = torch.distributions.MultivariateNormal(loc=mu_phi, covariance_matrix=covar_phi)\n",
    "\n",
    "print(f\"q_phi mean shape : (B,Dz,T) = {q_phi.mean.shape}\")  # should be (batch_size, Dz, T)\n",
    "print(f\"q_phi covar shape : (B,Dz,T,T) = {q_phi.covariance_matrix.shape}\")  # should be (batch_size, Dz, T, T)\n",
    "print(f\"q_phi batch shape : (B,Dz) = {q_phi.batch_shape}\")  # should be (batch_size,Dz)\n",
    "print(f\"q_phi event shape : (T) = {q_phi.event_shape}\")  # should be (T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517f764",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Gaussian Process priors\n",
    "</div>\n",
    "\n",
    "Each dimension $l$ of the latent variables (with $1 \\leq l \\leq D_z$) has a Gaussian Process prior over times:\n",
    "\n",
    "\\begin{align}\n",
    "z_l \\sim \\mathcal{GP}(m_l(.), k_l(.,.))\n",
    "\\end{align}\n",
    "\n",
    "The mean functions $m_l$ are usually constant null.\n",
    "\n",
    "The kernel functions $k_l(.,.)$ are a priori different along the dimensions. They encode the prior knowledge (if any) regarding the time series. They can either be fixed, or have learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc8abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import GaussianKernel, GaussianKernelFixed, MaternKernel, MaternKernelFixed, GPNullMean, GPConstantMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f564ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to form two lists of Dz kernel and mean functions (one per latent dimension)\n",
    "# can be handcrafted or built\n",
    "\n",
    "kernels_list = [ MaternKernelFixed(nu=1.5, lengthscale=1.0, sigma=1.0).to(device) for _ in range(Dz) ]  # list of Dz identical kernels\n",
    "mean_functions_list = [ GPNullMean().to(device) for _ in range(Dz) ]  # list of Dz identical mean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b36b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import compute_gp_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c937bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, kernel_matrix, L_matrix, p_theta_z = compute_gp_priors(t, Dz, kernels_list, mean_functions_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577b479",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Sampling from posterior\n",
    "</div>\n",
    "\n",
    "We sample $K$ samples from $q_{\\phi}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_samples = q_phi.rsample(sample_shape=(K,))  # (K, B, Dz, T)\n",
    "print(f\"z_samples shape : (K,B,Dz,T) = {z_samples.shape}\")  # should be (K, batch_size, Dz, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41bfe35",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Decoder\n",
    "</div>\n",
    "\n",
    "By D-separation, we know that the decoder factorizes :\n",
    "\n",
    "\\begin{align}\n",
    "p_{\\theta_x}(x_{1:N} \\vert z_{1:N}) &= \\prod_{i=1}^{N} p_{\\theta_x}(x_i \\vert z_i)\n",
    "\\end{align}\n",
    "\n",
    "We build a decoder with an inverse CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import DecoderCNN\n",
    "\n",
    "decoder = DecoderCNN(Dz=Dz, hidden_dim=hidden_dim).to(device)\n",
    "x_recon = decoder(z_samples.permute(0,1,3,2))  # (K,B,T,W=64,H=64,C=3)\n",
    "\n",
    "print(f\"x_recon shape : (K,B,T,W=64,H=64,C=3) = {x_recon.shape}\")  # should be (K, batch_size, T, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea0363",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Computing the loss\n",
    "</div>\n",
    "\n",
    "The loss is\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta_x, \\theta_z, \\phi, x_{1:N}) &= \\sum_{i=1}^N \\mathbb{E}_{z_i \\sim q_{\\phi}(z_i \\vert x_{1:N})} \\log{p_{\\theta_x}(x_i \\vert z_i)} - \\sum_{l=1}^{D_z} \\mathbb{KL} ( q_{\\phi}(z_l \\vert x_{1:N}) \\vert\\vert p_{\\theta_z}(z_{l,1:N})) \n",
    "\\end{align}\n",
    "\n",
    "Where the expectation $\\mathbb{E}_{z_i \\sim q_{\\phi}(z_i \\vert x_{1:N})}$ is approximated by averaging $K$ $p_{\\theta_x}$ samples, and the $\\mathbb{KL}$'s are computed analytically for two Gaussians.\n",
    "\n",
    "Remember that $p_{\\theta_x}$ is a tf.distributions.MVN object of batch_shape $(K,B,N)$ and event_shape $D_x$. We adapt the original data $x$ of shape $(B,N,Dx)$ accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start with the KL\n",
    "\n",
    "kl = torch.distributions.kl_divergence(q_phi, p_theta_z)  # (B, Dz)\n",
    "print(f\"KL between q_phi and p_theta_z tensor shape : (B,Dz) = {kl.shape}\")  # should be (batch_size, Dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05639c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then the reconstruction loss\n",
    "\n",
    "print(f\"Input x : shape : (B,T,64,64,3) = {x.shape}\")  # should be (batch_size, T, 64, 64, 3)\n",
    "print(f\"x min : {x.min().item():.4f}, x_max : {x.max().item():.4f}\")\n",
    "print(f\"Reconstructed x_recon : shape : (K,B,T,64,64,3) = {x_recon.shape}\")  # should be (K, batch_size, T, 64, 64, 3)\n",
    "print(f\"x_recon min : {x_recon.min().item():.4f}, x_recon max : {x_recon.max().item():.4f}\")\n",
    "\n",
    "reconstruction_error = (x - x_recon)**2  # (K,B,T,64,64,3)\n",
    "print()\n",
    "print(f\"reconstruction_error tensor shape : (K,B,T,64,64,3) = {reconstruction_error.shape}\")  # should be (K, batch_size, T, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8553dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use a cross entropy loss instead\n",
    "reconstruction_error_bce = F.binary_cross_entropy(x_recon, x.unsqueeze(0).repeat(K,1,1,1,1,1), reduction='none')  # (K,B,T,64,64,3)\n",
    "# print()\n",
    "# print(f\"reconstruction_error tensor shape : (K,B,T,64,64,3) = {reconstruction_error.shape}\")  # should be (K, batch_size, T, 64, 64, 3)\n",
    "\n",
    "print(f\"reconstruction_error BCE tensor shape : (K,B,T,64,64,3) = {reconstruction_error_bce.shape}\")  # should be (K, batch_size, T, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d730c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -reconstruction_error.mean() + kl.mean()\n",
    "print(f\"loss : {loss.item():.4f}\")\n",
    "\n",
    "loss.backward()  # backpropagate the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6988b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Training\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c54c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import EarlyStoppingCallback\n",
    "early_stopper = EarlyStoppingCallback(patience=100, min_delta=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1937c3",
   "metadata": {},
   "source": [
    "Assemble components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = 1.0  # time step between two frames if T=8 frames in [0,1]\n",
    "\n",
    "kernels_list = [ GaussianKernelFixed(lengthscale=(delta_t / (2**i)), sigma=1.0).to(device) for i in range(int(Dz/4)) ] + \\\n",
    "[ MaternKernelFixed(nu=0.5, lengthscale=(delta_t / (2**i)), sigma=1.0).to(device) for i in range(int(Dz/4)) ] +  \\\n",
    "[ MaternKernelFixed(nu=1.5, lengthscale=(delta_t / (2**i)), sigma=1.0).to(device) for i in range(int(Dz/4)) ] + \\\n",
    "[ MaternKernelFixed(nu=2.5, lengthscale=(delta_t / (2**i)), sigma=1.0).to(device) for i in range(int(Dz/4)) ]\n",
    "\n",
    "mean_functions_list = [ GPNullMean().to(device) for _ in range(Dz) ] # list of Dz identical mean functions\n",
    "mean, kernel_matrix, L_matrix, p_theta_z = compute_gp_priors(t, Dz, kernels_list, mean_functions_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a8133",
   "metadata": {},
   "source": [
    "Form parameters from the kernels and mean functions, if they are learnable, form the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderCNN(Dz=Dz, hidden_dim=hidden_dim).to(device)\n",
    "decoder = DecoderCNN(Dz=Dz, hidden_dim=hidden_dim).to(device)\n",
    "\n",
    "encfile = 'models/gpvae_encoder_gpvAE_sprites_current.pth'\n",
    "decfile = 'models/gpvae_decoder_gpvAE_sprites_current.pth'\n",
    "\n",
    "# with open(encfile, 'rb') as f:\n",
    "#     encoder.load_state_dict(torch.load(f))\n",
    "# with open(decfile, 'rb') as f:\n",
    "#     decoder.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import get_parameters_from_priors\n",
    "\n",
    "prior_params = get_parameters_from_priors(kernels_list, mean_functions_list)\n",
    "\n",
    "if prior_params:\n",
    "    learnable_prior = True\n",
    "else:\n",
    "    learnable_prior = False\n",
    "    \n",
    "print(f\"Learnable prior : {learnable_prior}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()) + prior_params,\n",
    "    lr = 1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import train_step, test_step, BetaThresholdScheduler\n",
    "\n",
    "beta_scheduler = BetaThresholdScheduler(\n",
    "    rec_loss_threshold=1.1e-2,  # keep KL weight to beta_start until reconstruction loss is below this threshold\n",
    "    beta_start=0.0,           # starting value of beta for the KL weight\n",
    "    beta_end=1.0,             # final value of beta for the KL weight\n",
    "    num_epochs=20           # number of epochs to linearly increase beta from beta_start to beta_end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    optimizer,  \n",
    "    prior,\n",
    "    learnable_prior,\n",
    "    device,\n",
    "    K,  \n",
    "    n_epochs=100,\n",
    "):\n",
    "    # log\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_kls = []\n",
    "    test_kls = []\n",
    "    train_rec_losses = []\n",
    "    test_rec_losses = []\n",
    "    \n",
    "    # early stopping\n",
    "    msg = \"no callback\"\n",
    "    \n",
    "    # beta management\n",
    "    test_epoch_rec_loss = np.inf\n",
    "    \n",
    "    # train the model for n_epochs epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # PRIOR pass --------------------------------------------------------------\n",
    "        # if the kernel is learnable, we need to recompute the prior mean and kernel at each epoch\n",
    "        if learnable_prior:\n",
    "            mean, kernel_matrix, L_matrix, prior = compute_gp_priors(t, Dz, kernels_list, mean_functions_list, verbose=False)\n",
    "            \n",
    "        # get beta update\n",
    "        # beta = beta_scheduler(epoch, test_epoch_rec_loss)\n",
    "        beta = 1.0\n",
    "        \n",
    "        # One train step\n",
    "        encoder, decoder, train_epoch_loss, train_epoch_kl, train_epoch_rec_loss = train_step(\n",
    "            train_loader,\n",
    "            encoder,\n",
    "            decoder,\n",
    "            optimizer,  \n",
    "            prior,\n",
    "            device,\n",
    "            K,\n",
    "            beta=beta\n",
    "        )\n",
    "        \n",
    "        train_losses.append(train_epoch_loss)\n",
    "        train_kls.append(train_epoch_kl)\n",
    "        train_rec_losses.append(train_epoch_rec_loss)\n",
    "        \n",
    "        # One test step\n",
    "        test_epoch_loss, test_epoch_kl, test_epoch_rec_loss = test_step(\n",
    "            test_loader,\n",
    "            encoder,\n",
    "            decoder,\n",
    "            prior,\n",
    "            device,\n",
    "            K,\n",
    "        )\n",
    "        \n",
    "        test_losses.append(test_epoch_loss)\n",
    "        test_kls.append(test_epoch_kl)\n",
    "        test_rec_losses.append(test_epoch_rec_loss)\n",
    "        \n",
    "        # save models every 10 epochs\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            torch.save(encoder.state_dict(), encfile)\n",
    "            torch.save(decoder.state_dict(), decfile)\n",
    "            print(f\"Saved encoder to {encfile} and decoder to {decfile} at epoch {epoch+1}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopper:\n",
    "            stop, counter = early_stopper.early_stop(test_epoch_loss)\n",
    "            if stop:\n",
    "                msg = f'Early stopping at epoch {epoch+1} with counter {counter}'\n",
    "                stop = True\n",
    "            else:\n",
    "                msg = f'Early stopping counter: {counter} / {early_stopper.patience}'\n",
    "        \n",
    "        # report out\n",
    "        print(f\"Epoch {epoch+1:<6} / {n_epochs:<6} - beta = {beta:.2f} -- TRAIN : total loss {train_epoch_loss:.4e}, KL: {train_epoch_kl:.4e}, Reco: {train_epoch_rec_loss:.4e} -- TEST : total loss {test_epoch_loss:.4e}, KL: {test_epoch_kl:.4e}, Reco: {test_epoch_rec_loss:.4e} -- {msg}\")\n",
    "        \n",
    "        # check overfit\n",
    "        if stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "        \n",
    "    return train_losses, test_losses, train_kls, test_kls, train_rec_losses, test_rec_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22254845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "mean, kernel_matrix, L_matrix, prior = compute_gp_priors(t, Dz, kernels_list, mean_functions_list, verbose=False)\n",
    "\n",
    "train_losses, test_losses, train_kls, test_kls, train_rec_losses, test_rec_losses = train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    optimizer,  \n",
    "    prior,\n",
    "    learnable_prior,\n",
    "    device,\n",
    "    K,  \n",
    "    n_epochs=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80d869",
   "metadata": {},
   "source": [
    "Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecea382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.gpvae_lib_sprites import report_out_losses\n",
    "\n",
    "report_out_losses(train_losses, test_losses, train_kls, test_kls, train_rec_losses, test_rec_losses, K)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433a751",
   "metadata": {},
   "source": [
    "Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Getting models with latent dimension: {Dz}\")\n",
    "# dim = f\"{Dz}\"\n",
    "\n",
    "# # load trained models\n",
    "# path = 'models/'\n",
    "\n",
    "# # save models\n",
    "# torch.save(encoder.state_dict(), path + f'gpvae_encoder_sprites_{dim}.pth')\n",
    "# torch.save(decoder.state_dict(), path + f'gpvae_decoder_sprites_{dim}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e193340",
   "metadata": {},
   "source": [
    "Load models id required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b56cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Getting models with latent dimension: {Dz}\")\n",
    "# dim = f\"{Dz}\"\n",
    "\n",
    "# # load trained models\n",
    "# path = 'models/'\n",
    "\n",
    "# encoder = EncoderCNN(Dz=Dz, hidden_dim=hidden_dim).to(device)\n",
    "# decoder = DecoderCNN(Dz=Dz, hidden_dim=hidden_dim).to(device)\n",
    "\n",
    "# with open(encfile, 'rb') as f:\n",
    "#     encoder.load_state_dict(torch.load(f))\n",
    "# with open(decfile, 'rb') as f:\n",
    "#     decoder.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1dc1f",
   "metadata": {},
   "source": [
    "Check reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69036ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 3\n",
    "\n",
    "# get samples from test set\n",
    "idx = np.random.choice(len(X_test), N_SAMPLES, replace=False)\n",
    "x_tests = X_test[idx]  # (N_SAMPLES, 8, 64, 64, 3)\n",
    "\n",
    "# compute posterior\n",
    "mu_x, logcovar_x = encoder(torch.tensor(x_tests, dtype=torch.float32).to(device))\n",
    "mu_phi = mu_x.permute(0,2,1)  # (N_SAMPLES, Dz, T)\n",
    "covar_phi = torch.diag_embed(torch.exp(logcovar_x).permute(0,2,1))  # (N_SAMPLES, Dz, T, T) diagonal matrices\n",
    "q_phi = torch.distributions.MultivariateNormal(loc=mu_phi, covariance_matrix=covar_phi)\n",
    "\n",
    "# set K\n",
    "K = 3\n",
    "\n",
    "# sample from posterior\n",
    "z_samples = q_phi.rsample(sample_shape=(K,))  # (K, N_SAMPLES, Dz, T)\n",
    "\n",
    "# decode\n",
    "x_recon = decoder(z_samples.permute(0,1,3,2))  # (K, N_SAMPLES, T, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5caaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display reconstructions\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    fig, ax = plt.subplots(nrows=(K+1), ncols=T, figsize=(T*2, K*3))\n",
    "    for t in range(T):\n",
    "        ax[0, t].imshow(x_tests[i,t])\n",
    "        ax[0, t].axis('off')\n",
    "        ax[0, t].set_title(f\"Original {i} t={t}\")\n",
    "    for k in range(K):\n",
    "        for t in range(T):\n",
    "            ax[k+1, t].imshow(x_recon[k,i,t].detach().cpu().numpy())\n",
    "            ax[k+1, t].axis('off')\n",
    "            ax[k+1, t].set_title(f\"Sample {k} t={t}\")\n",
    "    fig.suptitle(\"Top: original, below: reconstructions\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97597f2c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "Générations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ed403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of time steps we want to generate\n",
    "T = 10\n",
    "\n",
    "# form prior for T time steps\n",
    "t = torch.linspace(0, 1, T).to(device).unsqueeze(0).repeat(1, 1)  # (1, T)\n",
    "\n",
    "# compute prior\n",
    "mean, kernel_matrix, L_matrix, p_theta_z = compute_gp_priors(t, Dz, kernels_list, mean_functions_list, verbose=False)\n",
    "print(f\"Computed prior:\")\n",
    "print(f\"\\tmean shape: (1, Dz) = {p_theta_z.batch_shape}\")\n",
    "print(f\"\\tevent shape: (T) = {p_theta_z.event_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ff048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from prior\n",
    "# number of samples\n",
    "K = 5\n",
    "z_samples = p_theta_z.rsample(sample_shape=(K,))  # (K, Dz, T)\n",
    "print(f\"z_samples shape : (K,B,Dz,T) = {z_samples.shape}\")  # should be (K, Dz, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a672b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode from prior samples\n",
    "x_gen = decoder(z_samples.permute(0,1,3,2))  # (K,B,T,Dz) => (K,B,T,64,64,3)\n",
    "print(f\"x_gen shape : (K,B,T,64,64,3) = {x_gen.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display generations\n",
    "fig,axs = plt.subplots(nrows=K, ncols=T, figsize=(T*2, K*2))\n",
    "for k in range(K):\n",
    "    for t in range(T):\n",
    "        axs[k,t].imshow(x_gen[k,0,t].detach().cpu().numpy())\n",
    "        axs[k,t].axis('off')\n",
    "        axs[k,t].set_title(f\"Sample {k+1} @ t={t+1}\")\n",
    "fig.suptitle(\"Generations from prior\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
