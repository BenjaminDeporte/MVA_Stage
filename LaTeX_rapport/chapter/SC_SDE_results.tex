\chapter{Stochastic Differential Equations}\label{sec:SDE_results}

We use here the notations of \cite{sarkka_applied_2019} and recall the key results relevant to this report.

\section{Generic SDE}

A generic \textbf{stochastic differential equation} is defined as:

\defn{General Form of a Stochastic Differential Equation}{
    We define a \gls{sde} in dimension $D$.

    Let:
    \begin{itemize}
        \item $B$ be a Brownian motion $B_t \in \mathbb{R}^S$, of diffusion matrix $Q$
        \item $F$ be a deterministic function "drift" $F : \mathbb{R}^D \times \mathbb{R}\rightarrow \mathbb{R}^{D \times D}$
        \item $L$ be a deterministic function "dispersion" $L : \mathbb{R}^D \times \mathbb{R}\rightarrow \mathbb{R}^{D \times S}$ 
    \end{itemize}

    The \gls{sde} is:
    \begin{align}
        \label{generic_sde}
        dX_t &= F(X_t,t) dt + L(X_t,t) dB_t \\
        X_{t_0} &= X_0
    \end{align}
    where $X_0$ can be a scalar constant or a random variable.
    A stochastic process $X$ is said to be solution of \ref{generic_sde} if it verifies:
    \begin{align*}
        \forall t, \,\, X_t = X_0 + \int_{0}^{t} F(X_u, u)du + \int_{0}^{t} L(X_u,u) dB_u
    \end{align*}
}

As for \gls{ode}, a solution to \ref{generic_sde} might not exist. Also, results similar to Cauchy-Lipschitz 
exist for existence and unicity, based on assumptions on $F$ and $L$. 

Intuitively, we can see that an "infinitesimal increment" of $X_t$ to $X_{t+\Delta_t}$ verifies :
$\Delta {X_t} \approx F(X_t, t) \Delta t + L(X_t,t) dB_t$. But $dB_t$ is a Brownian increment independent of $X_{<t}$ (ie $\mathcal{F}_t$),
This suggests that $X_{t+ \Delta_t}$ depends on the past only by $X_t$. In other words, $X_t \vert \mathcal{F}_s = X_t \vert X_s$ 
for any $0 < s < t$. ie : \textbf{the solution of a \gls{sde} is a Markov process}. (The formal proof is given in \cite{mouvement-brownien-calcul-ito}.)

Formally, a Markov process is caracterized by its \textbf{transition kernels}. 
That is, for any $s < t$, and any $A \in \mathcal{B}_{\mathbb{R}^{D}}$, a Markov process verifies 
$\mathbb{P}(X_t \in A \vert \mathcal{F}_s) = \mathbb{P}(X_t \in A \vert X_s)$. And the transition kernels 
of $X$ are the applications $P_{s,t} : \mathbb{R}^{D} \times \mathcal{B}_{\mathbb{R}^{D}} \rightarrow [0,1]$, 
such that for any $f : \mathbb{R}^{D} \rightarrow \mathbb{R}$ measurable and bounded, we have:
\begin{align}
    P_{s,t}f(x) = \int_{{\mathbb{R}^{D}}} P_{s,t}(x,dy) f(y)
\end{align}

So $P_{s,t}$ actually is the probability measure of starting from $x$ at time $s$, and reach $y \in dy$ at time $t$.

When the transition kernels have densities $p(x,t \vert y,s)$ (ie starting from $y$ at time $s$, and
reaching $x$ at time $t$), then a fundamental result is the \textbf{Fokker Plank Kolmogorov} equation 
(also known as forward Kolomogorov) :
\begin{align}
    \label{FPK}
    \frac{\partial p}{\partial y} &= \mathcal{A}^{*}p \\
    \mathcal{A}^{*}(\bullet) &= - \sum_{i=1}^{D} \frac{\partial}{\partial x_i} (F_i(x,t)(\bullet)) + \
        \frac{1}{2} \sum_{i,j=1}^{D} \frac{\partial^{2}}{\partial x_i \partial x_j} (L(x,t)QL(x,t)^{T}\vert_{i,j} (\bullet))
\end{align}


The Fokker-Plank-Kolmogorov equation \ref{FPK} allows to derive -ordinary- differential equations for the moments 
of $X_t$ (see \cite{sarkka_applied_2019}). For the first two, defining
\begin{align}
    m(t) &= \mathbb{E}(X_t) \\
    P(t) &= \mathbb{E}((X_t - m(t))(X_t-m(t))^{T})
\end{align}

We have (NB : the expectations are taken w.r.t. $x$, ie the density probability $(p(x,t))$) :
\begin{align}
    \label{SDE_moments}
    \frac{dm}{dt} &= \mathbb{E}(F(x,t)) \\
    \frac{dP}{dt} &= \mathbb{E}(F(x,t)(x-m(t))^{T}) + \mathbb{E}((x-m(t)) F(x,t)^{T}) +\
    \mathbb{E}(L(x,t)QL(x,t)^{T})
\end{align}


\section{Linear SDE}

A particularly useful flavor of \gls{sde} is the linear \gls{sde}, that allows some close-form (or at least nicer) solutions:

\defn{Linear Stochastic Differential Equation}{
    With the same notaions as \ref{generic_sde}:

    The linear \gls{sde} is:
    \begin{align}
        \label{linear_sde}
        dX_t &= F(t) X_t dt + L(t) dB_t \\
        X_{t_0} &= X_0
    \end{align}
}

In this case, the transition kernels family can be characterized as:
\begin{align}
    \Psi &: \mathbb{R}^{2 } \rightarrow \mathbb{R}^{D} \\
    \frac{\partial \Psi (\tau, t)}{\partial \tau} &= F(\tau) \Psi(\tau, t) \\
    \frac{\partial \Psi (\tau, t)}{\partial t} &= - \Psi(\tau, t) F(t)  \\
    \Psi(\tau, t) &= \Psi(\tau, s) \Psi(s, t) \,\,\, (\text{Chapman-Kolmogorov}) \\
    \Psi(\tau, t) &= \Psi(t, \tau)^{-1} \\ 
    \Psi(t,t) &= I_d
\end{align}

And:
\prop{the solution to \ref{linear_sde} is:
\begin{align}
    \label{solution_linear_sde}
    X_t &= \Psi(t,t_0) X_0 + \int_{t_0}^{t} \Psi(t, \tau) L(\tau) dB_{\tau} \\
    X_{t_0} &= X_0
\end{align}
}

If $F$ is constant, we find : $X_t = \exp{F(t-t_0)}X_0 + \int_{t_0}^{t} \exp{F(t- \tau)}L(\tau)dB_{\tau}$

We see from the form of \ref{solution_linear_sde} that, when $X_0$ is Gaussian, then $X_t$ is a linear combination of 
independent Gaussian random variables, therefore Gaussian. ie : \textbf{the solution of a linear SDE is a Gaussian process}.

In this case, the first two moments of $X_t$ are enough to fully describe the solution. The equations \ref{SDE_moments} simplify into:
\begin{align}
    \label{SDE_linear_moments}
    \frac{dm}{dt} &= F(t) m(t) \\
    \frac{dP}{dt} &= F(t)P(t) + P(t)F(t)^{T} + L(t)QL(t)^{T} \\
    \text{with initial condition } \,\, X_0 &\sim \mathcal{N}(m_0, P_0)
\end{align}
The transition density ($p(X_t = x(t) \vert X_s = x(s)$) can be found explicitely ($0 < s < t$):
\begin{align}
    p(x_t \vert x_s) &= \mathcal{N}(x_t \vert m(t\vert s), P(t \vert s)) \\
    m(t \vert s) &= \Psi(t,s)x(s) \\
    P(t \vert s) &= \int_{s}^{t} \Psi(t,\tau)L(\tau)Q L(\tau)^{T}\Psi(t, \tau)^{T} d\tau
\end{align}

Which allows to \textbf{discretize} the \gls{sde} as:
\begin{align}
    \label{linear sde discretization}
    x_{t_{k+1}} &= A_k x_{t_k} + q_k \\
    q_k &\sim \mathcal{N}(0, \Sigma_k) \\
    A_k &= \Psi(t_{k+1}, t_k) \\
    \Sigma_k &= \Sigma(t_{k+1}, t_k) = \int_{t_k}^{t_{k+1}} \Psi(t_{k+1}, \tau) L(\tau)Q L(\tau)^{T} \Psi(t_{k+1}, \tau)^{T} d\tau
\end{align}

In practice, the \textbf{linearization of an SDE} is one of the techniques used to approximate \gls{sde} and 
allow computations:
\begin{align}
    dX_t &= F(X_t, t)dt + L(X_t, t)dB_t \\
    F(X_t, t) &\approx F(m(t), t) + J_X F(m(t),t)(X_t - m(t)) \\
    L(X_t, t] &\approx L(m(t),t) \\
    \frac{dm}{dt} &= F(m(t), t) \\
    \frac{dP}{dt} &= J_X F(m(t),t) P(t)^{T} + P(t)J_X F(m(t),t)^{T} + L(m(t), t)QL(m(t),t)^{T} \\
\end{align}
where $J_X F$ is the Jacobian of $F$ w.r.t $X$.

A set of example calculations for the Ornstein-Uhlenbeck process is located in the appendix.