%-----------------------------------------------------------------
%--- VAE 
%-----------------------------------------------------------------

\chapter{Vanilla Variational Auto Encoder}\label{Vanilla VAE}
    
We consider a sequence of i.i.d points $(x_i)_{i=1,...,N} \in \mathbb{R}^D$, and the associated latent variables $(z_i)_{i=1,...,N} \in \mathbb{R}^L$. 

In the vanilla VAE setting, the observation model (decoder) is $p_{\theta_x}(x \vert z)$, the approximate posterior (encoder) is $q_{\phi}(z \vert x)$, the latent prior is $p_{\theta_z}(z)$.

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
%nodes
\node[latent]   (z)     {$z_i$};
\node[obs, below= of z]       (x) {$x_i$};
% edges
\path[->] (z) edge [bend left=-45] node[mid left] {$p_{\theta_x}(x_i\vert z_i)$} (x)
            (x) edge [bend left=-45] node[mid right] {$q_{\phi}(z_i\vert x_i)$} (z);

\plate [inner sep = 1.35cm, xshift=0.25cm] {plate1} { %
    (x)%
    (z)%
  } {$i=1,..,N$}; %
\end{tikzpicture}
\caption{Vanilla VAE}
\label{fig:vanilla_vae}
\end{center}
\end{figure}

The log likelihood of the data is:
\begin{align*}
    \log{p_{\theta}(x)} = \log{\frac{p(x,z)}{p(z\vert x)}}
\end{align*}

Multiplying both sides by $q_\phi(z \vert x)$ and integrating over $dz$ leads to:
\begin{align*}
    \log{p_{\theta}(x)} &= \int q_\phi(z \vert x) \log{\frac{p_\theta(x,z)}{p(z\vert x)}}dz \\
    &= \int q_\phi(z\vert x) \log{\frac{p_\theta(x,z)}{q_\phi(z\vert x)}\frac{q_\phi(z \vert x)}{p(z \vert x)}}dz \\
    &= \mathbb{E}_{q_\phi(z \vert x)} \log{\frac{p_\theta(x,z)}{q_\phi(z \vert x)}} + \mathbb{KL}(q_\phi(z \vert x) \vert\vert p(z \vert x)) \\
    &\geq \mathbb{E}_{q_\phi(z \vert x)} \log{\frac{p_\theta(x,z)}{q_\phi(z \vert x)}} = \mathcal{L}(\theta, \phi, X)
\end{align*}

In this setting, the D-separation is obvious and the joint distribution factorizes over $n$:
\begin{align*}
    p_{\theta}(x,z) &= \prod_{i=1}^n p_{\theta_x}(x_i \vert z_i) p_{\theta_z}(z_i) \\
    q_{\phi}(z \vert x) &= \prod_{i=1}^n q_{\phi}(z_i \vert x_i)
\end{align*}
The \gls{vlb} (or \gls{elbo}) $\mathcal{L}(\theta, \phi, X)$ simplifies into:
\begin{align*}
    \mathcal{L}(\theta, \phi, X) &= \mathbb{E}_{q_{\phi}(z \vert x)} \log{\frac{\prod_{i=1}^n p_{\theta_x}(x_i \vert z_i) p_{\theta_z}(z_i)}{\prod_{i=1}^n q_{\phi}(z_i \vert x_i)}} \\
    &= \sum_{i=1}^n \mathbb{E}_{q_{\phi}(z_i \vert x_i)} \log{p_{\theta_x}(x_i \vert z_i)} - \sum_{i=1}^n \mathbb{KL}(q_{\phi}(z_i \vert x_i) \vert\vert p_{\theta_z}(z_i) )
\end{align*}
The first term is the reconstruction loss, and is estimated via Monte Carlo sampling over $z_i \sim q_{\phi}(z_i \vert x_i)$. The second term is a KL-divergence, which can be computed analytically when $q_\phi$ and $p_{\theta_z}$ are chosen to be Gaussians.

% ---- CODE DE LILIAN ---------------------------------------
% \begin{figure}[H]
% \centering
% \begin{tikzpicture}

% % Nodes
% \node[const] (alpha) {$\alpha$};
% \node[latent, right=of alpha, xshift=1.5cm] (pi) {$\pi$};
% \node[latent, below=of pi, yshift=-1.5cm] (zi) {$z_i$};
% \node[obs, below=of zi, yshift=-1.5cm] (xi) {$x_i$};
% \node[const, left=of xi, yshift=0.5cm, xshift=-1.5cm] (mu) {$\mu$};
% \node[const, left=of xi, yshift=-0.5cm, xshift=-1.5cm] (sigma) {$\Sigma$};


% % Plates
% \plate [inner sep=0.3cm, xshift=0cm, yshift=0cm] {plate1} {(zi)(xi)} {$N$};

% % Edges
% \edge {alpha} {pi};
% \edge {mu, sigma} {xi};
% % \edge {pi} {zi};
% % \edge {zi} {xi};

% % Variational Arrows (dashed arrows for q distributions)
% \path [->] (pi) edge [bend right] node[left] {$p(z | \pi)$} (zi);
% \path [->] (zi) edge [bend right] node[right] {$q_{\phi}(\pi | z)$} (pi);

% \path [->] (zi) edge [bend right] node[left] {$p(x | z)$} (xi);
% \path [->] (xi) edge [bend right] node[right] {$q_{\phi}(z | x)$} (zi);


% \end{tikzpicture}
% \caption{Markovian Hierarchical VAE}
% \label{fig:graphical_variational}
% \end{figure}


%---------------------------------------------------------------------
%--- GAUSSIAN PROCESS 
%---------------------------------------------------------------------

\chapter{Gaussian Process}\label{sec:Gaussian Process}

We summarize here most of the results of the Gaussian Process, and refers the reader to \cite{rasmussen_gaussian_2008} for further details.

We first recall the Gaussian marginal and conditional result:

Let $x$ and $y$ be jointly Gaussian vectors, ie:
\begin{align}
    \begin{bmatrix}
        x \\ y
    \end{bmatrix} &\sim \mathcal{N} \left( 
    \begin{bmatrix}
        \mu_x \\ \mu_y
    \end{bmatrix},
        \begin{bmatrix}
            A & C \\
            C^T & B
        \end{bmatrix}
    \right) = \mathcal{N} \left( 
        \begin{bmatrix}
        \mu_x \\ \mu_y
    \end{bmatrix},
        \begin{bmatrix}
            \tilde{A} & \tilde{C} \\
            \tilde{C}^T & \tilde{B}
        \end{bmatrix}^{-1}
    \right)
\end{align}
where $A, B, C$ is the block decomposition of the covariance matrix, and $\tilde{A}, \tilde{B}, \tilde{C}$ the block decomposition of the precision matrix.

Then the marginal distribution of $x$ and the conditional distribution of $x$ given $y$ are :
\begin{align}
    x &\sim \mathcal{N}(\mu_x, A) \\
    x \vert y &\sim \mathcal{N}(\mu_x + CB^{-1}(y-\mu_y), A-CB^{-1}C^T) \\
    &= \mathcal{N}(\mu_x - \tilde{A}^{-1}\tilde{C}(y-\mu_y), \tilde{A}^{-1})
\end{align}

We now consider a Gaussian Process with mean function $m(.)$ and kernel $k(.,.)$
\begin{align}
    f(x) \sim \mathcal{GP}(m(x), k(x,x'))
\end{align}
At the training points $X = \{x_1,...,x_n\}$, the observations are $Y=\{y_1,...,y_n\}$ with some noise $y = f(x) + \epsilon$ with $\epsilon \overset{i.i.d}{\sim} \mathcal{N}(0,\sigma_n^2)$.

The covariance between observations writes:
\begin{align}
    \text{cov}(y_p,y_q) &= k(x_p, x_q) + \delta_{pd}\sigma_n^2 \\
    \text{cov}(y) &= K(X,X) + \sigma_n^2 I
\end{align}

At some test points $X_*$, we aim to predict $f_* = f(X_*)$. Then:
\begin{align}
    \begin{bmatrix}
        y \\ f_*
    \end{bmatrix} \sim \mathcal{N} \left( 0, \begin{bmatrix}
        K(X,X)+\sigma_n^2I & K(X,X_*) \\ K(X_*,X) & K(X_*,X_*)
    \end{bmatrix}\right)
\end{align}

From which we get:
\begin{align}
    f_* \vert X_*, X, Y &\sim \mathcal{N}(\overline{f_*}, \rm{cov(f_*)}) \\
    \overline{f_*} &= K(X_*,X) \left( K(X,X) + \sigma_n^2 I\right)^{-1}Y \\
    \rm{cov}(f_*) &= K(X_*,X_*) - K(X_*,X) \left( K(X,X) + \sigma_n^2I\right)^{-1} K(X,X_*)
\end{align}


\chapter{KL divergence between two exponential-family distributions}\label{sec:KL-two-exponential-family-distributions}

We recall the family of distributions parameterized by $\eta \in \R^K$, over a fixed support $\mathcal{X}^D \in \R^D$ : the \textbf{exponential family} of distributions $p(x \vert \eta)$ is given by:
\begin{align}
    p(x \vert \eta) &= \frac{1}{Z(\eta)} h(x) \exp\left(\eta^T \mathcal{T}(x)\right) \\
    &= h(x) \exp \left( \eta^T \mathcal{T}(x) - A(\eta)\right)
\end{align}
with:
\begin{itemize}
    \item $h(x)$ is the base measure, ie a scaling constant (often 1)
    \item $\mathcal{T}(x)$ are the sufficient statistics
    \item $\eta$ are the natural parameters, or canonical parameters
    \item $Z(\eta)$ is the partition function, $A(\eta)$ is the log partition function.
\end{itemize}

The Bernoulli, categorical (ie multinomial for one observation), Gaussian distributions are part of the exponential family.

The \textbf{$\mathbb{KL}$-divergence between two exponential family distributions of the same family} is:

\begin{align}
    \mathbb{KL}(p(x\vert \eta_1) \vert \vert p(x \vert \eta_2)) &= \mathbb{E}_{\eta_1}\left[ (\eta_1 - \eta_2) \mathcal{T}(x) - A(\eta_1) + A(\eta_2)\right] \\
    &= (\eta_1 - \eta_2)^T \mathbb{E}_{\eta_1}\mathcal{T}(x) - A(\eta_1) + A(\eta_2)
\end{align}

The most important example is the $\mathbb{KL}$-divergence between two multivariate Gaussian distributions of dimension $D$:

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!black,title=KL between two multivariate Gaussians of dimension $D$]
\begin{align}
    \label{KL-two-gaussians}
    \mathbb{KL}(\mathcal{N}(x \vert \mu_1, \Sigma_1) \vert\vert \mathcal{N}(x \vert \mu_2, \Sigma_2) &=
    \frac{1}{2}\left[ \text{tr}(\Sigma_2^{-1}\Sigma_1) + (\mu_2-\mu_1)^T \Sigma_2^{-1}(\mu_2-\mu_1) -D + \log{\frac{\vert \Sigma_2\vert}{\vert \Sigma_1 \vert}}\right]
\end{align}
\end{tcolorbox}


% ----------------------------------------
% ----- ORNSTEIN UHLENBECK ---------------
% ----------------------------------------

\chapter{Ornstein Uhlenbeck}\label{Ornstein Uhlenbeck}

We summarize here some computations of chapters \ref{sec:SC_intro} and \ref{sec:SDE_results} for the Ornstein-Uhlenbeck process.

We start by a preliminary result:

\thmp{Stochastic exponential}{
Let $Z_t$ be the Itô's process (ie $a_t$ and $b_t$ two stochastic processes)
\begin{align*}
    dZ_t &= a_t dt + b_t dB_t \\
    Z_0 &= 0
\end{align*}
Then consider the SDE :
\begin{align*}
    dX_t &= X_t dZ_t \\
    &= a_t X_t dt + b_t X_t dB_t \\
    X_0 &= 1
\end{align*}
Then the solution is:
\begin{align}
    \label{solution stochastic exponential}
    X_t &= e^{Y_t} \\
    Y_t &= Z_t - \frac{1}{2}\int_0^t b_s^2 ds
\end{align}
}
{
We set
\begin{align*}
    X_t &= e^{Y_t} = f(Y_t,t) \\
    dY_t &= \mu_t dt + \sigma_t dB_t
\end{align*}
and apply Itô's formula:
\begin{align*}
    dX_t &= d(e^{Y_t}) \\
    &= X_t dY_t + \frac{1}{2}X_t \sigma_t^2dt \\
    &= X_t \left( \mu_t dt + \sigma_t dB_t \right) + \frac{1}{2}X_t \sigma_t^2dt \\
    &= \left( X_t \mu_t + \frac{1}{2}X_t \sigma_t^2\right) dt + X_t \sigma_t dB_t \\
\end{align*}

By identification:
\begin{align*}
    \mu_t &= a_t - \frac{1}{2}\sigma_t^2 \\
    \sigma_t &= b_t
\end{align*}
Then
\begin{align*}
    dY_t &= \left( a_t - \frac{1}{2}\sigma_t^2\right) dt + \sigma_t dB_t \\
    &= dZ_t - \frac{1}{2}\sigma^2_t dt \\
    Y_t &= Z_t - \frac{1}{2} \int_0^t b_s^2 ds \,\, (Y_0 = 0)
\end{align*}
Conversely, $e^{Y_t}$ is solution, as
\begin{align*}
    d(e^{Y_t}) &= e^{Y_t} dY_t + \frac{1}{2}e^{Y_t} b_t^2 dt \\
    &= e^{Y_t} \left( dY_t + \frac{1}{2}b_t^2 dt\right) \\
    &= e^{Y_t} dZ_t
\end{align*}
}

\defn{Ornstein Uhlenbeck process}{
    The \textbf{Ornstein Uhlenbeck process} is the stochastic processes solution of the linear \gls{sde}:
    \begin{align}
        dX_t &= - \lambda X_t dt + \sigma dB_t \\
        X_{t_0} &= X_0
    \end{align}
    where $\lambda > 0$ is the \textbf{drift} and $\sigma > 0$ the \textbf{diffusion coefficient}.
}

\thmp{Solution of Ornstein Uhlenbeck}{
    \begin{align}
    \label{analytical solution of OU}
    dX_t &= - \lambda X_t dt + \sigma dB_t \\
    X_{t_0} &= X_0 \\
    X_t &= e^{- \lambda t} X_0 + \sigma \sqrt{\frac{1 - e^{-2 \lambda t}}{2 \lambda}}\mathcal{N}(0, 1)
\end{align}
}{
For Ornstein-Uhlenbeck, we write $Y_t = e^{\lambda t}X_t$. Ito's formula gives :
\begin{align}
    dY_t &= e^{\lambda t}X_t dX_t + \lambda e^{\lambda t}X_t \\
    \label{dY}
    &= \sigma e^{\lambda t} dB_t \\
    Y_t &= Y_0 + \sigma \int_{0}^{t} e^{\lambda s} dB_s \\
    X_t &= e^{-\lambda t} X_0 + \sigma e^{-\lambda t} \int_{0}^{t} e^{\lambda s} dB_s 
\end{align}
We have to compute:
\begin{align}
    \int_{0}^{t} e^{\lambda s}dB_s &= \underset{n \rightarrow \infty}{\lim} \sum_{k=0}^{n} e^{\lambda t_k}
    (B_{t_{k+1}} - B_{t_k})
\end{align}
The sum on the rhs is a sum of independent Gaussians $e^{\lambda t_k}(B_{t_{k+1}} - B_{t_k}) \sim e^{\lambda t_k}\mathcal{N}(0, t_{k+1}-t_k)$, 
so the sum is a centered Gaussian of variance $\sum_{k=0}^{n} e^{2 \lambda t_k} (t_{k+1}-t_k)$.
So :
\begin{align}
    \int_{0}^{t} e^{\lambda s}dB_s &= \
    \mathcal{N}(0, \underset{n \rightarrow \infty}{\lim} \sum_{k=0}^{n} e^{2 \lambda t_k}
    (t_{k+1} - t_k)) \\
    &= \mathcal{N}(0, \int_{0}^{t} e^{2 \lambda s}ds) \\
    &= \mathcal{N}(0, \frac{1}{2 \lambda} (e^{2 \lambda t} - 1))
\end{align}
}

\thmp{Fokker Plank Kolmogorov solution for O.U.}{
    The stationary solution of the Fokker Plank Kolmogorov equation of a 1D Ornstein Uhlenbeck process is:
    \begin{align}
        \frac{\partial^{2}p}{\partial x^{2}} + \frac{2 \lambda}{\sigma} x \frac{\partial p}{\partial x} \
        + \frac{2 \lambda}{\sigma} p &= 0 \\
        p &\propto \exp{- \frac{\lambda x^{2}}{\sigma}}
    \end{align}
}{
    We have $F(X_t,t) = - \lambda X_t$, $L(X_t,t) = 1$, $Q = \sigma$ in \ref{FPK}, which leads to:
    \begin{align}
        \frac{\partial p}{\partial t} &= \frac{\sigma}{2} \frac{\partial^{2}p}{\partial x^{2}} + \lambda x \frac{\partial p}{\partial x} \
        + \lambda p
    \end{align}
    When $p$ is stationary (ie when $t \rightarrow \infty$), then $\frac{\partial p}{\partial t} = 0$ and 
    we get the result.
}

\thmp{Moment differential equations for O.U.}{
    The equations \ref{SDE_linear_moments} simplify in:
    \begin{align}
        \frac{dm}{dt} &= -\lambda m \\
        \frac{dP}{dt} &= - 2 \lambda P + \sigma \\
        x(0) &= x_0 \\
        P(0) &= 0 \\
        X_t &\sim \mathcal{N}(X_t \vert m(t), P(t))
    \end{align}
}{substituting $\lambda$ and $\sigma$ in \ref{SDE_linear_moments}}


\thmp{Discretization of O.U}{
    The discretization \ref{linear sde discretization} writes:
    \begin{align}
        x_{t_{k+1}} &= a_k x_{t_k} + q_k \\
        q_k &\sim \mathcal{N}(0, \Sigma_k) \\
        a_k &= e^{-\lambda \Delta t_k} \\
        \Sigma_k &= \frac{\sigma}{2 \lambda} \left( 1 - e^{-2 \lambda \Delta t_k} \right)
    \end{align}
}{One can substitute $\lambda$ and $\sigma$ into \ref{linear sde discretization}.

For $\lambda > 0$ and $\sigma > 0$, we can write from \ref{dY} (with $t_{k+1} = t_k + \Delta t$):
\begin{align}
    Y_{t_{k+1}}- Y_{t_k} &= \sigma \int_{t_k}^{t_{k+1}} e^{\lambda s}dB_s \\
    &= \sigma e^{\lambda t_k} \mathcal{N}(0, \frac{e^{2 \lambda \Delta t} - 1}{2 \lambda}) \\
    X_{t_{k+1}} &= e^{- \lambda t_{k+1}} Y_{t_{k+1}} \\
    &= e^{- \lambda \Delta t} X_{t_k} + \sigma \sqrt{\frac{1 - e^{-2 \lambda \Delta t}}{2 \lambda}} \mathcal{N}(0,1)
\end{align}

In other words:
\begin{align}
    \label{transition_ou}
    p(X_{t_{k+1}} \vert X_{t_k}) &= \mathcal{N}\left(X_{t_{k+1}} \vert e^{- \lambda \Delta t} X_{t_k}, \sigma^{2} \frac{1 - e^{-2 \lambda \Delta t}}{2 \lambda}\right)
\end{align}
}

\thmp{Maximum Likelihood parameters estimation}{
    Let $x_0, x_1, ... x_k, ... x_{n}$ be an observation of a Ornstein Uhlenbeck process with unknown $\lambda > 0$ and $\sigma > 0$.
    The previous results lead to the following maximum likelihood point estimates:
    \begin{align}
        \lambda_{ML} &= - \frac{1}{\Delta t} \log{\frac{\sum_{k=0}^{n-1} x_k x_{k+1}}{\sum_{k=0}^{n-1} x_k^{2} }} \\
        \sigma_{ML}^{2} &= \frac{1}{n} \frac{2 \lambda_{ML}}{1 - e^{-2 \lambda_{ML} \Delta t}} \sum_{k=0}^{n-1} \left( x_{k+1} - e^{- \lambda_{ML} \Delta t} x_k\right)^{2}
    \end{align}
}{We have :
\begin{align}
    p(x_{k+1} \vert x_{k}) &= \mathcal{N}\left(x_{k+1} \vert e^{- \lambda \Delta t} x_{k}, \sigma^{2} \frac{1 - e^{-2 \lambda \Delta t}}{2 \lambda}\right)
\end{align}
With:
\begin{align}
    a &= e^{- \lambda \Delta t} \\
    \eta^{2} &= \sigma^{2} \frac{1 - e^{-2 \lambda \Delta t}}{2 \lambda}
\end{align}
The likelihood writes:
\begin{align}
    p(x_{1:n} \vert \lambda, \sigma) &= \prod_{k=0}^{n-1} p(x_{k+1} \vert x_k) \\
    - \log{p(x_{1:n} \vert \lambda, \sigma)} &= \frac{n}{2} \log{2 \pi \eta^{2}} + \frac{1}{2 \eta^{2}}  \sum_{k=0}^{n-1} \left( x_{k+1} - a x_k\right)^{2}
\end{align}
Forming the gradient and putting it to zero gives the result.
}


% -----------------------------------------------------------------
% --- WHY BROWNIAN MOTION IS GAUSSIAN AND MARKOV ------------------
% -----------------------------------------------------------------

\chapter{Why Brownian motion is a Gaussian and a Markov process}\label{sec:brownian_motion_gaussian_and_markov}

Solutions of linear \gls{sde} are Gaussian processes and Markov processes. I found counter-intuitive at first, that a Gaussian process might be Markovian.
After all, the kernel function encodes dependencies and correlations between several points, so there is no \textit{a priori} reason to have 
$p(x_n \vert x_{n-1}, x_{n-2}, ... , x_1) = p(x_n \vert x_{n-1})$.

The Markovian property is actually enabled by the GP kernel. Here is a toy example for the Browian motion.

The Brownian motion is solution of the simplest linear equation: $dX_t = dB_t$.

\thmp{Kernel function of the Brownian motion}{
    The Brownian motion is the solution of the linear \gls{sde}
    \begin{align}
        dX_t &= dB_t
    \end{align}
    It is a Gaussian process with mean and kernel functions given by:
    \begin{align}
        B_t &\sim \mathcal{GP}(0, \text{min}(t,t'))
    \end{align}
}{An elegant proof can be found in \cite{mouvement-brownien-calcul-ito}. Let's consider a discretized version of the Brownian motion, ie a random walk:
\begin{align}
    X_{n} &= X_{n-1} + \xi_n \\
    \xi_n &\underset{\text[i.i.d.]}{\sim} \mathcal{N}(0,1)
\end{align}
Then, $\forall \alpha_1, \alpha_2, ..., \alpha_n \in \mathbb{R}$,
\begin{align}
    \alpha_1 X_1 + \alpha_2 X_2 + ... + \alpha_n X_n &= \alpha_1 \xi_1 + \alpha_2 (\xi_1 + \xi_2) + ... + \alpha_n (\xi_1 + \xi_2 + ... \xi_n) \\
    &= (\alpha_1 + \alpha_2 + ... + \alpha_n)\xi_1 + (\alpha_2 + ... + \alpha_n)\xi_2 + ... + \alpha_n \xi_n
\end{align}
which is Gaussian as a linear combination of independent Gaussians. Therefore $X_{[1:n]} = (X_1,...,X_n)$ is a Gaussian vector and $(X_n)_{n \geq 1}$ is a Gaussian process.

The law of the vector $X_{[1:n]}$ is computed using the caracteristic function (with $\alpha = (\alpha_1,...,\alpha_n)$)
\begin{align}
    \phi(\alpha) &= \mathbb{E}(e^{<\alpha, X_{[1:n]}}) \\
    &= \mathbb{E}(e^{((\alpha_1 + \alpha_2 + ... + \alpha_n)\xi_1 + (\alpha_2 + ... + \alpha_n)\xi_2 + ... + \alpha_n \xi_n)}) \\
    &= \mathbb{E}(e^{(\alpha_1 + \alpha_2 + ... + \alpha_n)\xi_1}e^{(\alpha_2 + ... + \alpha_n)\xi_2}...e^{\alpha_n\xi_n}) \\
    &= \mathbb{E}(e^{(\alpha_1 + \alpha_2 + ... + \alpha_n)\xi_1}) \mathbb{E}(e^{(\alpha_2 + ... + \alpha_n)\xi_2}) ... \mathbb{E}(e^{\alpha_n\xi_n}) \\
    &= e^{-\frac{1}{2}(\alpha_1 + \alpha_2 + ... + \alpha_n)^{2}} e^{-\frac{1}{2}(\alpha_2 + ... + \alpha_n)^{2}} ... e^{-\frac{1}{2}\alpha_n^{2}} \\
    &= e^{-\frac{1}{2}\sum_{i=1}^{n}(\sum_{j=i}^{n}\alpha_j)^{2}} \\
    &= e^{-\frac{1}{2}\vert\vert B \alpha \vert\vert ^{2}} \\
    &= e^{-\frac{1}{2} < \alpha, B^{T}B \alpha >}
\end{align}
with the matrix:
\begin{align}
    B &= \begin{pmatrix}
        1 & 0 & 0 & ... & 0 \\
        1 & 1 & 0 & ... & 0 \\
        \vdots \\
        1 & 1 & 1 & ... & 1
    \end{pmatrix}
\end{align}
and the covariance matrix $\Gamma = B^{T}B$:
\begin{align}
    \Gamma &= \begin{pmatrix}
        1 & 1 & 1 & ... & 1 \\
        1 & 2 & 2 & ... & 2 \\
        1 & 2 & 3 & ... & 3 \\
        \vdots \\
        1 & 2 & 3 & ... & n
    \end{pmatrix}
\end{align}
ie $\Gamma_{i,j} = \text{min}(i,j)$
}

Let's look now at three points $x_1, x_2, x_3$, taken at times $t_1 < t_2 < t_3$.

By definition of a Gaussian process, their joint probability is Gaussian:

\begin{align}
    \begin{pmatrix}
        x_1 \\ x_2 \\ x_3
    \end{pmatrix} &\sim 
    \mathcal{N}
    \begin{pmatrix}
        \begin{pmatrix}
            0 \\ 0 \\ 0
        \end{pmatrix},
        \begin{pmatrix}
            \Gamma(t_1,t_1) & \Gamma(t_1,t_2) & \Gamma(t_1, t_3) \\
            \Gamma(t_2,t_1) & \Gamma(t_2,t_2) & \Gamma(t_3, t_3) \\
            \Gamma(t_3,t_1) & \Gamma(t_3,t_2) & \Gamma(t_3, t_3) \\
        \end{pmatrix}
    \end{pmatrix} \\
    &= \mathcal{N}
    \begin{pmatrix}
        \begin{pmatrix}
            0 \\ 0 \\ 0
        \end{pmatrix},
        \begin{pmatrix}
            t_1 & t_1 & t_1 \\
            t_1 & t_2 & t_2 \\
            t_1 & t_2 & t_3 \\
        \end{pmatrix}
    \end{pmatrix}
\end{align}

We compute now $p(x_3 \vert x_2, x_1)$ with Gaussian conditionning:

\begin{align}
    p(x_3 \vert x_2, x_1) &= \mathcal{N}(m_{3,12}, k_{3,12}) \\
    m_{3,12} &= \begin{pmatrix}
        t_1 & t_2
    \end{pmatrix}
    \begin{pmatrix}
        t_1 & t_1 \\
        t_1 & t_2
    \end{pmatrix}^{-1}
    \begin{pmatrix}
        x_1 \\ x_2
    \end{pmatrix} \\
    k_{3,12} &= t_3 - \begin{pmatrix}
        t_1 & t_2
    \end{pmatrix}
    \begin{pmatrix}
        t_1 & t_1 \\
        t_1 & t_2
    \end{pmatrix}^{-1}
    \begin{pmatrix}
        t_1 \\ t_2
    \end{pmatrix}
\end{align}

We compute
\begin{align}
    \begin{pmatrix}
        t_1 & t_1 \\
        t_1 & t_2
    \end{pmatrix}^{-1} &= \frac{1}{t_1(t_2 - t_1)}
    \begin{pmatrix}
        t_2 & -t_1 \\
        -t_1 & t_1
    \end{pmatrix}
\end{align}

and finally get:
\begin{align}
    m_{3,12} &= x_2 \\
    k_{3,12} &= t_3 - t_2
\end{align}

which proves that $p(x_3 \vert x_2, x_1) = p(x_3 \vert x_2) = \mathcal{N}(x_2, t_3-t_2)$, ie the Browian motion is a Markov process,
and we also retrieve that $x_3 - x_2 \sim \mathcal{N}(0, t_3-t_2)$.

\chapter{Adjoint sensitivity method}\label{sec:adjoint_sensitivity_method}

NB : I have chosen here to write vector with an underline : $\underline{u}$ versus a scalar $u$. Event though the notation 
is heavier, this should prove useful when coding the algorithm and checking for shapes of gradients and Jacobians.

In a machine learning setting, we model a variable $\underline{u}$ -usually a latent variable- as a vector-valued function
     verifying an \gls{ode}:
    \begin{align}
        \label{main_ode}
        \frac{d \underline{u}}{dt} &= f_{\theta}(\underline{u},t) \\
        \underline{u}(t=0) &= \underline{u}_0
    \end{align}
    \begin{itemize}
        \item Notations:
            \begin{itemize}
                \item $x$ is a scalar value
                \item $\underline{x}$ is a vector
            \end{itemize}
        \item $t$ is the time.
        \item $\underline{u} : \mathbb{R} \rightarrow \mathbb{R}^N$ is a function of time into a space of dimension $N$.
        \item $f_{\theta} : \mathbb{R}^N \times \mathbb{R} \rightarrow \mathbb{R}^N$ is a function parameterized 
        by $\underline{\theta} \in \mathbb{R}^P$ - typically  a neural network which we want to train. NB : $f_{\theta}$ can also be seen as 
        a function $f(\underline{u}, t, \underline{\theta})$.
    \end{itemize}

    We wish to optimize a loss $J$ function of the \textbf{function} $\underline{u}$ and parameters set $\underline{\theta}$:
    \begin{align}
        \label{functionnal_loss}
        J: (\mathbb{R}^N \times \mathbb{R} \rightarrow \mathbb{R}^N) \times \mathbb{R}^P &\rightarrow \mathbb{R} \\
        \underline{u}, \underline{\theta} &\mapsto J(\underline{u}, \underline{\theta}) = \int_{0}^{T} g(\underline{u}, \underline{\theta}) dt
    \end{align}
    where $g$ is a scalar-valued functional.

    For example, we can set $g(\underline{u}, \underline{\theta}) = \underline{u}^{T} Q \underline{u}$, where $Q$ is a $N \times N$ definite positive symetric matrix to compute
     a $L_2$ loss.

    In order to train our neural network $f_{\theta}$, we need to compute the gradients
    \begin{align}
        \frac{dJ}{d \underline{\theta}} &= \frac{d}{d \underline{\theta}} \int_{0}^{T} g(\underline{u}, \theta) dt 
    \end{align}
    so we can backpropagate them.

    Let's start the computation.

    \begin{align}
        \frac{dJ}{d \underline{\theta}} &= \frac{d}{d \underline{\theta}} \int_{0}^{T} g(\underline{u}, \underline{\theta}) dt \\
        &= \int_{0}^{T} \left( \frac{\partial g}{\partial \underline{\theta}} + \frac{\partial g}{\partial \underline{u}} 
        \frac{d \underline{u}}{d \underline{\theta}} \right) dt
    \end{align}

    where $\frac{\partial g}{\partial \underline{\theta}}$ is a gradient (shape $1 \times P$ as a row), $\frac{\partial g}{\partial \underline{u}}$ 
    is a gradient (shape $1 \times N$), and $\frac{d \underline{u}}{d \underline{\theta}}$ is a Jacobian $N \times P$.

    The \textbf{adjoint method} consists in framing the problem as an optimization problem, and using the dual:
    \begin{align}
        \underset{\underline{\theta}}{\text{min}} &: {J(\underline{u}, \underline{\theta})} \\
        \text{s.t} \,\,\,  &\frac{d \underline{u}}{dt} = f_{\theta}(\underline{u},t) \\
    \end{align}

    We form the Lagrangien of the problem, and compute its derivative wrt $\underline{\theta}$ (NB : the 
    Lagrange multiplier $\lambda$ is a function here):
    \begin{align}
        \mathcal{L}(\underline{u}, \underline{\theta}, \underline{\lambda} ) &= \int_{0}^{T} \left[ g(\underline{u}, \underline{\theta})
            + \lambda^{T}(t) \left( f_{\theta}(\underline{u},t) - \frac{d \underline{u}}{dt} \right) \right] dt \\
        \frac{d \mathcal{L}}{d \underline{\theta}} &= \int_{0}^{T} \left[ \frac{\partial g}{\partial \underline{u}} \frac{d \underline{u}}{d \underline{\theta}}
        + \frac{\partial g}{\partial \underline{\theta}} + \lambda^{T}(t) \left( \frac{\partial \underline{f}}{\partial \underline{u}} \frac{d \underline{u}}{d \underline{\theta}}
        + \frac{\partial \underline{f}}{\partial \underline{\theta}} -\frac{d}{d \underline{\theta}} \frac{d \underline{u}}{dt} \right) \right] dt
    \end{align} 

    We integrate by parts the problematic part of the integral:
\begin{align}
    \int_{0}^{T} \lambda^{T}(t) \frac{d}{d \underline{\theta}} \frac{d \underline{u}}{dt} dt &=
        \int_{0}^{T} \lambda^{T}(t) \frac{d}{dt} \frac{d \underline{u}}{d \underline{\theta}} dt \\
        &= \lambda^{T}(t)\frac{d \underline{u}}{d \underline{\theta}} \vert^{T}_{0} - \int_{0}^{T} \left( \frac{d \lambda}{dt} \right)^{T} \frac{d \underline{u}}{d \underline{\theta}} dt
\end{align}
Finally:
\begin{align}
    \frac{d \mathcal{L}}{d \underline{\theta}} &= \int_{0}^{T} \left[
        \left( \frac{\partial g}{\partial \underline{u}} + \left( \frac{d \lambda}{dt} \right)^{T} + \lambda^{T}(t) \frac{\partial \underline{f}}{\partial \underline{u}}\right) 
            \frac{d \underline{u}}{d \underline{\theta}} + \frac{\partial g}{\partial \underline{\theta}} + \lambda^{T}(t) \frac{\partial \underline{f}}{\partial \underline{\theta}} \right] dt
            - \lambda^{T}(t)\frac{d \underline{u}}{d \underline{\theta}} \vert^{T}_{0}
\end{align}

Which leads to, canceling the factor of $\frac{d \underline{u}}{d \underline{\theta}}$ in the integral, and choosing $\lambda(T)=0$:
\begin{align}
    \frac{d \lambda}{dt} + \left( \frac{\partial \underline{f}}{\partial \underline{u}}\right)^{T} \lambda(t) + \left( \frac{\partial g}{\partial \underline{u}}\right)^{T} &= 0 \\
    \lambda(T) &= 0 \\
    \frac{d \mathcal{L}}{d \underline{\theta}} &= \int_{0}^{T} \left( \frac{\partial g}{\partial \underline{\theta}} + \lambda^{T}(t) \frac{\partial \underline{f}}{\partial \underline{\theta}} \right) dt
    + \lambda(0) \frac{d \underline{u}}{d \underline{\theta}} \vert_{0}
\end{align}

    Now, we remark that the solution $\underline{u}, \underline{\theta}$ is feasible, so $\frac{d \mathcal{L}}{d \underline{\theta}} = \frac{dJ}{d \underline{\theta}}$ as the \gls{ode} is verified.

    Finally, the gradient of the loss wrt the parameter set $\underline{\theta}$ is given by:
    \begin{tcolorbox}[colback=blue!5!white,colframe=black!75!black,title=Gradient computation by adjoint method]
        \begin{align}
            \frac{d \lambda}{dt} + \left( \frac{\partial \underline{f}}{\partial \underline{u}}\right)^{T} \lambda(t) + \left( \frac{\partial g}{\partial \underline{u}}\right)^{T} &= 0 \\
            \lambda(T) &= 0 \\
            \frac{dJ}{d \underline{\theta}} &= \int_{0}^{T} \left( \frac{\partial g}{\partial \underline{\theta}} + \lambda^{T}(t) \frac{\partial \underline{f}}{\partial \underline{\theta}} \right) dt
            + \lambda(0) \frac{d \underline{u}_0}{d \underline{\theta}}
        \end{align}
    \end{tcolorbox}
    The Lagrange multiplier function $\lambda$ is given by solving a terminal value \gls{ode}.

The overall strategy for computing the gradient of the loss $J$ wrt to the parameter set $\underline{\theta}$ is therefore:
    \begin{tcolorbox}[colback=blue!5!white,colframe=black!75!black,title=Strategy for computing the gradient of the loss $J$ wrt $\underline{\theta}$]
        \begin{enumerate}
            \item solve the \textbf{initial value problem} with an \gls{ode} solver:
                \begin{align}
                    \frac{d \underline{u}}{dt} &= f_{\theta}(\underline{u},t) \\
                    \underline{u}(t=0) &= \underline{u}_0
                \end{align}
            \item solve the \textbf{adjoint/terminal value problem} with an \gls{ode} solver:
                \begin{align}
                    \label{adjoint}
                    \frac{d \lambda}{dt} + \left( \frac{\partial \underline{f}}{\partial \underline{u}}\right)^{T} \lambda(t) + \left( \frac{\partial g}{\partial \underline{u}}\right)^{T} &= 0 \\
                    \lambda(T) &= 0
                \end{align}
            \item compute the gradient:
                \begin{align}
                    \frac{dJ}{d \underline{\theta}} &= \int_{0}^{T} \left( \frac{\partial g}{\partial \underline{\theta}} + \lambda^{T}(t) \frac{\partial \underline{f}}{\partial \underline{\theta}} \right) dt
                        + \lambda(0) \frac{d \underline{u}_0}{d \underline{\theta}}
                \end{align}
        \end{enumerate}
    \end{tcolorbox}

    where the derivatives $\frac{\partial g}{\partial \underline{\theta}}$, $\frac{\partial \underline{f}}{\partial \underline{\theta}}$, $\frac{\partial \underline{f}}{\partial \underline{u}}$ can 
    be computed via automatic differentiation.