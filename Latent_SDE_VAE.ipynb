{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80222970",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 38px; color: black; font-weight: bold;\">\n",
    "Latent Neural SDE VAE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38425f08",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Biblio\n",
    "</div>\n",
    "\n",
    "Neural ODEs:\n",
    "\n",
    "**Neural ODEs (https://arxiv.org/abs/1806.07366) (2019)** : introduction of the Neural ODE as the continuous-time limit of a ResNet stack. Presentation of the use of the adjoint sensitivity method. Seminal paper for Neural ODE.\n",
    "\n",
    "**Latent ODEs for Irregularly-Sampled Time Series (https://arxiv.org/abs/1907.03907) (2019)** : Evolution of the Neural ODE model towards a Neural ODE RNN model, where the approximate posterior is built with a RNN on past observations.\n",
    "\n",
    "Neural SDEs:\n",
    "\n",
    "**SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic Differential Equations (https://arxiv.org/abs/2502.02472 , 2025)** : good background section (#2) to explain Neural SDE. Propose a new method SDE matching, inspired by score and flow matching, vs the adjoint sensivity method. SDE matching is claimed to be more efficient to compute gradients and train latent SDEs.\n",
    "\n",
    "**Scalable Gradients for Stochastic Differential Equations (https://arxiv.org/abs/2001.01328) (2020)** : generalization of the adjoint sensitivity method to SDEs. Combination with gradient-based stochastic variational inference for infinite-dimension VAEs.\n",
    "\n",
    "**Neural SDEs (https://www.researchgate.net/publication/333418188_Neural_Stochastic_Differential_Equations) (2019)** : link between infinitely deep residual networks and solutions to stochastic differential equations\n",
    "\n",
    "**Stable Neural SDEs in analyzing irregular time series data (https://arxiv.org/abs/2402.14989) (2025)** : points to the necessity of careful design of the drift and diffusion neural nets in latent SDEs. Introduces three latent SDEs models with performance guarantees.\n",
    "\n",
    "**Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations (https://arxiv.org/abs/2412.12112) (2024)** : application of neural SDEs to a biological use case (brain activity). Details the model, architecture, ELBO/loss computation. Takes into account inputs/commands in the model. \n",
    "\n",
    "General/Misc:\n",
    "\n",
    "**Efﬁcient gradient computation for dynamical models (https://www.fil.ion.ucl.ac.uk/~wpenny/publications/efficient_revised.pdf) (2014)** : summary of finite difference method, forward sensitivity method, adjoint sensitivity method, to compute gradients of a functional cost function. Applies to Neural ODEs training.\n",
    "\n",
    "**Cyclical Annealing Schedule: A Simple Approach to Mitigating KL Vanishing (https://arxiv.org/abs/1903.10145) (2019)** : explanation of the posterior collapse/KL vanishing problem, introduces different KL annealing schedules for VAE training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d885ce",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Code : torchsde library by Google Research\n",
    "</div>\n",
    "\n",
    "https://github.com/google-research/torchsde\n",
    "\n",
    "[1] Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, David Duvenaud. \"Scalable Gradients for Stochastic Differential Equations\". International Conference on Artificial Intelligence and Statistics. 2020. [arXiv]\n",
    "\n",
    "[2] Patrick Kidger, James Foster, Xuechen Li, Harald Oberhauser, Terry Lyons. \"Neural SDEs as Infinite-Dimensional GANs\". International Conference on Machine Learning 2021. [arXiv]\n",
    "\n",
    "[3] Patrick Kidger, James Foster, Xuechen Li, Terry Lyons. \"Efficient and Accurate Gradients for Neural SDEs\". 2021. [arXiv]\n",
    "\n",
    "[4] Patrick Kidger, James Morrill, James Foster, Terry Lyons, \"Neural Controlled Differential Equations for Irregular Time Series\". Neural Information Processing Systems 2020. [arXiv]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26b0c1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model & Math\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7c6bf",
   "metadata": {},
   "source": [
    "Data : $\\mathbf{X} = (x_{t_1}, x_{t_2}, ..., x_{t_N}) \\in \\mathbb{R}^{D_x}$ - assuming all $t_i \\in [0,1]$.\n",
    "\n",
    "The latent space has dimension $D_z$. The latent continuous dynamic is $\\mathbf{Z}$ defined by:\n",
    "\\begin{align*}\n",
    "z_0^{(\\theta)} &\\sim p_{\\theta_z}(z_0) \\\\\n",
    "dz_t^{(\\theta)} &= f_{\\theta}(z_t, t)dt + \\sigma_{\\theta}(z_t,t)dB_t \n",
    "\\end{align*}\n",
    "with: \n",
    "\\begin{align}\n",
    "\\textbf{drift} \\,& f_{\\theta} : \\mathbb{R}^{D_z} \\times [0,1] \\rightarrow \\mathbb{R}^{D_z} \\\\\n",
    "\\textbf{diffusion} \\,& \\sigma_{\\theta} : \\mathbb{R}^{D_z} \\times [0,1] \\rightarrow \\mathbb{R}^{D_z \\times D_z} \\\\\n",
    "\\textbf{Brownian motion} \\,& dB_t \\in \\mathbb{R}^{D_z}\n",
    "\\end{align}\n",
    "\n",
    "The decoder is classically:\n",
    "\\begin{align}\n",
    "p_{\\theta_x}(x_{t_i} \\vert z_{t_i})\n",
    "\\end{align}\n",
    "\n",
    "The approximate posterior (encoder) is also a SDE:\n",
    "\\begin{align}\n",
    "z_0^{(\\phi)} &\\sim q_{\\phi}(z_0 \\vert \\textbf{X}) \\\\\n",
    "dz_t^{(\\phi)} &= f_{\\phi}(z_t, t, \\textbf{X})dt + \\sigma_{\\theta}(z_t,t)dB_t \n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "- the drift $f_{\\phi}(z_t, t, \\textbf{X})$ is conditionned on observations $\\textbf{X}$\n",
    "- the diffusion of the approximate posterior is shared with the diffusion of the prior : $\\sigma_{\\theta}(z_t,t)$ - this ensures the application of Girsanov theorem and a finite KL divergence between the two stochastic processes (prior and approximate posterior) (see Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations (https://arxiv.org/abs/2412.12112) (2024))\n",
    "- drift and diffusion neural nets do not exhibit the same convergence guarantee (Stable Neural SDEs in analyzing irregular time series data (https://arxiv.org/abs/2402.14989) (2025))\n",
    "- non-diagonal diffusion seems to be difficult to simulate and costly to approximate (Scalable Gradients for Stochastic Differential Equations (https://arxiv.org/abs/2001.01328) (2020))\n",
    "- it seems a good practice to encode only part of the $\\textbf{X}$ in the approximate posterior : context vector (Scalable Gradients for Stochastic Differential Equations (https://arxiv.org/abs/2001.01328) (2020)), and $t_c << t_n$ in Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations (https://arxiv.org/abs/2412.12112) (2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f16593",
   "metadata": {},
   "source": [
    "Variational lower bound on the log marginal likelihood:\n",
    "\n",
    "We write:\n",
    "\\begin{align}\n",
    "p(x_{t_1:t_N}) &= \\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{p(z_{t_1:t_N} \\vert x_{t_1:t_N})}\n",
    "\\end{align}\n",
    "And:\n",
    "\\begin{align}\n",
    "\\log{p(x_{t_1:t_N})} &= \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{q_{\\phi}(z\\vert X)}\\frac{q_{\\phi}(z\\vert X)}{p(z_{t_1:t_N} \\vert x_{t_1:t_N})}} dz\n",
    "\\end{align}\n",
    "where $q_{\\phi}(z \\vert X)$ is formally is posterior distribution over **functions** $z : \\mathbb{R} \\rightarrow \\mathbb{R}^{D_z}$.\n",
    "Then:\n",
    "\\begin{align}\n",
    "\\log{p(x_{t_1:t_N})} &= \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{q_{\\phi}(z\\vert X)}} dz + \\mathbb{KL}(q_{\\phi}(z\\vert X) \\vert\\vert p(z_{t_1:t_N} \\vert x_{t_1:t_N}))\n",
    "\\end{align}\n",
    "where we -audaciously- consider $p(z_{t_1:t_N} \\vert x_{t_1:t_N})$ as a dsitribution over functions $z$ taking values $z_{t_1:t_N}$ at times $t_1:t_N$ so the $\\mathbb{KL}$ actually means something.\n",
    "Still on the same path:\n",
    "\\begin{align}\n",
    "\\log{p(x_{t_1:t_N})} &\\geq \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{q_{\\phi}(z\\vert X)}} dz \\\\\n",
    "&= \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N} \\vert z_{t_1:t_N})}{q_{\\phi}(z\\vert X)} p(z_{t_1:t_N})} dz \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z \\vert X)} \\log{p(x_{t_1:t_N} \\vert z_{t_1:t_N})} - \\mathbb{KL}(q_{\\phi}(z\\vert X) \\vert\\vert p(z_{t_1:t_N})) \\\\\n",
    "\\end{align}\n",
    "We write -still audaciously-\n",
    "\\begin{align}\n",
    "\\mathbb{KL}(q_{\\phi}(z\\vert X) \\vert\\vert p(z_{t_1:t_N})) &= \\mathbb{KL}(q_{\\phi}(z_0\\vert X) \\vert\\vert p_{\\theta_z}(z_0)) + \\mathbb{KL}(q_{\\phi}(z_{>0}\\vert X) \\vert\\vert p_{\\theta_z}(z_{>0}))\n",
    "\\end{align}\n",
    "where the first $\\mathbb{KL}$ on the r.h.s is a classic between two probability distributions over a random variable, and the second is derived from the Girsanov's theorem as:\n",
    "\\begin{align}\n",
    "\\mathbb{KL}(q_{\\phi}(z_{>0}\\vert X) \\vert\\vert p_{\\theta_z}(z_{>0})) &= \\frac{1}{2} \\mathbb{E}_{q_{\\phi}(z_{>0}\\vert X)} \\left( \\int_{0}^{T} \\vert \\Delta(t) \\vert^2 dt \\right) \\\\\n",
    "\\Delta(t) &= \\sigma_{\\theta}^{-1}(z_t,t) (f_{\\phi}(z_t, t, \\textbf{X}) - f_{\\theta}(z_t, t))\n",
    "\\end{align}\n",
    "\n",
    "Finally:\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta, \\phi, \\textbf{X}) &= \\mathbb{E}_{q_{\\phi}(z \\vert X)} \\log{p(x_{t_1:t_N} \\vert z_{t_1:t_N})} - \\mathbb{KL}(q_{\\phi}(z_0\\vert X) \\vert\\vert p_{\\theta_z}(z_0)) - \\frac{1}{2} \\mathbb{E}_{q_{\\phi}(z_{>0}\\vert X)} \\left( \\int_{0}^{T} \\vert \\Delta(t) \\vert^2 dt \\right)\n",
    "\\end{align}\n",
    "\n",
    "During training:\n",
    "- the integral is approximated via numerical integration\n",
    "- expectations are estimated with MC sampling\n",
    "- NB : sampling is actually : sampling $z_0 \\sim q_{\\phi}(z_0 \\vert \\textbf{X})$ and sampling a function $z$ by sampling a Brownian motion path $B_t$ and computing the whole realization path $z_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ad2f6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Set Up\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c507af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsde\n",
    "# from torchdiffeq import odeint, odeint_adjoint\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import timeit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bcf728",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fb066",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Data and Problem Statement\n",
    "</div>\n",
    "\n",
    "- The experiment is an unknown stochastic process $dX_t = f(X_t,t)dt + \\sigma(X_t,t)dB_t$\n",
    "- We observe several sample paths of this stochastic process.\n",
    "- Each sample path is a collection $\\{ (t_1, x_{t_1}), (t_2, x_{t_2}), ..., (t_n, x_{t_n}) \\}$ of $n$ data points at observation times $(t_i)_{1 \\leq i \\leq n}$. NB : $n$ may vary by sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb776b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 8 # batch size, ie number of sample paths\n",
    "LENGTH = 100 # total number of points used to draw a full path of the stochastic process\n",
    "N_POINTS = 50 # total number of points that are actually observed in the stochastic process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea1670",
   "metadata": {},
   "source": [
    "Data Generating SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1864017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we create an Ornstein Uhlenbeck SDE model:\n",
    "# dX_t = theta * (mu - X_t) dt + sigma dB_t\n",
    "# theta, mu, sigma scalar parameters\n",
    "# B_t is a standard 1D Brownian motion\n",
    "\n",
    "# SDE are instantiated as subclasses of nn.Module\n",
    "\n",
    "class DataGeneratingSDE(nn.Module):\n",
    "    def __init__(self, theta, mu, sigma):\n",
    "        \n",
    "        # noise type can take 4 values : \"diagonal\", \"general\", \"additive\", \"scalar\"\n",
    "        # here we use \"diagonal\" : the diffusion function g(t,y) is an element wise function,\n",
    "        # its output has the same shape as y, ie (batch_size, state_size)\n",
    "        \n",
    "        # sde_type can be \"ito\" or \"stratonovich\"\n",
    "        # we use \"ito\" here. The available methods for computation are Euler(-Maruyama), Milstein, SRK.\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        \n",
    "        # we register the parameters so we can save them. But we will not train them.\n",
    "        self.register_buffer(\"theta\", torch.tensor(theta))\n",
    "        self.register_buffer(\"mu\", torch.tensor(mu))\n",
    "        self.register_buffer(\"sigma\", torch.tensor(sigma))\n",
    "\n",
    "    # DRIFT FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the drift at time t and state y\n",
    "    # note : the functions f and g must be able to handle inputs of shape (batch_size, state_size)\n",
    "    # for any batch_size >= 1\n",
    "    def f(self, t, y):\n",
    "        return self.theta * (self.mu - y)\n",
    "    \n",
    "    # DIFFUSION FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the diffusion at time t and state y\n",
    "    # (NB : generally, the output of g is of shape (batch_size, state_size, brownian_size) when noise_type is \"general\")\n",
    "    def g(self, t, y):\n",
    "        return self.sigma * torch.ones_like(y)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        msg = f\"Ornstein Uhlenbeck SDE Model - mu = {self.mu:.3f}, theta = {self.theta:.3f}, sigma = {self.sigma:.3f}\"\n",
    "        return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70645eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "theta = torch.distributions.Uniform(0.1, 1.0).rsample()\n",
    "mu = torch.distributions.Uniform(-1.0, 1.0).rsample()\n",
    "sigma = torch.distributions.Uniform(0.01, 1.0).rsample()\n",
    "datamodel = DataGeneratingSDE(theta=theta.item(), mu=mu.item(), sigma=sigma.item()).to(device)\n",
    "\n",
    "print(f\"Data Generating Model : {datamodel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc78a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form dataset\n",
    "\n",
    "# times\n",
    "t_start = 0.0\n",
    "t_end = 10.0\n",
    "times = torch.linspace(t_start, t_end, LENGTH).to(device) # (LENGTH)\n",
    "all_times = times.repeat(B,1) # (B, LENGTH)\n",
    "       \n",
    "print(f\"All times for data generation : {all_times.shape} (batch, length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b860d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "Dx = 1 # dimension - 1 as it is a univariate time serie\n",
    "\n",
    "# sampling full data paths\n",
    "y_start = 0.0\n",
    "y0s = torch.full((B,1),y_start).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_data = torchsde.sdeint(datamodel, y0s, times, method='euler', dt=1e-3) # (N_POINTS,B,1)\n",
    "    \n",
    "all_data = all_data.permute(1,0,2) # (B,N_POINTS,1)\n",
    "# print(f\"Computed full sample paths : {all_data.shape} (length,batch,1)\")\n",
    "\n",
    "# extract some subsets in each sample path\n",
    "for b in range(B):\n",
    "    idx = np.random.choice(np.arange(LENGTH), N_POINTS, replace=False)  # indices to pick\n",
    "    idx = np.sort(idx) # sort them to have increasing times\n",
    "    observation_ts = times[idx] # (N_POINTS) \n",
    "    sampled_d = all_data[b,idx] # (N_POINTS,1)\n",
    "    if b==0:\n",
    "        sampled_data = sampled_d.detach().unsqueeze(0)\n",
    "        observation_times = observation_ts.detach().unsqueeze(0)\n",
    "    else:\n",
    "        sampled_data = torch.cat([sampled_data, sampled_d.detach().unsqueeze(0)], dim=0)\n",
    "        observation_times = torch.cat([observation_times, observation_ts.detach().unsqueeze(0)], dim=0) # (B,N_POINTS)\n",
    "\n",
    "# print(f\"Observations times : {observation_times.shape}\")\n",
    "# print(f\"Sampled data : {sampled_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DISPLAY=5\n",
    "fig, ax = plt.subplots(nrows=1, ncols=N_DISPLAY, figsize=(6*N_DISPLAY,4))\n",
    "idx = np.random.choice(np.arange(B),N_DISPLAY,replace=False)\n",
    "for i,id in enumerate(idx):\n",
    "    ax[i].plot(all_times[id].squeeze().detach().cpu().numpy(), all_data[id,:].squeeze().detach().cpu().numpy(), label='full ground truth path', color='blue')\n",
    "    ax[i].scatter(observation_times[id].squeeze().detach().cpu().numpy(), sampled_data[id].squeeze().detach().cpu().numpy(), s=100, label='sampled points in path', color='green', marker='o')\n",
    "    ax[i].legend()\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(f'Sample Path {id}/{B}')\n",
    "    \n",
    "fig.suptitle(f'Data samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DATA GENERATING MODEL\")\n",
    "print(datamodel)\n",
    "print()\n",
    "print(f\"DATA SUMMARY\")\n",
    "print()\n",
    "print(f\"LENGTH of full sample path : {LENGTH}\")\n",
    "print(f\"BATCH of paths : {B}\")\n",
    "print(f\"Number of points N_POINTS observed in each path : {N_POINTS}\")\n",
    "print()\n",
    "print(f\"Tensor of full paths : {all_data.shape} (BATCH,LENGTH,1)\")\n",
    "print(f\"Tensor of all times : {all_times.shape} (BATCH,LENGTH)\")\n",
    "print()\n",
    "print(f\"Tensor of sampled paths : {sampled_data.shape} (BATCH,N_POINTS,1)\")\n",
    "print(f\"Tensor of sampling times : {observation_times.shape} (BATCH,N_POINTS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ef715",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 38px; color: black; font-weight: bold;\">\n",
    "Model and Pipeline\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f4aa3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : parameters\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = 1  # observation space dimension\n",
    "Dz = 4  # latent space dimension\n",
    "Dl = 16 # LSTM dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deefcf00",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : posterior 1/2 : Context LSTM\n",
    "</div>\n",
    "\n",
    "- Context LSTM - Encodes $(t_i, x_{t_i})_{1 \\leq i \\leq N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextLSTM(nn.Module):\n",
    "    \"\"\"LSTM model class to encode all observations,\n",
    "    with their observation times, into a context\n",
    "    vector that will be used in the posterior\n",
    "    \"\"\"\n",
    "    def __init__(self, lstm_dim=Dl, n_layers=1, input_dim=Dx):\n",
    "        # inputs:\n",
    "        # lstm_dim : dimension of the LSTM\n",
    "        # n_layers : number of LSTM layers\n",
    "        # input_dim : input dimension, defaults to 1 (univariate time series)\n",
    "        super().__init__()\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_dim + 1, # add 1 for time dimension\n",
    "            hidden_size=self.lstm_dim,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "    def forward(self,t,x):\n",
    "        # inputs:\n",
    "        # t : tensor (N,) of time stamps for a given single sample path\n",
    "        # x : tensor (N,input_dim) of observations at times t for the single sample path\n",
    "        # outputs:\n",
    "        # h : tensor (lstm_dim) of hidden stats encoding (t,x)\n",
    "        x_ext = torch.cat([t.unsqueeze(-1),x], dim=-1) # (N,input_dim+1)\n",
    "        _,(hn,_) = self.lstm(x_ext) # hn (1,lstm_dim)\n",
    "        \n",
    "        return hn.squeeze() # (lstm_dim) even if the input is batched with B=1\n",
    "\n",
    "    def __repr__(self):\n",
    "        description = f\"ContextLSTM with lstm_dim = {self.lstm_dim}, n_layers = {self.n_layers}, input_dim = {self.input_dim}\"\n",
    "        description += f\"\\nLSTM net : {self.lstm}\"\n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d383d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test LSTM\n",
    "context_lstm = ContextLSTM(input_dim=Dx).to(device)\n",
    "print(context_lstm)\n",
    "\n",
    "t_in = torch.randn(50).to(device)\n",
    "x_in = torch.randn(50,Dx).to(device)\n",
    "\n",
    "context = context_lstm(t_in, x_in)\n",
    "\n",
    "print(f\"Inputs:\")\n",
    "print(f\"\\ttimes : {t_in.shape}\")\n",
    "print(f\"\\tobservations : {x_in.shape}\")\n",
    "print(f\"Outputs:\")\n",
    "print(f\"\\thidden state : {context.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf48ff",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : posterior 2/2 : Posterior for initial values of the SDEs\n",
    "</div>\n",
    "\n",
    "- $q_{\\phi}(z_0) \\sim \\mathcal{N}(\\mu_{\\phi}(X), \\sigma_{\\phi}(X))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f97d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior distribution for starting value\n",
    "\n",
    "class EncoderStartingValue(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder for the starting value of the latent variable.\n",
    "    Uses the context vector from the LSTM to parameterize\n",
    "    the mean and log-variance of a Gaussian distribution.\n",
    "    NB : we assume a diagonal covariance matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, context_dim=Dl, latent_dim=Dz, n_layers=1, hidden_dim=32):\n",
    "        # inputs:\n",
    "        # context_dim : dimension of the context vector. This is the dimension of the LSTM (Dl)\n",
    "        # latent_dim ; latent space dimension (Dz)\n",
    "        # n_layers, hidden_dim : number and size of layers of the MLP\n",
    "        super().__init__()\n",
    "        self.context_dim = context_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = self.context_dim\n",
    "        for i in range(self.n_layers):\n",
    "            layers.append(nn.Linear(input_dim, self.hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            input_dim = self.hidden_dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.mean = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        self.logvar = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        \n",
    "    def forward(self, c):\n",
    "        # input:\n",
    "        # c : context vector, tensor (B,context_dim)\n",
    "        # output:\n",
    "        # mean : tensor (B, latent_dim) : mean of the Gaussian\n",
    "        # logvar : tensor (B, latent_dim) : log var of the Gaussian\n",
    "        x = self.mlp(c)\n",
    "        mean = self.mean(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mean, logvar\n",
    "\n",
    "    def __repr__(self):\n",
    "        description = f\"Encoder of Starting Value z0 given X\\n\"\n",
    "        description += f\"\\tInput size (context vector) : {self.context_dim}\\n\"\n",
    "        description += f\"\\tOutput dimension (latent vector dimension) : {self.latent_dim}\\n\"\n",
    "        description += f\"\\tMLP : {self.mlp}\\n\"\n",
    "        description += f\"\\tMean : {self.mean}\\n\"\n",
    "        description += f\"\\tLog var : {self.logvar}\"\n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36aa7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_start = EncoderStartingValue().to(device)\n",
    "print(encoder_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=3\n",
    "\n",
    "mean_z0_post, logvar_z0_post = encoder_start(context)\n",
    "cov_z0_post = torch.diag_embed(torch.exp(logvar_z0_post)).to(device)\n",
    "\n",
    "q_phi_z0 = torch.distributions.MultivariateNormal(\n",
    "    loc=mean_z0_post,\n",
    "    covariance_matrix=cov_z0_post\n",
    ")\n",
    "\n",
    "z0s_post = q_phi_z0.rsample((K,)).to(device)\n",
    "\n",
    "print(f\"Sampling Posterior initial values z0s for the SDEs\")\n",
    "print(f\"\\tDistribution mean : {mean_z0_post.shape}\")\n",
    "print(f\"\\tCovariance matrix : {cov_z0_post.shape}\")\n",
    "print(f\"\\tDistribution object : {q_phi_z0}\")\n",
    "print(f\"Sampling {K} samples : {z0s_post.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa60051",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : Posterior and Prior SDEs\n",
    "</div>\n",
    "\n",
    "- Posterior : $dZ_t^{(\\phi)} = f_{\\phi}(Z_t,t \\vert X)dt + \\sigma_{\\theta}(Z_t,t)dB_t$\n",
    "- Prior : $dZ_t^{(\\theta)} = f_{\\theta}(Z_t,t)dt + \\sigma_{\\theta}(Z_t,t)dB_t$\n",
    "\n",
    "Here, we choose to implement both the prior and the posterior in the same class (see torchsde.sdeint documentation):\n",
    "- this allows to share the same diffusion by design\n",
    "- this allows a library-based computation of the KL between the two SDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(nn.Module):\n",
    "    \"\"\"\n",
    "    Latent SDE class\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=Dx, latent_dim=Dz, lstm_dim=Dl, hidden_dim=32):\n",
    "        # we use a diagonal noise type\n",
    "        # the SDE type is \"Ito\"\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        self.Dx = input_dim\n",
    "        self.Dz = latent_dim\n",
    "        self.Dl = lstm_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Ornstein Uhlenbeck prior parameters\n",
    "        self.kappa = 1.0\n",
    "        self.mu = 0.0\n",
    "        # basic z|x encoder seen above\n",
    "        self.encoder = ContextLSTM(lstm_dim=self.Dl, input_dim=self.Dx)\n",
    "        self.context = None # context tensor\n",
    "        # MLP for posterior drift\n",
    "        self.posterior_drift = nn.Sequential(\n",
    "            nn.Linear(self.Dz+self.Dl, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.Dz)\n",
    "        )\n",
    "        # MLP for shared diagonal diffusion\n",
    "        self.shared_diffusion = nn.Sequential(\n",
    "            nn.Linear(self.Dz+self.Dl, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.Dz)\n",
    "        )\n",
    "        \n",
    "    def encode(self,t,x):\n",
    "        # separate method to encode data:\n",
    "        # inputs :\n",
    "        # t : time steps, tensor (B,N)\n",
    "        # x : observations at times t, tensor (B,N,Dx)\n",
    "        # NB : the encoding is different for each instance of the batch,\n",
    "        #      as the observation times are different accross samples\n",
    "        #      So we need to iterate over the batchs\n",
    "        b = x.size(0)  # batch shape\n",
    "        for i in range(b):\n",
    "            ctx = self.encoder(t[i], x[i]) # return a tensor shape (lstm_dim=Dl)\n",
    "            if i==0:\n",
    "                context = ctx.unsqueeze(0)\n",
    "            else:\n",
    "                context = torch.cat([context, ctx.unsqueeze(0)], dim=0)\n",
    "            self.context = context # B,Dl\n",
    "\n",
    "    def f(self,t,z):\n",
    "        \"\"\"Posterior drift\"\"\"\n",
    "        # assume self.context has been computed\n",
    "        # inputs:\n",
    "        # NB : S is the batch dimension for torchsde, ie the number of sampled paths for one SDE\n",
    "        # t : times tensor (S,1) : unused. Time is taken into account in the context\n",
    "        #     computed from self.encoder\n",
    "        # z : variable tensor (S,Dz)\n",
    "        # outputs:\n",
    "        # f(t,z) : drift tensor (S,Dz)\n",
    "        \n",
    "        # when we run one SDE (input S=1) with K samples of z,\n",
    "        # we have inputs self.context (1,Dl) and z (K,Dz)\n",
    "        # we handle it here:\n",
    "        if self.context.size(0)==1 and z.size(0)>1:\n",
    "            K = z.size(0)\n",
    "            ctx = self.context.repeat(K,1) # ctx (K,Dl)\n",
    "        else:\n",
    "            ctx = self.context\n",
    "        z_ext = torch.cat([ctx, z], dim=-1) # form (S,Dl+Dz)\n",
    "        posterior_drift = self.posterior_drift(z_ext) # (S,Dz)\n",
    "        return posterior_drift\n",
    "\n",
    "    def g(self,t,z):\n",
    "        \"\"\"Shared diffusion\"\"\"\n",
    "        # assume self.context has been computed\n",
    "        # inputs : t,z as above\n",
    "        # outputs : g(t,z) : diagonal diffusion (S,Dz)\n",
    "        if self.context.size(0)==1 and z.size(0)>1:\n",
    "            K = z.size(0)\n",
    "            ctx = self.context.repeat(K,1) # ctx (K,Dl)\n",
    "        else:\n",
    "            ctx = self.context\n",
    "        z_ext = torch.cat([ctx, z], dim=-1) # form (S,Dl+Dz)\n",
    "        # z_ext = torch.cat([self.context, z], dim=-1) # form (S,Dl+Dz)\n",
    "        shared_diffusion = self.shared_diffusion(z_ext) # (S,Dz)\n",
    "        return shared_diffusion\n",
    "    \n",
    "    def h(self,t,z):\n",
    "        \"\"\"Prior drift\"\"\"\n",
    "        # here, we posit a fixed Ornstein Uhlenbeck\n",
    "        prior_drift = self.kappa * (self.mu - z)\n",
    "        return prior_drift\n",
    "    \n",
    "    def __repr__(self):\n",
    "        d = f\"Latent SDE Model - Dz = {self.Dz} - LSTM dim = {self.Dl}\\n\"\n",
    "        d += f\"\\tLSTM Encoder : {self.encoder}\\n\"\n",
    "        d += f\"\\tPosterior Drift : {self.posterior_drift}\\n\"\n",
    "        d += f\"\\tPrior Drift : fixed, O.U with kappa = {self.kappa}; mu = {self.mu}\\n\"\n",
    "        d += f\"\\tShared Diffusion : {self.shared_diffusion}\"\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26969fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sde = LatentSDE().to(device)\n",
    "print(model_sde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test encode method\n",
    "print(f\"Context tensor before encoding : {model_sde.context}\")\n",
    "model_sde.encode(observation_times, sampled_data)\n",
    "print(f\"Context tensor after encoding : {model_sde.context.shape}\") # (B,Dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46aaeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test posterior drift\n",
    "z = torch.randn((B,Dz)).to(device)\n",
    "posterior_drift = model_sde.f(observation_times[:,0], z)\n",
    "print(f\"Posterior drift:\\n\\tinputs: t = {observation_times[:,0].shape}, z = {z.shape}\\n\\toutputs : posterior drift = {posterior_drift.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8fd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prior drift\n",
    "prior_drift = model_sde.h(observation_times[:,0], z)\n",
    "print(f\"Prior O.U. drift:\\n\\tinputs: t = {observation_times[:,0].shape}, z = {z.shape}\\n\\toutputs : prior drift = {prior_drift.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test shared diffusion\n",
    "diff = model_sde.g(observation_times[:,0], z)\n",
    "print(f\"Shared diffusion:\\n\\tinputs: t = {observation_times[:,0].shape}, z = {z.shape}\\n\\toutputs : diffusion = {diff.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing sdeint works\n",
    "\n",
    "# we have a total of B observations, sampled at different times.\n",
    "# for each observation, we run a separate SDE, on a set of K samples z0.\n",
    "# in the end, we get (B,K) sample paths, K sample paths for each SDE within the batch B.\n",
    "\n",
    "K = 3\n",
    "# NB : need to robustify the posterior_drift method for K>1, as self.context and z have different dim=0 then\n",
    "z0s_post = q_phi_z0.rsample((B,K)).to(device)\n",
    "print(f\"Sampling {K} initial values for each of the {B} SDEs to compute\")\n",
    "print(f\"Initial values : {z0s_post.shape}\") # (B,K,Dz) - K can possibly be one, but needs to be specified K=1 if this is the case\n",
    "\n",
    "for i in tqdm(range(B)):\n",
    "    # one SDE per instance within the batch of size B\n",
    "    current_observation_times = observation_times[i,:].squeeze(0) # (B,N) => (1,N) with [i,:] => (N,) with squeeze(0)\n",
    "    current_observed_data = sampled_data[i,:,:] # (B,N,1) => (N,1)\n",
    "    # debug\n",
    "    print(f\"input 1 : z0s[i,:,:] = {z0s_post[i,:,:].shape}\")  # (K,Dz)\n",
    "    print(f\"input 2 : current_observation_times = { current_observation_times.shape}\") # (N,)\n",
    "    print(f\"input 3 : current_observed_data = {current_observed_data.shape}\") # (N,1)\n",
    "    # we encode the observation times (N,)\n",
    "    model_sde.encode(current_observation_times.unsqueeze(0), current_observed_data.unsqueeze(0)) # (1,N) and (1,N,1) => (1,Dl)\n",
    "    print(f\"Encoded observations have produced context : {model_sde.context.shape}\") # (1,Dl)\n",
    "    # the posterior drift and shared diffusion can handle z0s[i,:,:] (K,Dz) and current_observation_times (N,) for K>1 with a repeat\n",
    "    current_zs = torchsde.sdeint(model_sde, z0s_post[i,:,:], current_observation_times, method='euler', dt=1e-3) # (N,K,Dz)\n",
    "    if i==0:\n",
    "        zs_post = current_zs.unsqueeze(0).detach()  # we use .detach() as we do not need to keep the computational graph\n",
    "        # the gradient computation will happen wrt to the model paramters, not the data.\n",
    "    else:\n",
    "        zs_post = torch.cat([zs_post, current_zs.unsqueeze(0).detach()], dim=0)\n",
    "    print(f\"The current SDE has produced a solution : {current_zs.shape}\") # (N,K,Dz) => (1,N,K,Dz) with unsqueeze(0)\n",
    "        \n",
    "print(f\"\\nTotal Batched solutions : Posterior zs = {zs_post.shape}\") # (B,N,K,Dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3870de",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : Decoder\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder from z (B,K,Dz) to x (B,K,1).\n",
    "    We assume here a Gaussian distribution with diagonal covariance\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=Dz, obs_dim=Dx, n_layers=1, hidden_dim=32):\n",
    "        # inputs:\n",
    "        # latent_dim ; latent space dimension (Dz)\n",
    "        # obs_dim : observation space dimension (Dx)\n",
    "        # n_layers, hidden_dim : number and size of layers of the MLP\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.obs_dim = obs_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = self.latent_dim\n",
    "        for i in range(self.n_layers):\n",
    "            layers.append(nn.Linear(input_dim, self.hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            input_dim = self.hidden_dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.mean = nn.Linear(self.hidden_dim, self.obs_dim)\n",
    "        self.logvar = nn.Linear(self.hidden_dim, self.obs_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # input:\n",
    "        # z : context vector, tensor (B,latent_dim) or (B,K,latent_dim)\n",
    "        # output:\n",
    "        # mean : tensor (B, obs_dim) or (B,K,obs_dim): mean of the Gaussian\n",
    "        # logvar : tensor (B, obs_dim) or (B,K,obs_dim): log var of the Gaussian\n",
    "        x = self.mlp(z)\n",
    "        mean = self.mean(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mean, logvar\n",
    "\n",
    "    def __repr__(self):\n",
    "        description = f\"Gaussian Decoder of x given z\\n\"\n",
    "        description += f\"\\tInput size (latent variable dimension) : {self.latent_dim}\\n\"\n",
    "        description += f\"\\tOutput dimension (observation vector dimension) : {self.obs_dim}\\n\"\n",
    "        description += f\"\\tMLP : {self.mlp}\\n\"\n",
    "        description += f\"\\tMean : {self.mean}\\n\"\n",
    "        description += f\"\\tLog var : {self.logvar}\"\n",
    "        return description        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3601f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate decoder\n",
    "decoder = GaussianDecoder().to(device)\n",
    "print(decoder)\n",
    "\n",
    "# compute mean and logvar\n",
    "# z = torch.randn((B,N_POINTS,K,Dz))\n",
    "mu_x, logvar_x = decoder(zs_post) # (B,N,K,Dx) ; (B,N,K,Dx)\n",
    "print(f\"\\ninputs : {z.shape}\")\n",
    "print(f\"outputs : mu_x {mu_x.shape}, logvar_x {logvar_x.shape}\")\n",
    "\n",
    "# instantiate distribution\n",
    "cov_x = torch.diag_embed(torch.exp(logvar_x)).to(device) # (B,N,K,Dx,Dx)\n",
    "p_theta_x = torch.distributions.MultivariateNormal(loc=mu_x, covariance_matrix=cov_x)\n",
    "print(f\"\\nDistribution p_theta_x : {p_theta_x}\")\n",
    "print(f\"\\tbatch shape : {p_theta_x.batch_shape}\") # (B,N,K)\n",
    "print(f\"\\tEvent shape : {p_theta_x.event_shape}\") # (Dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed2197",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : prior\n",
    "</div>\n",
    "\n",
    "The latent space has dimension $D_z$. \n",
    "\n",
    "The latent prior is a Ornstein Uhlenbeck process $\\mathbf{Z}$ defined by:\n",
    "\\begin{align*}\n",
    "z_0^{(\\theta)} &\\sim p_{\\theta_z}(z_0) \\\\\n",
    "dz_t^{(\\theta)} &= \\kappa (\\mu - z_t) dt + \\sigma_{\\theta}(z_t,t)dB_t \n",
    "\\end{align*}\n",
    "with: \n",
    "\\begin{align}\n",
    "\\textbf{drift} \\,& f_{\\theta}(z_t,t) = \\kappa (\\mu - z_t) \\\\\n",
    "\\kappa &\\in \\mathbb{R} \\\\\n",
    "\\mu &\\in \\mathbb{R}^{D_z} \\\\\n",
    "\\textbf{diffusion} \\,& \\sigma_{\\theta} : \\mathbb{R}^{D_z} \\times [0,1] \\rightarrow \\mathbb{R}^{D_z \\times D_z} \\\\\n",
    "\\textbf{Brownian motion} \\,& dB_t \\in \\mathbb{R}^{D_z}\n",
    "\\end{align}\n",
    "\n",
    "The $\\textbf{diffusion}$ is a MLP shared with the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17126f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample prior staring values z0s\n",
    "mean_z0_prior = torch.zeros(Dz).to(device)\n",
    "cov_z0_prior = torch.eye(Dz).to(device)\n",
    "p_z0_prior = torch.distributions.MultivariateNormal(loc=mean_z0_prior, covariance_matrix=cov_z0_prior)\n",
    "z0s_prior = p_z0_prior.rsample((K,))\n",
    "\n",
    "print(f\"Sampling Prior initial values z0s for the SDEs\")\n",
    "print(f\"\\tDistribution mean : {mean_z0_prior.shape}\")\n",
    "print(f\"\\tCovariance matrix : {cov_z0_prior.shape}\")\n",
    "print(f\"\\tDistribution object : {p_z0_prior}\")\n",
    "print(f\"Sampling {K} samples : {z0s_prior.shape}\")\n",
    "\n",
    "# NB : we do not explicitely sample prior paths. We only need the KL, which is computed internally with logqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we compute (again) the posterior AND the KL with the prior\n",
    "\n",
    "for i in tqdm(range(B)):\n",
    "    # one SDE per instance within the batch of size B\n",
    "    current_observation_times = observation_times[i,:].squeeze(0) # (B,N) => (1,N) with [i,:] => (N,) with squeeze(0)\n",
    "    current_observed_data = sampled_data[i,:,:] # (B,N,1) => (N,1)\n",
    "    # debug\n",
    "    print(f\"input 1 : z0s[i,:,:] = {z0s_post[i,:,:].shape}\")  # (K,Dz)\n",
    "    print(f\"input 2 : current_observation_times = { current_observation_times.shape}\") # (N,)\n",
    "    print(f\"input 3 : current_observed_data = {current_observed_data.shape}\") # (N,1)\n",
    "    # we encode the observation times (N,)\n",
    "    model_sde.encode(current_observation_times.unsqueeze(0), current_observed_data.unsqueeze(0)) # (1,N) and (1,N,1) => (1,Dl)\n",
    "    print(f\"Encoded observations have produced context : {model_sde.context.shape}\") # (1,Dl)\n",
    "    # the posterior drift and shared diffusion can handle z0s[i,:,:] (K,Dz) and current_observation_times (N,) for K>1 with a repeat\n",
    "    current_zs, kl_path = torchsde.sdeint(model_sde, z0s_post[i,:,:], current_observation_times, method='euler', dt=1e-3, logqp=True) # (N,K,Dz)\n",
    "    if i==0:\n",
    "        zs_post = current_zs.unsqueeze(0).detach()  # we use .detach() as we do not need to keep the computational graph\n",
    "        kl_paths = kl_path.unsqueeze(0).clone() # we use clone() as we will need the computaional graph\n",
    "        # the gradient computation will happen wrt to the model paramters, not the data.\n",
    "    else:\n",
    "        zs_post = torch.cat([zs_post, current_zs.unsqueeze(0).detach()], dim=0)\n",
    "        kl_paths = torch.cat([kl_paths, kl_path.unsqueeze(0).clone()], dim=0)\n",
    "    print(f\"The current SDE has produced a solution : {current_zs.shape}\") # (N,K,Dz) => (1,N,K,Dz) with unsqueeze(0)\n",
    "    print(f\"And a KL between prior and posterior SDEs : {kl_path.shape}\") # (N-1,K)\n",
    "        \n",
    "print(f\"\\nTotal Batched solutions : Posterior zs = {zs_post.shape}\") # (B,N,K,Dz)\n",
    "print(f\"Total KL tensor : {kl_paths.shape}\") # (B,N-1,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84604ece",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Computing losses and backpropagating\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_z0 = torch.distributions.kl_divergence(q_phi_z0, p_z0_prior)  # (1)\n",
    "kl_sde = kl_paths.mean()  # (B,N-1,K) => (1)\n",
    "\n",
    "print(f\"KL between initial value distribution p_z0 and q_z0 : {kl_z0:.3e}\")\n",
    "print(f\"KL path tensor : {kl_paths.shape} => KL path : {kl_sde:.3e}\")\n",
    "\n",
    "xs = sampled_data.unsqueeze(-1).repeat(1,1,K,1) # (B,N,Dx=1) => (B,N,1,Dx=1) => (B,N,K,Dx)\n",
    "rec_loss = p_theta_x.log_prob(xs)  # (B,N,K)\n",
    "print(f\"rec_loss tensor : {rec_loss.shape}\")\n",
    "rec_loss = rec_loss.mean(dim=2).sum(dim=1).mean() # (B,N,K) => (1)\n",
    "print(f\"rec_loss : {rec_loss:.3e}\")\n",
    "\n",
    "loss = -rec_loss + kl_z0 + kl_sde \n",
    "print(f\"loss totale : {loss:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add75254",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 28px; color: black; font-weight: bold;\">\n",
    "Training\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd218dbd",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Data Loaders\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2efeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form datasets and dataloaders for PyTorch training\n",
    "class SDEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, times, data):\n",
    "        self.t = times.detach()\n",
    "        self.x = data.detach()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.t[idx], self.x[idx]\n",
    "    \n",
    "train_ratio = 0.8\n",
    "id_train = int(train_ratio * len(sampled_data))\n",
    "\n",
    "train_dataset = SDEDataset(observation_times[:id_train], sampled_data[:id_train])\n",
    "test_dataset = SDEDataset(observation_times[id_train:], sampled_data[id_train:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2) #, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2) #, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "K = 3\n",
    "\n",
    "model_sde = LatentSDE().to(device)\n",
    "encoder_start = EncoderStartingValue().to(device)\n",
    "decoder = GaussianDecoder().to(device)\n",
    "\n",
    "parameters = list(model_sde.parameters()) + list(encoder_start.parameters()) + list(decoder.parameters())\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(parameters, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_epoch_loss = []\n",
    "list_kl_z0s = []\n",
    "list_kl_sdes = []\n",
    "list_rec_loss = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    # perform one training step\n",
    "    model_sde.train()\n",
    "    encoder_start.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    kl_z0s = 0.0\n",
    "    kl_sdes = 0.0\n",
    "    rec_loss_total = 0.0\n",
    "    \n",
    "    for j, (t_batch, x_batch) in enumerate(train_loader):\n",
    "        # -- data\n",
    "        # t_batch : (B,N)\n",
    "        # x_batch : (B,N,Dx)\n",
    "        # -- compute context\n",
    "        batch_size = t_batch.size(0)\n",
    "        for i in tqdm(range(batch_size), disable=True):\n",
    "            current_observations_times = t_batch[i,:].squeeze(0) # (N,)\n",
    "            current_observed_data = x_batch[i,:,:] # (N,Dx=1)\n",
    "            # encode into context\n",
    "            model_sde.encode(current_observation_times.unsqueeze(0), current_observed_data.unsqueeze(0)) # (1,N) and (1,N,1) => (1,Dl)\n",
    "            # compute posterior initial value\n",
    "            mean_z0_post, logvar_z0_post = encoder_start(model_sde.context)\n",
    "            cov_z0_post = torch.diag_embed(torch.exp(logvar_z0_post)).to(device)\n",
    "            q_phi_z0 = torch.distributions.MultivariateNormal(\n",
    "                loc=mean_z0_post,\n",
    "                covariance_matrix=cov_z0_post\n",
    "            )\n",
    "            z0s_post = q_phi_z0.rsample((K,)).to(device)  # (K,Dl) ??\n",
    "            # print(f\"z0s_post : {z0s_post.shape}\")\n",
    "            # print(f\"q_phi_z0 : {q_phi_z0}\")\n",
    "            # compute posterior paths\n",
    "            current_zs, kl_path = torchsde.sdeint(model_sde, z0s_post[i,:,:], current_observation_times, method='euler', dt=1e-3, logqp=True) # (N,K,Dz)\n",
    "            # if i==0:\n",
    "            zs_post = current_zs.unsqueeze(0).detach()  # we use .detach() as we do not need to keep the computational graph\n",
    "            kl_paths = kl_path.unsqueeze(0).clone() # we use clone() as we will need the computaional graph\n",
    "                # the gradient computation will happen wrt to the model paramters, not the data.\n",
    "            # else:\n",
    "            #     zs_post = torch.cat([zs_post, current_zs.unsqueeze(0).detach()], dim=0)\n",
    "            #     kl_paths = torch.cat([kl_paths, kl_path.unsqueeze(0).clone()], dim=0)\n",
    "            # print(f\"zs_post : {zs_post.shape}\")\n",
    "            # print(f\"kl_paths : {kl_paths.shape}\")\n",
    "            # decode\n",
    "            # compute mean and logvar\n",
    "            mu_x, logvar_x = decoder(zs_post) # (B,N,K,Dx) ; (B,N,K,Dx)\n",
    "            # print(f\"mu_x : {mu_x.shape}\")\n",
    "            # print(f\"logvar_x : {logvar_x.shape}\")\n",
    "            # print(f\"\\ninputs : {z.shape}\")\n",
    "            # print(f\"outputs : mu_x {mu_x.shape}, logvar_x {logvar_x.shape}\")\n",
    "            # instantiate distribution\n",
    "            cov_x = torch.diag_embed(torch.exp(logvar_x)).to(device) # (B,N,K,Dx,Dx)\n",
    "            p_theta_x = torch.distributions.MultivariateNormal(loc=mu_x, covariance_matrix=cov_x)\n",
    "            xs = sampled_data.unsqueeze(-1).repeat(1,1,K,1) # (B,N,Dx=1) => (B,N,1,Dx=1) => (B,N,K,Dx)\n",
    "            # print(f'p_theta_x : {p_theta_x}')\n",
    "            # print(f\"xs : {xs.shape}\")\n",
    "            # compute losses and backprop\n",
    "            optimizer.zero_grad()\n",
    "            kl_z0 = torch.distributions.kl_divergence(q_phi_z0, p_z0_prior)  # (1)\n",
    "            kl_sde = kl_paths.mean()  # (B,N-1,K) => (1)\n",
    "            rec_loss = p_theta_x.log_prob(xs).mean(dim=2).sum(dim=1).mean()\n",
    "            loss = -rec_loss + kl_z0 + kl_sde\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # report out\n",
    "            print(f\"Sample {i+1}/{batch_size} in batch {j+1}/{len(train_loader)} .. Total loss : {loss.item():.3e} .. kl_z0 : {kl_z0.item():.3e} .. kl_path : {kl_sde.item():.3e} .. rec loss : {rec_loss.item():.3e}\",end=\"\\r\")\n",
    "            epoch_loss += loss.item()\n",
    "            kl_z0s += kl_z0.item()\n",
    "            kl_sdes += kl_sde.item()\n",
    "            rec_loss_total += rec_loss.item()\n",
    "    # form averages\n",
    "    epoch_loss /= (batch_size * len(train_loader))\n",
    "    kl_z0s /= (batch_size * len(train_loader))\n",
    "    kl_sdes /= (batch_size * len(train_loader))\n",
    "    rec_loss_total /= (batch_size * len(train_loader))\n",
    "    # log\n",
    "    list_epoch_loss.append(epoch_loss)\n",
    "    list_kl_z0s.append(kl_z0s)\n",
    "    list_kl_sdes.append(kl_sdes)\n",
    "    list_rec_loss.append(rec_loss_total)\n",
    "        \n",
    "    # report at epoch level\n",
    "    print(f\"Epoch {epoch+1:<3}/{N_EPOCHS:<3} .. Total loss : {epoch_loss:.3e} .. kl_z0 : {kl_z0s:.3e} .. kl_path : {kl_sdes:.3e} .. rec_loss : {rec_loss_total:.3e}\" + \" \"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,6))\n",
    "\n",
    "results={\n",
    "    \"total loss\" : list_epoch_loss,\n",
    "    \"kl z0\" : list_kl_z0s,\n",
    "    \"kl paths\" : list_kl_sdes,\n",
    "    \"rec loss\" : list_rec_loss\n",
    "}\n",
    "\n",
    "for i,(k,v) in enumerate(results.items()):\n",
    "    ax[i].plot(v)\n",
    "    ax[i].set_title(k)\n",
    "    ax[i].grid(True)\n",
    "    \n",
    "fig.suptitle(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee1577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0743f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab9846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37151072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313886e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4c369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fdd046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "torchy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
