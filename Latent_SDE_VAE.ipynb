{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80222970",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 38px; color: black; font-weight: bold;\">\n",
    "Latent Neural SDE VAE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38425f08",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Biblio\n",
    "</div>\n",
    "\n",
    "Neural ODEs:\n",
    "\n",
    "**Neural ODEs (https://arxiv.org/abs/1806.07366) (2019)** : introduction of the Neural ODE as the continuous-time limit of a ResNet stack. Presentation of the use of the adjoint sensitivity method. Seminal paper for Neural ODE.\n",
    "\n",
    "**Latent ODEs for Irregularly-Sampled Time Series (https://arxiv.org/abs/1907.03907) (2019)** : Evolution of the Neural ODE model towards a Neural ODE RNN model, where the approximate posterior is built with a RNN on past observations.\n",
    "\n",
    "Neural SDEs:\n",
    "\n",
    "**SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic Differential Equations (https://arxiv.org/abs/2502.02472 , 2025)** : good background section (#2) to explain Neural SDE. Propose a new method SDE matching, inspired by score and flow matching, vs the adjoint sensivity method. SDE matching is claimed to be more efficient to compute gradients and train latent SDEs.\n",
    "\n",
    "**Scalable Gradients for Stochastic Differential Equations (https://arxiv.org/abs/2001.01328) (2020)** : generalization of the adjoint sensitivity method to SDEs. Combination with gradient-based stochastic variational inference for infinite-dimension VAEs.\n",
    "\n",
    "**Neural SDEs (https://www.researchgate.net/publication/333418188_Neural_Stochastic_Differential_Equations) (2019)** : link between infinitely deep residual networks and solutions to stochastic differential equations\n",
    "\n",
    "**Stable Neural SDEs in analyzing irregular time series data (https://arxiv.org/abs/2402.14989) (2025)** : points to the necessity of careful design of the drift and diffusion neural nets in latent SDEs. Introduces three latent SDEs models with performance guarantees.\n",
    "\n",
    "**Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations (https://arxiv.org/abs/2412.12112) (2024)** : application of neural SDEs to a biological use case (brain activity). Details the model, architecture, ELBO/loss computation. Takes into account inputs/commands in the model. \n",
    "\n",
    "General/Misc:\n",
    "\n",
    "**Efﬁcient gradient computation for dynamical models (https://www.fil.ion.ucl.ac.uk/~wpenny/publications/efficient_revised.pdf) (2014)** : summary of finite difference method, forward sensitivity method, adjoint sensitivity method, to compute gradients of a functional cost function. Applies to Neural ODEs training.\n",
    "\n",
    "**Cyclical Annealing Schedule: A Simple Approach to Mitigating KL Vanishing (https://arxiv.org/abs/1903.10145) (2019)** : explanation of the posterior collapse/KL vanishing problem, introduces different KL annealing schedules for VAE training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d885ce",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Code : torchsde library by Google Research\n",
    "</div>\n",
    "\n",
    "https://github.com/google-research/torchsde\n",
    "\n",
    "[1] Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, David Duvenaud. \"Scalable Gradients for Stochastic Differential Equations\". International Conference on Artificial Intelligence and Statistics. 2020. [arXiv]\n",
    "\n",
    "[2] Patrick Kidger, James Foster, Xuechen Li, Harald Oberhauser, Terry Lyons. \"Neural SDEs as Infinite-Dimensional GANs\". International Conference on Machine Learning 2021. [arXiv]\n",
    "\n",
    "[3] Patrick Kidger, James Foster, Xuechen Li, Terry Lyons. \"Efficient and Accurate Gradients for Neural SDEs\". 2021. [arXiv]\n",
    "\n",
    "[4] Patrick Kidger, James Morrill, James Foster, Terry Lyons, \"Neural Controlled Differential Equations for Irregular Time Series\". Neural Information Processing Systems 2020. [arXiv]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26b0c1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model & Math\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7c6bf",
   "metadata": {},
   "source": [
    "Data : $\\mathbf{X} = (x_{t_1}, x_{t_2}, ..., x_{t_N}) \\in \\mathbb{R}^{D_x}$ - assuming all $t_i \\in [0,1]$.\n",
    "\n",
    "The latent space has dimension $D_z$. The latent continuous dynamic is $\\mathbf{Z}$ defined by:\n",
    "\\begin{align*}\n",
    "z_0^{(\\theta)} &\\sim p_{\\theta_z}(z_0) \\\\\n",
    "dz_t^{(\\theta)} &= f_{\\theta}(z_t, t)dt + \\sigma_{\\theta}(z_t,t)dB_t \n",
    "\\end{align*}\n",
    "with: \n",
    "\\begin{align}\n",
    "\\textbf{drift} \\,& f_{\\theta} : \\mathbb{R}^{D_z} \\times [0,1] \\rightarrow \\mathbb{R}^{D_z} \\\\\n",
    "\\textbf{diffusion} \\,& \\sigma_{\\theta} : \\mathbb{R}^{D_z} \\times [0,1] \\rightarrow \\mathbb{R}^{D_z \\times D_z} \\\\\n",
    "\\textbf{Brownian motion} \\,& dB_t \\in \\mathbb{R}^{D_z}\n",
    "\\end{align}\n",
    "\n",
    "The decoder is classically:\n",
    "\\begin{align}\n",
    "p_{\\theta_x}(x_{t_i} \\vert z_{t_i})\n",
    "\\end{align}\n",
    "\n",
    "The approximate posterior (encoder) is also a SDE:\n",
    "\\begin{align}\n",
    "z_0^{(\\phi)} &\\sim q_{\\phi}(z_0 \\vert \\textbf{X}) \\\\\n",
    "dz_t^{(\\phi)} &= f_{\\phi}(z_t, t, \\textbf{X})dt + \\sigma_{\\theta}(z_t,t)dB_t \n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "- the drift $f_{\\phi}(z_t, t, \\textbf{X})$ is conditionned on observations $\\textbf{X}$\n",
    "- the diffusion of the approximate posterior is shared with the diffusion of the prior : $\\sigma_{\\theta}(z_t,t)$ - this ensures the application of Girsanov theorem and a finite KL divergence between the two stochastic processes (prior and approximate posterior) (see Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations (https://arxiv.org/abs/2412.12112) (2024))\n",
    "- drift and diffusion neural nets do not exhibit the same convergence guarantee (Stable Neural SDEs in analyzing irregular time series data (https://arxiv.org/abs/2402.14989) (2025))\n",
    "- non-diagonal diffusion seems to be difficult to simulate and costly to approximate (Scalable Gradients for Stochastic Differential Equations (https://arxiv.org/abs/2001.01328) (2020))\n",
    "- it seems a good practice to encode only part of the $\\textbf{X}$ in the approximate posterior : context vector (Scalable Gradients for Stochastic Differential Equations (https://arxiv.org/abs/2001.01328) (2020)), and $t_c << t_n$ in Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations (https://arxiv.org/abs/2412.12112) (2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f16593",
   "metadata": {},
   "source": [
    "Variational lower bound on the log marginal likelihood:\n",
    "\n",
    "We write:\n",
    "\\begin{align}\n",
    "p(x_{t_1:t_N}) &= \\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{p(z_{t_1:t_N} \\vert x_{t_1:t_N})}\n",
    "\\end{align}\n",
    "And:\n",
    "\\begin{align}\n",
    "\\log{p(x_{t_1:t_N})} &= \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{q_{\\phi}(z\\vert X)}\\frac{q_{\\phi}(z\\vert X)}{p(z_{t_1:t_N} \\vert x_{t_1:t_N})}} dz\n",
    "\\end{align}\n",
    "where $q_{\\phi}(z \\vert X)$ is formally is posterior distribution over **functions** $z : \\mathbb{R} \\rightarrow \\mathbb{R}^{D_z}$.\n",
    "Then:\n",
    "\\begin{align}\n",
    "\\log{p(x_{t_1:t_N})} &= \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{q_{\\phi}(z\\vert X)}} dz + \\mathbb{KL}(q_{\\phi}(z\\vert X) \\vert\\vert p(z_{t_1:t_N} \\vert x_{t_1:t_N}))\n",
    "\\end{align}\n",
    "where we -audaciously- consider $p(z_{t_1:t_N} \\vert x_{t_1:t_N})$ as a dsitribution over functions $z$ taking values $z_{t_1:t_N}$ at times $t_1:t_N$ so the $\\mathbb{KL}$ actually means something.\n",
    "Still on the same path:\n",
    "\\begin{align}\n",
    "\\log{p(x_{t_1:t_N})} &\\geq \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N}, z_{t_1:t_N})}{q_{\\phi}(z\\vert X)}} dz \\\\\n",
    "&= \\int q_{\\phi}(z \\vert X) \\log{\\frac{p(x_{t_1:t_N} \\vert z_{t_1:t_N})}{q_{\\phi}(z\\vert X)} p(z_{t_1:t_N})} dz \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z \\vert X)} \\log{p(x_{t_1:t_N} \\vert z_{t_1:t_N})} - \\mathbb{KL}(q_{\\phi}(z\\vert X) \\vert\\vert p(z_{t_1:t_N})) \\\\\n",
    "\\end{align}\n",
    "We write -still audaciously-\n",
    "\\begin{align}\n",
    "\\mathbb{KL}(q_{\\phi}(z\\vert X) \\vert\\vert p(z_{t_1:t_N})) &= \\mathbb{KL}(q_{\\phi}(z_0\\vert X) \\vert\\vert p_{\\theta_z}(z_0)) + \\mathbb{KL}(q_{\\phi}(z_{>0}\\vert X) \\vert\\vert p_{\\theta_z}(z_{>0}))\n",
    "\\end{align}\n",
    "where the first $\\mathbb{KL}$ on the r.h.s is a classic between two probability distributions over a random variable, and the second is derived from the Girsanov's theorem as:\n",
    "\\begin{align}\n",
    "\\mathbb{KL}(q_{\\phi}(z_{>0}\\vert X) \\vert\\vert p_{\\theta_z}(z_{>0})) &= \\frac{1}{2} \\mathbb{E}_{q_{\\phi}(z_{>0}\\vert X)} \\left( \\int_{0}^{T} \\vert \\Delta(t) \\vert^2 dt \\right) \\\\\n",
    "\\Delta(t) &= \\sigma_{\\theta}^{-1}(z_t,t) (f_{\\phi}(z_t, t, \\textbf{X}) - f_{\\theta}(z_t, t))\n",
    "\\end{align}\n",
    "\n",
    "Finally:\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta, \\phi, \\textbf{X}) &= \\mathbb{E}_{q_{\\phi}(z \\vert X)} \\log{p(x_{t_1:t_N} \\vert z_{t_1:t_N})} - \\mathbb{KL}(q_{\\phi}(z_0\\vert X) \\vert\\vert p_{\\theta_z}(z_0)) - \\frac{1}{2} \\mathbb{E}_{q_{\\phi}(z_{>0}\\vert X)} \\left( \\int_{0}^{T} \\vert \\Delta(t) \\vert^2 dt \\right)\n",
    "\\end{align}\n",
    "\n",
    "During training:\n",
    "- the integral is approximated via numerical integration\n",
    "- expectations are estimated with MC sampling\n",
    "- NB : sampling is actually : sampling $z_0 \\sim q_{\\phi}(z_0 \\vert \\textbf{X})$ and sampling a function $z$ by sampling a Brownian motion path $B_t$ and computing the whole realization path $z_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ad2f6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Set Up\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c507af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsde\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "317c8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bcf728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/envs/torchy/lib/python3.13/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fb066",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Data and Problem Statement\n",
    "</div>\n",
    "\n",
    "- The experiment is an unknown stochastic process $dX_t = f(X_t,t)dt + \\sigma(X_t,t)dB_t$\n",
    "- We observe several sample paths of this stochastic process.\n",
    "- Each sample path is a collection $\\{ (t_1, x_{t_1}), (t_2, x_{t_2}), ..., (t_n, x_{t_n}) \\}$ of $n$ data points at observation times $(t_i)_{1 \\leq i \\leq n}$. NB : $n$ may vary by sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb776b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32 # batch size, ie number of sample paths\n",
    "LENGTH = 100 # total number of points used to draw a full path of the stochastic process\n",
    "N_POINTS = 50 # total number of points that are actually observed in the stochastic process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea1670",
   "metadata": {},
   "source": [
    "Data Generating SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1864017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we create an Ornstein Uhlenbeck SDE model:\n",
    "# dX_t = theta * (mu - X_t) dt + sigma dB_t\n",
    "# theta, mu, sigma scalar parameters\n",
    "# B_t is a standard 1D Brownian motion\n",
    "\n",
    "# SDE are instantiated as subclasses of nn.Module\n",
    "\n",
    "class DataGeneratingSDE(nn.Module):\n",
    "    def __init__(self, theta, mu, sigma):\n",
    "        \n",
    "        # noise type can take 4 values : \"diagonal\", \"general\", \"additive\", \"scalar\"\n",
    "        # here we use \"diagonal\" : the diffusion function g(t,y) is an element wise function,\n",
    "        # its output has the same shape as y, ie (batch_size, state_size)\n",
    "        \n",
    "        # sde_type can be \"ito\" or \"stratonovich\"\n",
    "        # we use \"ito\" here. The available methods for computation are Euler(-Maruyama), Milstein, SRK.\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        \n",
    "        # we register the parameters so we can save them. But we will not train them.\n",
    "        self.register_buffer(\"theta\", torch.tensor(theta))\n",
    "        self.register_buffer(\"mu\", torch.tensor(mu))\n",
    "        self.register_buffer(\"sigma\", torch.tensor(sigma))\n",
    "\n",
    "    # DRIFT FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the drift at time t and state y\n",
    "    # note : the functions f and g must be able to handle inputs of shape (batch_size, state_size)\n",
    "    # for any batch_size >= 1\n",
    "    def f(self, t, y):\n",
    "        return self.theta * (self.mu - y)\n",
    "    \n",
    "    # DIFFUSION FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the diffusion at time t and state y\n",
    "    # (NB : generally, the output of g is of shape (batch_size, state_size, brownian_size) when noise_type is \"general\")\n",
    "    def g(self, t, y):\n",
    "        return self.sigma * torch.ones_like(y)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        msg = f\"Ornstein Uhlenbeck SDE Model - mu = {self.mu:.3f}, theta = {self.theta:.3f}, sigma = {self.sigma:.3f}\"\n",
    "        return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70645eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "theta = torch.distributions.Uniform(0.1, 1.0).rsample()\n",
    "mu = torch.distributions.Uniform(-1.0, 1.0).rsample()\n",
    "sigma = torch.distributions.Uniform(0.01, 1.0).rsample()\n",
    "datamodel = DataGeneratingSDE(theta=theta.item(), mu=mu.item(), sigma=sigma.item()).to(device)\n",
    "\n",
    "print(f\"Data Generating Model : {datamodel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc78a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form dataset\n",
    "\n",
    "# times\n",
    "t_start = 0.0\n",
    "t_end = 10.0\n",
    "times = torch.linspace(t_start, t_end, LENGTH).to(device) # (LENGTH)\n",
    "all_times = times.repeat(B,1) # (B, LENGTH)\n",
    "       \n",
    "print(f\"All times for data generation : {all_times.shape} (batch, length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b860d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "Dx = 1 # dimension - 1 as it is a univariate time serie\n",
    "\n",
    "# sampling full data paths\n",
    "y_start = 0.0\n",
    "y0s = torch.full((B,1),y_start).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_data = torchsde.sdeint(datamodel, y0s, times, method='euler', dt=1e-3) # (N_POINTS,B,1)\n",
    "    \n",
    "all_data = all_data.permute(1,0,2) # (B,N_POINTS,1)\n",
    "# print(f\"Computed full sample paths : {all_data.shape} (length,batch,1)\")\n",
    "\n",
    "# extract some subsets in each sample path\n",
    "for b in range(B):\n",
    "    idx = np.random.choice(np.arange(LENGTH), N_POINTS, replace=False)  # indices to pick\n",
    "    observation_ts = times[idx] # (N_POINTS)\n",
    "    sampled_d = all_data[b,idx] # (N_POINTS,1)\n",
    "    if b==0:\n",
    "        sampled_data = sampled_d.detach().unsqueeze(0)\n",
    "        observation_times = observation_ts.detach().unsqueeze(0)\n",
    "    else:\n",
    "        sampled_data = torch.cat([sampled_data, sampled_d.detach().unsqueeze(0)], dim=0)\n",
    "        observation_times = torch.cat([observation_times, observation_ts.detach().unsqueeze(0)], dim=0) # (B,N_POINTS)\n",
    "\n",
    "# print(f\"Observations times : {observation_times.shape}\")\n",
    "# print(f\"Sampled data : {sampled_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DISPLAY=5\n",
    "fig, ax = plt.subplots(nrows=1, ncols=N_DISPLAY, figsize=(6*N_DISPLAY,4))\n",
    "idx = np.random.choice(np.arange(B),N_DISPLAY,replace=False)\n",
    "for i,id in enumerate(idx):\n",
    "    ax[i].plot(all_times[id].squeeze().detach().cpu().numpy(), all_data[id,:].squeeze().detach().cpu().numpy(), label='full ground truth path', color='blue')\n",
    "    ax[i].scatter(observation_times[id].squeeze().detach().cpu().numpy(), sampled_data[id].squeeze().detach().cpu().numpy(), s=100, label='sampled points in path', color='green', marker='o')\n",
    "    ax[i].legend()\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(f'Sample Path {id}/{B}')\n",
    "    \n",
    "fig.suptitle(f'Data samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DATA GENERATING MODEL\")\n",
    "print(datamodel)\n",
    "print()\n",
    "print(f\"DATA SUMMARY\")\n",
    "print()\n",
    "print(f\"LENGTH of full sample path : {LENGTH}\")\n",
    "print(f\"BATCH of paths : {B}\")\n",
    "print(f\"Number of points N_POINTS observed in each path : {N_POINTS}\")\n",
    "print()\n",
    "print(f\"Tensor of full paths : {all_data.shape} (BATCH,LENGTH,1)\")\n",
    "print(f\"Tensor of all times : {all_times.shape} (BATCH,LENGTH)\")\n",
    "print()\n",
    "print(f\"Tensor of sampled paths : {sampled_data.shape} (BATCH,N_POINTS,1)\")\n",
    "print(f\"Tensor of sampling times : {observation_times.shape} (BATCH,N_POINTS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ef715",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 38px; color: black; font-weight: bold;\">\n",
    "Model and Pipeline\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f4aa3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : parameters\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = 1  # observation space dimension\n",
    "Dz = 4  # latent space dimension\n",
    "Dl = 16 # LSTM dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deefcf00",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : posterior 1/2 : Context LSTM\n",
    "</div>\n",
    "\n",
    "- Context LSTM - Encodes $(t_i, x_{t_i})_{1 \\leq i \\leq N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextLSTM(nn.Module):\n",
    "    \"\"\"LSTM model class to encode all observations,\n",
    "    with their observation times, into a context\n",
    "    vector that will be used in the posterior\n",
    "    \"\"\"\n",
    "    def __init__(self, lstm_dim=Dl, n_layers=1, input_dim=Dx):\n",
    "        # inputs:\n",
    "        # lstm_dim : dimension of the LSTM\n",
    "        # n_layers : number of LSTM layers\n",
    "        # input_dim : input dimension, defaults to 1 (univariate time series)\n",
    "        super().__init__()\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_dim + 1, # add 1 for time dimension\n",
    "            hidden_size=self.lstm_dim,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "    def forward(self,t,x):\n",
    "        # inputs:\n",
    "        # t : tensor (B,N) of time stamps\n",
    "        # x : tensor (B,N,input_dim) of observations at times t\n",
    "        # outputs:\n",
    "        # h : tensor (B,lstm_dim) of hidden stats encoding (t,x)\n",
    "        x_ext = torch.cat([t.unsqueeze(-1),x], dim=-1) # (B,N,input_dim+1)\n",
    "        _,(hn,_) = self.lstm(x_ext) # hn (1,B,lstm_dim)\n",
    "        \n",
    "        return hn.squeeze(0) # (B,lstm_dim)\n",
    "\n",
    "    def __repr__(self):\n",
    "        description = f\"ContextLSTM with lstm_dim = {self.lstm_dim}, n_layers = {self.n_layers}, input_dim = {self.input_dim}\"\n",
    "        description += f\"\\nLSTM net : {self.lstm}\"\n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d383d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test LSTM\n",
    "context_lstm = ContextLSTM(input_dim=Dx)\n",
    "print(context_lstm)\n",
    "\n",
    "t_in = torch.randn(32,50)\n",
    "x_in = torch.randn(32,50,Dx)\n",
    "\n",
    "context = context_lstm(t_in, x_in)\n",
    "\n",
    "print(f\"Inputs:\")\n",
    "print(f\"\\ttimes : {t_in.shape}\")\n",
    "print(f\"\\tobservations : {x_in.shape}\")\n",
    "print(f\"Outputs:\")\n",
    "print(f\"\\thidden state : {context.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf48ff",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : posterior 2/2 : Posterior for initial values of the SDEs\n",
    "</div>\n",
    "\n",
    "- $q_{\\phi}(z_0) \\sim \\mathcal{N}(\\mu_{\\phi}(X), \\sigma_{\\phi}(X))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f97d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior distribution for starting value\n",
    "\n",
    "class EncoderStartingValue(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder for the starting value of the latent variable.\n",
    "    Uses the context vector from the LSTM to parameterize\n",
    "    the mean and log-variance of a Gaussian distribution.\n",
    "    NB : we assume a diagonal covariance matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, context_dim=Dl, latent_dim=Dz, n_layers=1, hidden_dim=32):\n",
    "        # inputs:\n",
    "        # context_dim : dimension of the context vector. This is the dimension of the LSTM (Dl)\n",
    "        # latent_dim ; latent space dimension (Dz)\n",
    "        # n_layers, hidden_dim : number and size of layers of the MLP\n",
    "        super().__init__()\n",
    "        self.context_dim = context_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = self.context_dim\n",
    "        for i in range(self.n_layers):\n",
    "            layers.append(nn.Linear(input_dim, self.hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            input_dim = self.hidden_dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.mean = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        self.logvar = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        \n",
    "    def forward(self, c):\n",
    "        # input:\n",
    "        # c : context vector, tensor (B,context_dim)\n",
    "        # output:\n",
    "        # mean : tensor (B, latent_dim) : mean of the Gaussian\n",
    "        # logvar : tensor (B, latent_dim) : log var of the Gaussian\n",
    "        x = self.mlp(c)\n",
    "        mean = self.mean(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mean, logvar\n",
    "\n",
    "    def __repr__(self):\n",
    "        description = f\"Encoder of Starting Value z0 given X\\n\"\n",
    "        description += f\"\\tInput size (context vector) : {self.context_dim}\\n\"\n",
    "        description += f\"\\tOutput dimension (latent vector dimension) : {self.latent_dim}\\n\"\n",
    "        description += f\"\\tMLP : {self.mlp}\\n\"\n",
    "        description += f\"\\tMean : {self.mean}\\n\"\n",
    "        description += f\"\\tLog var : {self.logvar}\"\n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36aa7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_start = EncoderStartingValue()\n",
    "print(encoder_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=3\n",
    "\n",
    "mean, logvar = encoder_start(context)\n",
    "cov = torch.diag_embed(0.5 * torch.exp(logvar))\n",
    "\n",
    "q_phi_z0 = torch.distributions.MultivariateNormal(\n",
    "    loc=mean,\n",
    "    covariance_matrix=cov\n",
    ")\n",
    "\n",
    "z0s = q_phi_z0.rsample((K,))\n",
    "\n",
    "print(f\"Sampling initial values for the SDEs\")\n",
    "print(f\"\\tDistribution mean : {mean.shape}\")\n",
    "print(f\"\\tCovariance matrix : {cov.shape}\")\n",
    "print(f\"\\tDistribution object : {q_phi_z0}\")\n",
    "print(f\"Sampling {K} samples : {z0s.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa60051",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : Posterior and Prior SDEs\n",
    "</div>\n",
    "\n",
    "- Posterior : $dZ_t^{(\\phi)} = f_{\\phi}(Z_t,t \\vert X)dt + \\sigma_{\\theta}(Z_t,t)dB_t$\n",
    "- Prior : $dZ_t^{(\\theta)} = f_{\\theta}(Z_t,t)dt + \\sigma_{\\theta}(Z_t,t)dB_t$\n",
    "\n",
    "Here, we choose to implement both the prior and the posterior in the same class (see torchsde.sdeint documentation):\n",
    "- this allows to share the same diffusion by design\n",
    "- this allows a library-based computation of the KL between the two SDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(nn.Module):\n",
    "    \"\"\"\n",
    "    Latent SDE class\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=Dx, latent_dim=Dz, lstm_dim=Dl, hidden_dim=32):\n",
    "        # we use a diagonal noise type\n",
    "        # the SDE type is \"Ito\"\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        self.Dx = input_dim\n",
    "        self.Dz = latent_dim\n",
    "        self.Dl = lstm_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Ornstein Uhlenbeck prior parameters\n",
    "        self.kappa = 1.0\n",
    "        self.mu = 0.0\n",
    "        # basic z|x encoder seen above\n",
    "        self.encoder = ContextLSTM(lstm_dim=self.Dl, input_dim=self.Dx)\n",
    "        self.context = None # context tensor\n",
    "        # net for posterior drift\n",
    "        self.posterior_drift = nn.Sequential(\n",
    "            nn.Linear(self.Dz+self.Dl, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.Dz)\n",
    "        )\n",
    "        # net for shared diagonal diffusion\n",
    "        self.shared_diffusion = nn.Sequential(\n",
    "            nn.Linear(self.Dz+self.Dl, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.Dz)\n",
    "        )\n",
    "        \n",
    "    def encode(self,t,x):\n",
    "        # separate method to encode data:\n",
    "        # inputs :\n",
    "        # t : time steps, tensor (B,N)\n",
    "        # x : observations at times t, tensor (B,N,Dx)\n",
    "        self.context = self.encoder(t,x) # encode into (B,Dl)\n",
    "\n",
    "    def f(self,t,z):\n",
    "        \"\"\"Posterior drift\"\"\"\n",
    "        # assume self.context has been computed\n",
    "        # inputs:\n",
    "        # t : times tensor (B,1) : unused. Time is taken into account in the context\n",
    "        #     computed from self.encoder\n",
    "        # z : variable tensor (B,Dz)\n",
    "        # outputs:\n",
    "        # f(t,z) : drift tensor (B,Dz)\n",
    "        z_ext = torch.cat([self.context, z], dim=-1) # form (B,Dl+Dz)\n",
    "        posterior_drift = self.posterior_drift(z_ext) # (B,Dz)\n",
    "        return posterior_drift\n",
    "\n",
    "    def g(self,t,z):\n",
    "        \"\"\"Shared diffusion\"\"\"\n",
    "        # assume self.context has been computed\n",
    "        # inputs : t,z as above\n",
    "        # outputs : g(t,z) : diagonal diffusion (B,Dz)\n",
    "        z_ext = torch.cat([self.context, z], dim=-1) # form (B,Dl+Dz)\n",
    "        shared_diffusion = self.shared_diffusion(z_ext) # (B,Dz)\n",
    "        return shared_diffusion\n",
    "    \n",
    "    def h(self,t,z):\n",
    "        \"\"\"Prior drift\"\"\"\n",
    "        # here, we posit a fixed Ornstein Uhlenbeck\n",
    "        prior_drift = self.kappa * (self.mu - z)\n",
    "        return prior_drift\n",
    "    \n",
    "    def __repr__(self):\n",
    "        d = f\"Latent SDE Model - Dz = {self.Dz} - LSTM dim = {self.Dl}\\n\"\n",
    "        d += f\"\\tLSTM Encoder : {self.encoder}\\n\"\n",
    "        d += f\"\\tPosterior Drift : {self.posterior_drift}\\n\"\n",
    "        d += f\"\\tPrior Drift : fixed, O.U with kappa = {self.kappa}; mu = {self.mu}\\n\"\n",
    "        d += f\"\\tShared Diffusion : {self.shared_diffusion}\"\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26969fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sde = LatentSDE()\n",
    "print(model_sde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test encode method\n",
    "print(f\"Context tensor before encoding : {model_sde.context}\")\n",
    "model_sde.encode(observation_times, sampled_data)\n",
    "print(f\"Context tensor after encoding : {model_sde.context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46aaeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8fd49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d2bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc2f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bed2197",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Model : prior\n",
    "</div>\n",
    "\n",
    "The latent space has dimension $D_z$. \n",
    "\n",
    "The latent prior is a Ornstein Uhlenbeck process $\\mathbf{Z}$ defined by:\n",
    "\\begin{align*}\n",
    "z_0^{(\\theta)} &\\sim p_{\\theta_z}(z_0) \\\\\n",
    "dz_t^{(\\theta)} &= \\kappa (\\mu - z_t) dt + \\sigma_{\\theta}(z_t,t)dB_t \n",
    "\\end{align*}\n",
    "with: \n",
    "\\begin{align}\n",
    "\\textbf{drift} \\,& f_{\\theta}(z_t,t) = \\kappa (\\mu - z_t) \\\\\n",
    "\\kappa &\\in \\mathbb{R} \\\\\n",
    "\\mu &\\in \\mathbb{R}^{D_z} \\\\\n",
    "\\textbf{diffusion} \\,& \\sigma_{\\theta} : \\mathbb{R}^{D_z} \\times [0,1] \\rightarrow \\mathbb{R}^{D_z \\times D_z} \\\\\n",
    "\\textbf{Brownian motion} \\,& dB_t \\in \\mathbb{R}^{D_z}\n",
    "\\end{align}\n",
    "\n",
    "The $\\textbf{diffusion}$ is a MLP shared with the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the latent space\n",
    "Dz = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a98847",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagonalSharedDiffusion(nn.Module):\n",
    "    \"\"\"The diffusion is shared between the prior and the posterior.\n",
    "    So we can actually compute a KL\n",
    "    \"\"\"\n",
    "    def __init__(self,n_layers=1, n_hidden=32, latent_dim=Dz):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.register_buffer(\"n_layers\", torch.tensor(n_layers))\n",
    "        self.register_buffer(\"n_hidden\", torch.tensor(n_hidden))\n",
    "        self.register_buffer(\"latent_dim\", torch.tensor(latent_dim))\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = self.latent_dim\n",
    "        for _ in range(self.n_layers):\n",
    "            layers.append(nn.Linear(input_dim, self.n_hidden))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(self.n_hidden, self.latent_dim ))\n",
    "\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,t,z):\n",
    "        # inputs:\n",
    "        # t : tensor (B,N) : NOT USED HERE - ie assume constant diffusion\n",
    "        # z : tensor (B,Dz)\n",
    "        # outputs:\n",
    "        # diff : tensor (B,Dz) > 0\n",
    "        return torch.exp(self.mlp(z))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        description = f'Model Diagonal Shared Diffusion'\n",
    "        description += f\"{self.mlp}\"\n",
    "        return description\n",
    "    \n",
    "shared_diffusion = DiagonalSharedDiffusion().to(device)\n",
    "print(shared_diffusion)\n",
    "\n",
    "print(f\"Computing diffusion\")\n",
    "z = torch.randn((B,LENGTH,Dz)).to(device)\n",
    "print(f\"Input : {z.shape} (batch,length,Dz)\")\n",
    "diff = shared_diffusion(times, z)\n",
    "print(f\"Output : diffusion = {diff.shape} (batch,length,Dz)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorSDE(nn.Module):\n",
    "    \"\"\"class for the latent Prior\n",
    "    This is a O.U. process with kappa=0.5, mu=0.0\n",
    "    \"\"\"\n",
    "    def __init__(self, shared_diffusion, kappa=0.5, mu=0.0):\n",
    "        super().__init__()\n",
    "        # we assume a diagonal shared diffusion\n",
    "        # shared_diffusion is a nn.Module\n",
    "        # FROM THE DOC : \"diagonal\": The diffusion g is element-wise and has output size (batch_size, state_size). \n",
    "        # The Brownian motion is a batch of state_size-dimensional Brownian motions.\n",
    "        self.noise_type = 'diagonal'\n",
    "        self.sde_type = 'ito'\n",
    "        self.register_buffer(\"kappa\", torch.tensor(kappa))\n",
    "        self.register_buffer(\"mu\", torch.tensor(mu))\n",
    "        self.diffusion = shared_diffusion\n",
    "        \n",
    "    # DRIFT FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the drift at time t and state y\n",
    "    # note : the functions f and g must be able to handle inputs of shape (batch_size, state_size)\n",
    "    # for any batch_size >= 1\n",
    "    def f(self,t,z):\n",
    "        return self.kappa * (self.mu - z)\n",
    "    \n",
    "    # DIFFUSION FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the diffusion at time t and state y\n",
    "    # (NB : generally, the output of g is of shape (batch_size, state_size, brownian_size) when noise_type is \"general\")\n",
    "    def g(self,t,z):\n",
    "        # we assume shared_diffusion : state_size --> state_size\n",
    "        return self.diffusion(t,z) * torch.ones_like(z)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        description = f\"Model Prior SDE - Ornstein Uhlenbeck\"\n",
    "        description += f\"kappa = {self.kappa:.3f}, mu = {self.mu:.3f}\"\n",
    "        description += f\"Diffusion : {self.diffusion}\"\n",
    "        return description\n",
    "        \n",
    "prior = PriorSDE(shared_diffusion=shared_diffusion).to(device)\n",
    "print(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ffdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior initial values\n",
    "p_z0_prior = torch.distributions.MultivariateNormal(\n",
    "    loc = torch.zeros(Dz),\n",
    "    covariance_matrix = torch.eye(Dz)\n",
    ")\n",
    "\n",
    "print(f\"Prior initial value z0 : {p_z0_prior}\")\n",
    "print(f\"\\tBatch shape : {p_z0_prior.batch_shape}\")\n",
    "print(f\"\\tEvent shape : {p_z0_prior.event_shape}\")\n",
    "\n",
    "# sample a batch of initial values\n",
    "z0s = p_z0_prior.sample((B,)).to(device)\n",
    "print(f\"Sampling initial values of O.U. priors : {z0s.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample priors\n",
    "N = 5\n",
    "idx = np.random.choice(B,N)\n",
    "z_priors = torchsde.sdeint(prior, z0s, times, method='euler')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=N, ncols=Dz, figsize=(6*N,4*Dz))\n",
    "times_ = times.detach().cpu().numpy()\n",
    "for i, id in enumerate(idx):\n",
    "    z_priors_ = z_priors[:,id,:].squeeze().detach().cpu().numpy()  # LENGTH,1,Dz => LENGTH,Dz\n",
    "    for j in range(Dz):\n",
    "        ax[i,j].plot(times_, z_priors_[:,j])\n",
    "        ax[i,j].set_title(f\"Sample {id} - component {j}\")\n",
    "        ax[i,j].grid()\n",
    "        \n",
    "fig.suptitle(f\"Prior samples - {N} samples in dimension {Dz}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05875e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5f28af6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Creating a SDE model, sampling paths\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab9846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0233e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POINTS = 50 # number of points in each path\n",
    "N_PATHS = 10  # number of paths to sample\n",
    "\n",
    "t_start = 0.0\n",
    "t_end = 10.0\n",
    "\n",
    "ts = torch.linspace(t_start, t_end, N_POINTS).to(device)  # time stamps where we want the solution, between 0 and 1\n",
    "print(f\"Time stamps shape : {ts.shape}\")  # shape (N_POINTS,)\n",
    "y_start = 0.25  # initial condition\n",
    "y0 = torch.full((N_PATHS, 1), y_start).to(device)  # initial condition 0.25, shape (batch_size=N_PATHS, state_size=1)\n",
    "print(f\"Initial condition shape : {y0.shape}\")  # shape (N_PATHS, 1)\n",
    "\n",
    "# now, we call sdeint to solve the SDE\n",
    "# NB : we can use the adjoint method by calling sdeint_adjoint instead of sdeint\n",
    "# method can be \"euler\", \"milstein\", \"srk\" for sde_type=\"ito\"\n",
    "# dt is the step size used by the solver (smaller dt -> more accurate but slower). By default, dt=1e-3\n",
    "\n",
    "with torch.no_grad():  # we don't need gradients for this demo\n",
    "    ys = torchsde.sdeint(model, y0, ts, method=\"euler\", dt=1e-3)  # shape (N_POINTS, N_PATHS, 1)\n",
    "print(f\"Computed solution samples : {ys.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ousde_samples(ts, ys, model, title=None):\n",
    "    \"\"\"\n",
    "    Utility functions to plot the sampled SDE solutions\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    n_points = ts.size()[0]\n",
    "    n_paths = ys.size()[1]\n",
    "    \n",
    "    for i, y in enumerate(ys.permute(1,0,2)):  # iterate over paths\n",
    "        ax.plot(ts.detach().cpu().numpy(), y.detach().cpu().numpy(), lw=1, alpha=1.0, label=f'Path {i+1}' if i<10 else None)  # plot each path\n",
    "    \n",
    "    if title is None:\n",
    "        title = f\"DATA : Sampled paths of the Ornstein-Uhlenbeck SDE - parameters : mu = {model.mu.item():.1f}, theta = {model.theta.item():.1f}, sigma = {model.sigma.item():.1f}\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"X(t)\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "        \n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_ousde_samples(ts, ys, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61e337",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Toy 1 : learning a O.U. model from the data\n",
    "</div>\n",
    "\n",
    "NB - yes this is an ugly way to learn parameters of an O.U. process. It is just to demonstrate a basic use of the torchsde SDE model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c702b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Toy_OU_SDE(nn.Module):\n",
    "    def __init__(self):\n",
    "        # we keep \"diagonal\" noise type\n",
    "        \n",
    "        # sde_type can be \"ito\" or \"stratonovich\"\n",
    "        # we use \"ito\" here. The available methods for computation are Euler(-Maruyama), Milstein, SRK.\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        \n",
    "        # here, we want to learn the parameters theta, mu, sigma\n",
    "        self.theta = nn.Parameter(torch.tensor(1.0))  # initial guess\n",
    "        self.mu = nn.Parameter(torch.tensor(1.0))     # initial guess\n",
    "        self.sigma = nn.Parameter(torch.tensor(1.0))  # initial guess\n",
    "\n",
    "    # DRIFT FUNCTION - same signature as above\n",
    "    def f(self, t, y):\n",
    "        return self.theta * (self.mu - y)\n",
    "    \n",
    "    # DIFFUSION FUNCTION - same signature as above\n",
    "    def g(self, t, y):\n",
    "        return self.sigma**2 * torch.ones_like(y)\n",
    "\n",
    "# instantiate model\n",
    "model_ou_1 = Toy_OU_SDE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1567ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torchsde.sdeint(model_ou_1, y0, ts, method=\"euler\", dt=1e-3)  # shape (N_POINTS, N_PATHS, 1)\n",
    "print(f\"Computed solution samples : {preds.size()}\")\n",
    "\n",
    "fig, ax = plot_ousde_samples(ts, preds, model_ou_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f051f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(learned_model, t_start=t_start, t_end=t_end, N_SAMPLES=5, device=device, gt_model=model, y_start=0.1):\n",
    "    \"\"\"\n",
    "    Utility function to plot comparison between ground truth model and learned model\n",
    "    \"\"\"\n",
    "\n",
    "    bm = torchsde.BrownianInterval(t_start, t_end, size=(N_SAMPLES, 1), device=device) # instantiate N_SAMPLES independent Brownian motions of dimension 1\n",
    "    bm_increments = torch.stack([bm(t0,t1) for t0,t1 in zip(ts[:-1], ts[1:])])  # sample N_POINTS-1 increments for each BM : shape (N_POINTS-1, N_SAMPLES, 1)\n",
    "    bm_queries = torch.cat([torch.zeros(1, N_SAMPLES, 1, device=device), torch.cumsum(bm_increments, dim=0)])  # add independent increments to sample Brownian motions : shape (N_POINTS, N_SAMPLES, 1)\n",
    "\n",
    "    y0s = torch.full((N_SAMPLES, 1), y_start).to(device)  # initial condition 0.1, shape (batch_size=N_SAMPLES, state_size=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ys_true = torchsde.sdeint(gt_model, y0s, ts, method=\"euler\", dt=1e-3, bm=bm)  # shape (N_POINTS, N_SAMPLES, 1)\n",
    "        ys_learned = torchsde.sdeint(learned_model, y0s, ts, method=\"euler\", dt=1e-3, bm=bm)  # shape (N_POINTS, N_SAMPLES, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=N_SAMPLES, figsize=(6*N_SAMPLES,6))\n",
    "\n",
    "    for i in range(N_SAMPLES):\n",
    "        ax[i].plot(ts.detach().cpu().numpy(), ys_true[:,i,:].detach().cpu().numpy(), lw=2, alpha=1.0, label='Ground truth', color='blue')\n",
    "        ax[i].plot(ts.detach().cpu().numpy(), ys_learned[:,i,:].detach().cpu().numpy(), lw=2, alpha=1.0, label='Model', color='orange')\n",
    "        ax[i].set_title(f\"Sampled paths - Sample {i+1}\")\n",
    "        ax[i].set_xlabel(\"Time\")\n",
    "        ax[i].set_ylabel(\"X(t)\")\n",
    "        ax[i].legend()\n",
    "        ax[i].grid()\n",
    "        \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avant training\n",
    "fig, ax = plot_comparison(model_ou_1)\n",
    "fig.suptitle(\"Comparison of the ground truth and O.U. SDE models before training\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop parameters\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(model_ou_1.parameters()), \n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# --- N EPOCHS for all training loops\n",
    "# -------------------------------------------------------\n",
    "N_EPOCHS = 200\n",
    "# -------------------------------------------------------\n",
    "# -------------------------------------------------------\n",
    "\n",
    "thetas = []\n",
    "mus = []\n",
    "sigmas = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # compute SDE and sample N_PATHS\n",
    "    preds = torchsde.sdeint(model_ou_1, y0, ts, method=\"euler\", dt=1e-3)  # shape (N_POINTS, N_PATHS, 1)\n",
    "    # compute average L2 loss between data paths and sampled paths\n",
    "    mse = (data - preds.permute(1,0,2))**2\n",
    "    loss = mse.mean()\n",
    "    # train\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # record and report out\n",
    "    losses.append(loss.item())\n",
    "    m = model_ou_1.mu.item()\n",
    "    s = torch.sqrt(model_ou_1.sigma).item()\n",
    "    t = model_ou_1.theta.item()\n",
    "    mus.append(m)\n",
    "    sigmas.append(s)\n",
    "    thetas.append(t)\n",
    "    print(f\"Epoch {epoch+1:<3} - {N_EPOCHS:<3} - loss = {loss.item():.3e} - parametres : theta = {t:.3f}, mu = {m:.3f}, sigma = {s:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(24,4))\n",
    "\n",
    "axs[0].plot(losses, label='losses')\n",
    "axs[1].plot(mus, label='mu')\n",
    "axs[2].plot(thetas, label='theta')\n",
    "axs[3].plot(sigmas, label='sigma')\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].set_xlabel('epoch')\n",
    "    axs[i].legend()\n",
    "    axs[i].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we test the two models by sampling the SAME brownian motion for both\n",
    "# after training\n",
    "fig, ax = plot_comparison(model_ou_1)\n",
    "fig.suptitle(\"Comparison of the ground truth and learned O.U. SDE models after training\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf08a84",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Toy 2 : learning a O.U. model from the data with bayesian inference\n",
    "</div>\n",
    "\n",
    "Here, we put a Gaussian prior on the O.U. paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianToy_OU_SDE(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # we keep \"diagonal\" noise type\n",
    "        \n",
    "        # sde_type can be \"ito\" or \"stratonovich\"\n",
    "        # we use \"ito\" here. The available methods for computation are Euler(-Maruyama), Milstein, SRK.\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        \n",
    "        # here, we want to learn the parameters theta, mu, sigma\n",
    "        # we put a prior on them\n",
    "        self.theta_mean = nn.Parameter(torch.tensor(1.0))  # initial guess\n",
    "        self.theta_std = nn.Parameter(torch.tensor(0.1))   # initial guess\n",
    "        self.mu_mean = nn.Parameter(torch.tensor(1.0))     # initial guess\n",
    "        self.mu_std = nn.Parameter(torch.tensor(0.1))      # initial guess\n",
    "        self.sigma_mean = nn.Parameter(torch.tensor(1.0))  # initial guess\n",
    "        self.sigma_std = nn.Parameter(torch.tensor(0.1))   # initial guess\n",
    "\n",
    "    # DRIFT FUNCTION\n",
    "    def f(self, t, y):\n",
    "        # sample parameters from normal distributions\n",
    "        # NB : need the reparametrization trick to backprop through the sampling\n",
    "        eps1 = torch.randn_like(self.theta_mean)\n",
    "        self.theta = self.theta_mean + eps1 * torch.abs(self.theta_std)\n",
    "        eps2 = torch.randn_like(self.mu_mean)\n",
    "        self.mu = self.mu_mean + eps2 * torch.abs(self.mu_std)\n",
    "        \n",
    "        return self.theta * (self.mu - y)\n",
    "    \n",
    "    # DIFFUSION FUNCTION\n",
    "    def g(self, t, y):\n",
    "        # sample sigma from normal distribution with reparametrization trick\n",
    "        eps3 = torch.randn_like(self.sigma_mean)\n",
    "        self.sigma = self.sigma_mean + eps3 * torch.abs(self.sigma_std)\n",
    "\n",
    "        return self.sigma**2 * torch.ones_like(y)\n",
    "\n",
    "# instantiate model\n",
    "bayesianmodel_ou = BayesianToy_OU_SDE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c17ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PATHS = 10  # number of paths to sample\n",
    "\n",
    "y_start = 0.25  # initial condition\n",
    "y0 = torch.full((N_PATHS, 1), y_start).to(device)  # initial condition 0.25, shape (batch_size=N_PATHS, state_size=1)\n",
    "\n",
    "preds = torchsde.sdeint(bayesianmodel_ou, y0, ts, method=\"euler\", dt=1e-3)  # shape (N_POINTS, N_PATHS, 1)\n",
    "print(f\"Computed solution samples : {preds.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bayesian_ousde_samples(ts, ys, model):\n",
    "    \"\"\"\n",
    "    Utility functions to plot the sampled SDE solutions\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    n_points = ts.size()[0]\n",
    "    n_paths = ys.size()[1]\n",
    "    \n",
    "    for i, y in enumerate(ys.permute(1,0,2)):  # iterate over paths\n",
    "        ax.plot(ts.detach().cpu().numpy(), y.detach().cpu().numpy(), lw=1, alpha=1.0, label=f'Path {i+1}' if i<10 else None)  # plot each path\n",
    "\n",
    "    title = f\"Sampled paths of the Ornstein-Uhlenbeck SDE - parameters : mu = ({model.mu_mean.item():.1f}, {model.mu_std.item():.1f})\" \\\n",
    "        + f\", theta = ({model.theta_mean.item():.1f}, {model.theta_std.item():.1f})\" \\\n",
    "            + f\", sigma = ({model.sigma_mean.item():.1f}, {model.sigma_std.item():.1f})\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"X(t)\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "        \n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_bayesian_ousde_samples(ts, preds, bayesianmodel_ou)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e58782",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_comparison(bayesianmodel_ou)\n",
    "fig.suptitle(\"Comparison of the ground truth and learned Bayesian SDE models before training\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop parameters\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(bayesianmodel_ou.parameters()), \n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "print(f\"Training for {N_EPOCHS} epochs with learning rate {learning_rate}\")\n",
    "\n",
    "losses = []\n",
    "theta_priors = []\n",
    "theta_stds = []\n",
    "mu_priors = []\n",
    "mu_stds = []\n",
    "sigma_priors = []\n",
    "sigma_stds = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # compute SDE and sample N_PATHS\n",
    "    preds = torchsde.sdeint(bayesianmodel_ou, y0, ts, method=\"euler\", dt=1e-3)  # shape (N_POINTS, N_PATHS, 1)\n",
    "    # compute average L2 loss between data paths and sampled paths\n",
    "    mse = (data - preds.permute(1,0,2))**2\n",
    "    loss = mse.mean()\n",
    "    # train\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # record\n",
    "    losses.append(loss.item())\n",
    "    mm, ms = bayesianmodel_ou.mu_mean.item(), bayesianmodel_ou.mu_std.item()\n",
    "    tm, t_s = bayesianmodel_ou.theta_mean.item(), bayesianmodel_ou.theta_std.item()\n",
    "    sm, ss = bayesianmodel_ou.sigma_mean.item(), bayesianmodel_ou.sigma_std.item()\n",
    "    mu_priors.append(mm)\n",
    "    mu_stds.append(ms)\n",
    "    theta_priors.append(tm)\n",
    "    theta_stds.append(t_s)\n",
    "    sigma_priors.append(sm)\n",
    "    sigma_stds.append(ss)\n",
    "    # report out\n",
    "    print(f\"Epoch {epoch+1:<3} - {N_EPOCHS:<3} - loss = {loss.item():.3e} - parametres : theta = ({tm:.3e}, {t_s:.3e}), mu = ({mm:.3e}, {ms:.3e}), sigma = ({sm:.3e}, {ss:.3e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(12,4*4))\n",
    "\n",
    "axs[0, 0].plot(losses, label='losses')\n",
    "\n",
    "# Second subplot - mu\n",
    "axs[1, 0].plot(mu_priors, label='mu mean', color='blue')\n",
    "axs[1, 1].plot(mu_stds, label='mu std', color='green')\n",
    "axs[1, 0].set_ylabel('mu mean', color='blue')\n",
    "axs[1, 1].set_ylabel('mu std', color='green')\n",
    "\n",
    "# Third subplot - theta\n",
    "axs[2, 0].plot(theta_priors, label='theta mean', color='blue')\n",
    "axs[2, 0].set_ylabel('theta mean', color='blue')\n",
    "axs[2, 1].plot(theta_stds, label='theta std', color='green')\n",
    "axs[2, 1].set_ylabel('theta std', color='green')\n",
    "\n",
    "# Fourth subplot - sigma\n",
    "axs[3, 0].plot(sigma_priors, label='sigma mean', color='blue')\n",
    "axs[3, 1].plot(sigma_stds, label='sigma std', color='green')\n",
    "axs[3, 0].set_ylabel('sigma mean', color='blue')\n",
    "axs[3, 1].set_ylabel('sigma std', color='green')\n",
    "\n",
    "# Set common properties\n",
    "for i in range(4):\n",
    "    axs[i, 0].set_xlabel('epoch')\n",
    "    axs[i, 1].set_xlabel('epoch')\n",
    "    axs[i, 0].legend()\n",
    "    if i > 0: axs[i, 1].legend()\n",
    "    axs[i, 0].grid()\n",
    "    axs[i, 1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_comparison(bayesianmodel_ou)\n",
    "fig.suptitle(\"Comparison of the true and learned Bayesian SDE models after training\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e5e80",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Toy 3 : learning an arbitrary SDE with a neural SDE model\n",
    "</div>\n",
    "\n",
    "Here, we sample paths from a non-trivial stochastic process, and learn drift and diffusion with MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237026ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGeneratingSDE(nn.Module):\n",
    "    def __init__(self, sigma=0.5):\n",
    "        \n",
    "        # we keep \"diagonal\" noise type\n",
    "        \n",
    "        # sde_type can be \"ito\" or \"stratonovich\"\n",
    "        # we use \"ito\" here. The available methods for computation are Euler(-Maruyama), Milstein, SRK.\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        self.register_buffer(\"sigma\", torch.tensor(sigma))\n",
    "        \n",
    "    # DRIFT FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the drift at time t and state y\n",
    "    # note : the functions f and g must be able to handle inputs of shape (batch_size, state_size)\n",
    "    # for any batch_size >= 1\n",
    "    def f(self, t, y):\n",
    "        return torch.sin(y)\n",
    "    \n",
    "    # DIFFUSION FUNCTION\n",
    "    # inputs are:\n",
    "    # - t : a tensor of shape (1,) representing the time stamps\n",
    "    # - y : a tensor of shape (batch_size, state_size) representing the current state\n",
    "    # outputs:\n",
    "    # - a tensor of shape (batch_size, state_size) representing the diffusion at time t and state y\n",
    "    # (NB : generally, the output of g is of shape (batch_size, state_size, brownian_size) when noise_type is \"general\")\n",
    "    def g(self,t,y):\n",
    "        return self.sigma * torch.ones_like(y)\n",
    "\n",
    "# datagen_model = DataGeneratingSDE(sigma=0.1).to(device)\n",
    "datagen_model = OUSDE(theta=2.0, mu=0.5, sigma=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ba32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will generate N_PATHS of the SDE, each computed on N_POINTS\n",
    "N_PATHS = 10\n",
    "N_POINTS = 50\n",
    "\n",
    "# time interval\n",
    "t_start = 0.0\n",
    "t_end = 10.0\n",
    "ts = torch.linspace(t_start, t_end, N_POINTS).to(device)\n",
    "\n",
    "# initial condition\n",
    "y_start = 0.50\n",
    "y0s = torch.full((N_PATHS,1), y_start).to(device)\n",
    "\n",
    "# sample paths\n",
    "with torch.no_grad():\n",
    "    ys = torchsde.sdeint(datagen_model, y0s, ts, method='euler', dt=1e-3)\n",
    "    \n",
    "# report out\n",
    "print(f\"Computing {N_PATHS} paths of the SDE, on {N_POINTS} points of the time interval ({t_start},{t_end})\")\n",
    "print(f\"Time tensor : {ts.shape}\")\n",
    "print(f\"Initial condition tensor : {y0s.shape}\")\n",
    "print(f\"Paths samples tensor : {ys.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f110cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_ousde_samples(ts, ys, datagen_model, title='Ground truth SDE samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ys.detach()\n",
    "print(f\"Data : {data.shape} - N_POINTS x N_PATHS x Dx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDE Model to learn\n",
    "class LearningSDE(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        \n",
    "        # create 2 MLPs for the drift and the diffusion\n",
    "        self.drift = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        self.diffusion = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, output_dim),\n",
    "            torch.nn.Softplus()\n",
    "        )\n",
    "        \n",
    "    def f(self, t, y):\n",
    "        return self.drift(y)\n",
    "\n",
    "    def g(self, t, y):\n",
    "        return self.diffusion(y)\n",
    "    \n",
    "learning_model = LearningSDE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd813c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = torchsde.sdeint(learning_model, y0s, ts, method='euler', atol=1e-2, rtol=1e-2, dt=1e-3)\n",
    "    \n",
    "fig, ax = plot_ousde_samples(ts, outputs, learning_model, title='Learning model before training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Drift and Diffusion networks\n",
    "\n",
    "# parameters\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(\n",
    "    params = list(learning_model.parameters()),\n",
    "    lr = learning_rate\n",
    ")\n",
    "# N_EPOCHS = 200\n",
    "losses = []\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "savefilepath = '/home/benjamin/Folders_Python/MVA_Stage/models/latent_sde/learned_sde.pth'\n",
    "\n",
    "# reporting\n",
    "print(f'Starting learning of SDE model on {N_EPOCHS} epochs')\n",
    "\n",
    "# training loop\n",
    "learning_model.train()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # compute sample SDE paths from the model\n",
    "    outputs = torchsde.sdeint(learning_model, y0s, ts, method='euler', atol=1e-5, rtol=1e-5, dt=1e-3) # N_POINTS, N_PATHS, 1\n",
    "    # compute basic L2 loss between the samples and the data\n",
    "    mse = (outputs-data)**2\n",
    "    loss = mse.mean()\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # record and report out\n",
    "    losses.append(loss.item())\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        torch.save(learning_model.state_dict(), savefilepath)\n",
    "        msg = f'saving model' + ' '*10\n",
    "    else:\n",
    "        msg = f'not saving model'\n",
    "    print(f\"Epoch {epoch+1:<3} - {N_EPOCHS:<3} ... loss = {loss.item():.3e} ... best = {best_loss:.3e} ... \" + msg, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore best model\n",
    "learning_model = LearningSDE().to(device)\n",
    "learning_model.load_state_dict(torch.load(savefilepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "ax.plot(losses, label='training loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print predictions vs ground truth by setting same Brownian motion samples for both\n",
    "\n",
    "fig, ax = plot_comparison(learned_model = learning_model, N_SAMPLES=3, gt_model=datagen_model, y_start=y_start)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc453e9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 20px; color: black; font-weight: bold;\">\n",
    "Toy 4 : Learning a SDE with a KL on a ground truth SDE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorSDE(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple O.U. for prior\n",
    "    \"\"\"\n",
    "    def __init__(self, shared_sigma, theta=1.0, mu=1.0):\n",
    "        # we keep \"diagonal\" noise type\n",
    "        \n",
    "        # sde_type can be \"ito\" or \"stratonovich\"\n",
    "        # we use \"ito\" here. The available methods for computation are Euler(-Maruyama), Milstein, SRK.\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        \n",
    "        # parameters\n",
    "        self.theta = torch.tensor(theta, requires_grad=True)\n",
    "        self.mu = torch.tensor(mu, requires_grad=True)\n",
    "        self.sigma = shared_sigma\n",
    "\n",
    "    # DRIFT FUNCTION - same signature as above\n",
    "    def f(self, t, y):\n",
    "        return self.theta * (self.mu - y)\n",
    "    \n",
    "    # DIFFUSION FUNCTION - same signature as above\n",
    "    def g(self, t, y):\n",
    "        return self.sigma**2 * torch.ones_like(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosteriorSDE(nn.Module):\n",
    "    \"\"\"\n",
    "    Posterior with a neural net\n",
    "    \"\"\"\n",
    "    def __init__(self, shared_sigma, n_layers=1, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.noise_type = \"diagonal\"\n",
    "        self.sde_type = \"ito\"\n",
    "        self.register_buffer(\"n_layers\", torch.tensor(n_layers))\n",
    "        self.register_buffer(\"hidden_dim\", torch.tensor(hidden_dim))\n",
    "        self.sigma = shared_sigma\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = 1\n",
    "        for i in range(int(self.n_layers)):\n",
    "            layers.append(torch.nn.Linear(input_dim, self.hidden_dim))\n",
    "            layers.append(torch.nn.Tanh())\n",
    "            input_dim = self.hidden_dim\n",
    "        layers.append(torch.nn.Linear(self.hidden_dim, 1))\n",
    "        self.drift = torch.nn.Sequential(*layers)\n",
    "        \n",
    "    def f(self, t, y):\n",
    "        return self.drift(y)\n",
    "    \n",
    "    def g(self,t ,y):\n",
    "        # same diffusion as prior\n",
    "        return self.sigma**2 * torch.ones_like(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_sigma = nn.Parameter(torch.tensor(1.0))\n",
    "prior = PriorSDE(shared_sigma).to(device)\n",
    "posterior = PosteriorSDE(shared_sigma).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking home made integral approximate calculation\n",
    "\n",
    "# def func(x):\n",
    "#     # return torch.sin(x)\n",
    "#     # return x\n",
    "#     return torch.exp(x)\n",
    "\n",
    "# def approx_int(f,a,b,n=1000):\n",
    "#     xs = torch.linspace(a,b,n)  # (n,1)\n",
    "#     fs = func(xs) # (n, 1)\n",
    "#     app_int = torch.stack( [1/2 * (xs[i+1]-xs[i]) * (fs[i] + fs[i+1]) for i in range(xs.shape[0]-1) ] ) # (n-1, 1)\n",
    "#     return app_int.sum()\n",
    "\n",
    "# a = torch.tensor(0.0)\n",
    "# b = torch.tensor(1.0)\n",
    "# # print(f\"integral = {torch.cos(a) - torch.cos(b)}\")\n",
    "# # print(f\"integral = {1/2*(b**2 - a**2)}\")\n",
    "# print(f\"integral = {torch.exp(b) - torch.exp(a)}\")\n",
    "# print(f\"approx = {approx_int(func,a,b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f373f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POINTS = 50\n",
    "\n",
    "# time interval\n",
    "t_start = 0.0\n",
    "t_end = 10.0\n",
    "ts = torch.linspace(t_start, t_end, N_POINTS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing KL between prior and posterior\n",
    "\n",
    "def kl_path (t, prior, posterior, K=3, epsilon=1e-3, device=device):\n",
    "    \"\"\"\n",
    "    compute the KL between the prior and the posterior\n",
    "    Inputs :\n",
    "    - t (torch.tensor) : time stamps \n",
    "    - prior (nn.Module) : prior with drift and diffusion\n",
    "    - posterior (nn.Module) : posterior with learnable drift and same diffusion as prior\n",
    "    - K (int, defaults to 3) : number of samples to estimate the expectation\n",
    "    Outputs :\n",
    "    - KL (tensor) : KL between the two stochastic processes\n",
    "    \"\"\"\n",
    "    \n",
    "    # sample z from posterior\n",
    "    bm = torchsde.BrownianInterval(t[0], t[-1], size=(K,1), device=device)\n",
    "    bm_increments = torch.stack([bm(t0,t1) for t0,t1 in zip(t[:-1], t[1:])])\n",
    "    bm_queries = torch.cat([torch.zeros(1,K, 1, device=device), torch.cumsum(bm_increments, dim=0)]) # n time_steps x K x Dx=1\n",
    "    \n",
    "    y_start = 0.0\n",
    "    y0s = torch.full((K,1), y_start).to(device)\n",
    "    \n",
    "    # compute paths\n",
    "    ys_prior = torchsde.sdeint(prior, y0s, t, method=\"euler\", dt=1e-3, bm=bm)\n",
    "    ys_posterior = torchsde.sdeint(posterior, y0s, t, method=\"euler\", dt=1e-3, bm=bm)\n",
    "    # compute drifts\n",
    "    ys_prior_drift = prior.f(t, ys_prior)\n",
    "    ys_posterior_drift = posterior.f(t, ys_posterior)\n",
    "    # compute common diffusion\n",
    "    diff = posterior.g(t, ys_posterior)\n",
    "        \n",
    "    # print(f\"prior drift = {ys_prior_drift}\")\n",
    "    # print(f\"posterior drift = {ys_posterior_drift}\")\n",
    "    # print(f\"diff drift = {diff}\")\n",
    "        \n",
    "    # compute KL\n",
    "    \n",
    "    # make sure we do not divide by something too close to zero\n",
    "    diff2 = torch.where(diff.abs().detach() > epsilon, diff, torch.full_like(diff, fill_value=epsilon) * diff.sign())\n",
    "    # print(f\"diff stable: {diff2}\")\n",
    "    \n",
    "    # compute kl\n",
    "    deltas = torch.div(ys_posterior_drift - ys_prior_drift, diff2)**2\n",
    "    # delta_t = torch.tensor( [t[i+1]-t[i]] for in range(t.shape[0]-1) )\n",
    "    approx_int = torch.stack( [1/2 * (t[i+1]-t[i]) * (deltas[i,:,:] + deltas[i+1,:,:]) for i in range(t.shape[0]-1) ] )  # n_steps-1 x K x 1\n",
    "    # print(f\"approx_int {approx_int}\")\n",
    "    kl = torch.sum(approx_int, dim=0).mean()\n",
    "    # print(kl.shape)\n",
    "    \n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = kl_path(ts, prior, posterior)\n",
    "kl.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not pass the shared_sigma parameter twice to the optimizer\n",
    "prior_params = [p for p in prior.parameters() if p is not shared_sigma]\n",
    "posterior_params = [p for p in posterior.parameters() if p is not shared_sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning the prior\n",
    "N_EPOCHS = 100\n",
    "K = 30\n",
    "y_start = 0.0\n",
    "y0s = torch.full((K,1), y_start).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    params = prior_params + posterior_params + [shared_sigma],\n",
    "    lr = 1e-3\n",
    ")\n",
    "epsilon = 1e-6\n",
    "kls = []\n",
    "sigmas = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # sample z from posterior\n",
    "    bm = torchsde.BrownianInterval(ts[0], ts[-1], size=(K,1), device=device)\n",
    "    bm_increments = torch.stack([bm(t0,t1) for t0,t1 in zip(ts[:-1], ts[1:])])\n",
    "    bm_queries = torch.cat([torch.zeros(1,K, 1, device=device), torch.cumsum(bm_increments, dim=0)]) # n time_steps x K x Dx=1\n",
    "    # compute paths, drifts, and common diffusion\n",
    "    ys_prior = torchsde.sdeint(prior, y0s, ts, method=\"euler\", dt=1e-3, bm=bm)\n",
    "    ys_posterior = torchsde.sdeint(posterior, y0s, ts, method=\"euler\", dt=1e-3, bm=bm)\n",
    "    # compute drifts\n",
    "    ys_prior_drift = prior.f(ts, ys_prior)\n",
    "    ys_posterior_drift = posterior.f(ts, ys_posterior)\n",
    "    # compute common diffusion\n",
    "    diff = posterior.g(ts, ys_posterior)\n",
    "    # compute kl\n",
    "    diff2 = torch.where(diff.abs().detach() > epsilon, diff, torch.full_like(diff, fill_value=epsilon) * diff.sign())\n",
    "    deltas = torch.div(ys_posterior_drift - ys_prior_drift, diff2)**2\n",
    "    approx_int = torch.stack( [1/2 * (ts[i+1]-ts[i]) * (deltas[i,:,:] + deltas[i+1,:,:]) for i in range(ts.shape[0]-1) ] )  # n_steps-1 x K x 1\n",
    "    kl = torch.sum(approx_int, dim=0).mean()\n",
    "    # train\n",
    "    optimizer.zero_grad()\n",
    "    kl.backward()\n",
    "    optimizer.step()\n",
    "    # reporting\n",
    "    print(f\"Epoch {epoch+1:<3} : {N_EPOCHS:<3} -- kl = {kl.item():.4e} -- diffusion = {shared_sigma.item():.3e}\")\n",
    "    kls.append(kl.item())    \n",
    "    sigmas.append(posterior.sigma.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bee1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "ax[0].plot(kls)\n",
    "ax[0].grid()\n",
    "ax[0].set_title(f'KL vs Epoch')\n",
    "ax[1].plot(sigmas)\n",
    "ax[1].grid()\n",
    "ax[1].set_title(f'Shared diffusion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot samples of both SDEs\n",
    "N_SAMPLES = 3\n",
    "bm = torchsde.BrownianInterval(t_start, t_end, size=(N_SAMPLES,1), device=device)\n",
    "bm_increments = torch.stack([bm(t0,t1) for t0,t1 in zip(ts[:-1],ts[1:])]) # N_POINTS-1, N_SAMPLES, 1\n",
    "bm_samples = torch.cat( [torch.zeros(1,N_SAMPLES,1,device=device), torch.cumsum(bm_increments,dim=0)]) # N_POINTS, N_SAMPLES_1\n",
    "\n",
    "y_start = 0.0\n",
    "y0s = torch.full((N_SAMPLES,1), y_start).to(device) # N_SAMPLES, 1\n",
    "\n",
    "# compute paths\n",
    "with torch.no_grad():\n",
    "    ys_prior = torchsde.sdeint(prior, y0s, ts, method=\"euler\", dt=1e-3, bm=bm)\n",
    "    ys_posterior = torchsde.sdeint(posterior, y0s, ts, method=\"euler\", dt=1e-3, bm=bm) # N_POINTS, N_SAMPLES, 1\n",
    "    \n",
    "fig, ax = plt.subplots(nrows=1, ncols=N_SAMPLES+2, figsize=(8*N_SAMPLES,6))\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    # plot trajectories\n",
    "    ax[i].plot(ts.detach().cpu().numpy(), ys_prior[:,i,:].detach().cpu().numpy(), lw=2, alpha=1.0, label='Prior', color='blue')\n",
    "    ax[i].plot(ts.detach().cpu().numpy(), ys_posterior[:,i,:].detach().cpu().numpy(), lw=2, alpha=1.0, label='Posterior', color='green')\n",
    "    ax[i].set_title(f\"Sampled paths - Sample {i+1}\")\n",
    "    ax[i].set_xlabel(\"Time\")\n",
    "    ax[i].set_ylabel(\"X(t)\")\n",
    "    ax[i].legend()\n",
    "    ax[i].grid()\n",
    "    \n",
    "\n",
    "# compute gradient fields\n",
    "x_min = torch.tensor(-3.0)\n",
    "x_max = torch.tensor(+3.0)\n",
    "N_XS = 10\n",
    "xs = torch.linspace(x_min, x_max, N_XS).to(device)\n",
    "\n",
    "T, X = torch.meshgrid(ts, xs, indexing='ij')\n",
    "\n",
    "ts_flat = T.flatten().unsqueeze(1) # N_POINTS * N_XS, 1\n",
    "xs_flat = X.flatten().unsqueeze(1) # N_XS * N_POINTS, 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    prior_flows = prior.f(ts_flat, xs_flat) # N_XS * N_POINTS, 1\n",
    "    posterior_flows = posterior.f(ts_flat, xs_flat) # N_XS * N_POINTS, 1\n",
    "    \n",
    "# reshape to grid\n",
    "prior_flows = prior_flows.reshape(T.shape) # N_POINTS, N_XS\n",
    "posterior_flows = posterior_flows.reshape(T.shape) # N_POINTS, N_XS\n",
    "\n",
    "# plot\n",
    "x_points = X.detach().cpu().numpy()\n",
    "t_points = T.detach().cpu().numpy()\n",
    "us_prior = prior_flows.detach().cpu().numpy()\n",
    "us_posterior = posterior_flows.detach().cpu().numpy()\n",
    "\n",
    "ax[N_SAMPLES].quiver(t_points, x_points, np.ones_like(us_prior), us_prior, scale=20, width=0.003, color='blue', alpha=0.7, label='prior drift')\n",
    "ax[N_SAMPLES+1].quiver(t_points, x_points, np.ones_like(us_posterior), us_posterior, scale=20, width=0.003, color='green', alpha=0.7, label='posterior drift')\n",
    "# ax[N_SAMPLES].legend()\n",
    "ax[N_SAMPLES].grid()\n",
    "ax[N_SAMPLES+1].grid()\n",
    "ax[N_SAMPLES].set_title('prior drift')\n",
    "ax[N_SAMPLES+1].set_title('posterior drift')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "torchy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
