{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273af21f",
   "metadata": {},
   "source": [
    "VAEs dynamiques : https://arxiv.org/abs/2008.12595\n",
    "\n",
    "# Training Deep Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f61dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tests.unit_tests import test_brick_1, test_brick_2, test_brick_3, test_brick_4, test_brick_5, test_brick_6\n",
    "# from libs.dkf import DeepKalmanFilter, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eba1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484759d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49afe4e",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b08db",
   "metadata": {},
   "source": [
    "### Structure SSM (Single State Model pour variables latentes + VAE pour observations):\n",
    "\n",
    "- $z_t$ variables latentes forment une chaîne de Markov, transition $p(z_t \\vert z_{t-1})$\n",
    "- $x_t$ observations, modèle $p_{\\theta_x}(x_t \\vert z_t)$\n",
    "- NB : pas de commande/input $u_t$ ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59c3e4",
   "metadata": {},
   "source": [
    "### Deep Kalman Filter :\n",
    "\n",
    "\\begin{align}\n",
    "p_{\\theta_z}(z_t \\vert z_{t-1}) &= \\mathcal{N}(z_t \\vert \\mu_{\\theta_z}(z_{t-1}), \\text{diag}(\\sigma_{\\theta_z}^{2}(z_{t-1}))) \\\\\n",
    "d_z(z_{t-1}) &= [ \\mu_{\\theta_z}(z_{t-1}), \\sigma_{\\theta_z}(z_{t-1}) ] \\\\\n",
    "p_{\\theta_x}(x_t \\vert z_{t}) &= \\mathcal{N}(x_t \\vert \\mu_{\\theta_x}(z_{t}), \\text{diag}(\\sigma_{\\theta_x}^{2}(z_{t}))) \\\\\n",
    "d_x(z_{t}) &= [ \\mu_{\\theta_x}(z_{t}), \\sigma_{\\theta_x}(z_{t}) ] \\\\\n",
    "\\end{align}\n",
    "\n",
    "où $d_x, d_z$ sont des réseaux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118ab0a",
   "metadata": {},
   "source": [
    "### Modèle inférence\n",
    "\n",
    "Le \"true posterior\" s'écrit :\n",
    "\\begin{align}\n",
    "p_{\\theta}(z_{1:T} \\vert x_{1:T}) &= \\prod_{t=1}^T p_{\\theta} (z_t \\vert z_{1:t-1}, x_{1:T} ) \\\\\n",
    "&= \\prod_{t=1}^T p_{\\theta} (z_t \\vert z_{t-1}, x_{t:T} )\n",
    "\\end{align}\n",
    "\n",
    "où la première écriture est l'application de la chain rule, et la deuxième est un résultat de D-séparation (latentes à dépendance Markovienne).\n",
    "\n",
    "On choisit comme approximation du posterior (=encodeur) une formulation calquée sur le vrai posterior :\n",
    "\n",
    "\\begin{align}\n",
    "q_{\\phi}(z_{1:T} \\vert x_{1:T}) &= \\prod_{t=1}^T q_{\\phi} (z_{t} \\vert z_{t-1}, x_{t:T})\n",
    "\\end{align}\n",
    "\n",
    "On voit que l'inférence prend en compte les observations futures $x_{t:T}$ (comme le Kalman smoother par exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ff007",
   "metadata": {},
   "source": [
    "# Implémentation de l'inférence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945b1b3",
   "metadata": {},
   "source": [
    "- **backward RNN** (dans les faits, un LSTM) pour encoder les $x_{t:T}$ par les hidden states $h_t$ : \n",
    "\n",
    "\\begin{align}\n",
    "h_t = \\text{LSTM}(h_{t+1}, x_t)\n",
    "\\end{align}\n",
    "\n",
    "- **combiner** (réseau MLP) pour aggréger $h_t$ et $z_{t-1}\n",
    "\n",
    "\\begin{align}\n",
    "g_t = \\text{Combiner}(h_t, z_{t-1})\n",
    "\\end{align}\n",
    "\n",
    "- **Encoder** (réseau MLP) pour inférer les paramètres du posterior:\n",
    "\n",
    "\\begin{align}\n",
    "e_z(g_t) &= [ \\mu_\\phi(g_t), \\sigma_\\phi(g_t)] \\\\\n",
    "q_\\phi(z_t \\vert g_t) &= \\mathcal{N}(z_t \\vert \\mu_{\\phi}(g_t), \\text{diag}(\\sigma_\\phi^2(g_t)))\n",
    "\\end{align}\n",
    "\n",
    "NB : il existe d'autres formulations du posterior approximé $q_\\phi$, qui peuvent faire intervenir un forward LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d1c6e0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f957c3",
   "metadata": {},
   "source": [
    "Le modèle s'entraîne en maximisant un ELBO, dont la formulation générique se simplifie dans le cas du DKF en :\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta, \\phi; X) &= \\sum_{t=1}^T \\mathbb{E}_{q_\\phi(z_t \\vert x_{1:T})} \\log(p_{\\theta_x}(x_t \\vert z_t)) -\n",
    "\\sum_{t=1}^T \\mathbb{E}_{q_\\phi(z_{t-1} \\vert x_{1:T})} \\text{D}_{\\text{KL}} \\left[ q_\\phi(z_t \\vert z_{-1}, x_{t:T}) \\vert\\vert \n",
    "p_{\\theta_z}(z_t \\vert z_{t-1}) \\right]\n",
    "\\end{align}\n",
    "\n",
    "Les deux termes s'explicitent de la façon suivante (avec $D$ dimension de l'espace des observations) :\n",
    "\n",
    "\\begin{align}\n",
    "p_{\\theta_x}(x_t \\vert z_t) &= \\mathcal{N}(x_t \\vert \\mu_{\\theta_x}(z_t), \\text{diag}(\\sigma_{\\theta_x}^2(z_t))) \\\\\n",
    "\\log{p_{\\theta_x}(x_t \\vert z_t)} &= -\\frac{D}{2} \\log{2\\pi} - \\frac{1}{2}\\log{\\vert \\text{diag}(\\sigma_{\\theta_x}^2(z_t)) \\vert} - \n",
    "\\frac{1}{2} \\left[ (x_t - \\mu_{\\theta_x}(z_t))^T (\\text{diag}(\\sigma_{\\theta_x}^2(z_t)))^{-1} (x_t - \\mu_{\\theta_x}(z_t)) \\right] \\\\\n",
    "&= \\frac{1}{2} \\left( \\sum_{i=1}^D \\log{\\sigma_{\\theta_x}^2(z_t)}\\vert_{i} + (x_t - \\mu_{\\theta_x}(z_t))^T \\text{diag} \\frac{1}{\\sigma_{\\theta_x}^2(z_t)} (x_t - \\mu_{\\theta_x}(z_t)) \\right)\n",
    "\\end{align}\n",
    "\n",
    "Et la KL entre les deux Gaussiennes:\n",
    "\n",
    "\\begin{align}\n",
    "q_\\phi(z_t \\vert z_{t-1}, x_{t:T}) &= \\mathcal{N}(z_t \\vert \\mu_{\\phi}(g_t), \\text{diag}(\\sigma_\\phi^2(g_t))) \\\\\n",
    "p_{\\theta_z}(z_t \\vert z_{t-1}) &= \\mathcal{N}(z_t \\vert \\mu_{\\theta_z}(z_{t-1}), \\text{diag}(\\sigma_{\\theta_z}^{2}(z_{t-1}))) \\\\\n",
    "\\end{align}\n",
    "\n",
    "a une close form (avec $Z$ dimension de l'espace latent):\n",
    "\n",
    "\\begin{align}\n",
    "\\text{D}_{\\text{KL}}(q_\\phi \\vert\\vert p_{\\theta_z}) &= \\frac{1}{2} \\left[ \\text{Tr}(\\text{diag}(\\sigma_{\\theta_z}^{2})^{-1} \\text{diag}(\\sigma_\\phi^2) ) + (\\mu_{\\theta_z} - \\mu_\\phi)^T (\\text{diag}(\\sigma_{\\theta_z}^{2})^{-1}) (\\mu_{\\theta_z} - \\mu_\\phi) +\n",
    "\\log{\\frac{\\vert \\text{diag}(\\sigma_{\\theta_z}^{2})\\vert}{\\vert \\text{diag}(\\sigma_\\phi^2) \\vert} } \\right] \\\\\n",
    "&= \\frac{1}{2}\\left[ \\sum_{i=1}^Z \\log{\\sigma_{\\theta_z}^{2}}\\vert_i - \\sum_{i=1}^Z \\log{\\sigma_{\\phi}^{2}}\\vert_i +\n",
    " (\\mu_{\\theta_z} - \\mu_\\phi)^T \\text{diag}(\\frac{1}{\\sigma_{\\theta_z}^{2}}) (\\mu_{\\theta_z} - \\mu_\\phi) + \\sum_{i=1}^D \\frac{\\sigma_{\\phi}^{2}\\vert_i} {\\sigma_{\\theta_z}^{2}\\vert_i} - Z \n",
    "\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a4e53",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcfdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 1 # Dimension of the observation space\n",
    "Z_DIM = 16 # Dimension of the latent space\n",
    "H_DIM = 16 # Dimension of the hidden state of the LSTM network(s)\n",
    "G_DIM = 8 # Dimension of the output of the combiner\n",
    "INTERMEDIATE_LAYER_DIM = 16 # Dimension of the intermediate layers of the MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951cab4",
   "metadata": {},
   "source": [
    "### Briques de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 1 : backward LSTM -----------------------------\n",
    "\n",
    "class BackwardLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Backward LSTM module.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(BackwardLSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,   # dimension of the observation space\n",
    "            hidden_size,  # dimension of the hidden state of the LSTM network\n",
    "            num_layers=num_layers, # number of layers of the LSTM network\n",
    "            batch_first=False, # using the default PyTorch LSTM implementation, expecting input shape (seq_len, batch, input_size)\n",
    "            bidirectional=False # unidirectional LSTM to start with\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reverse the input sequence - axis 0 is the time axis here\n",
    "        x_reversed = torch.flip(x, [0])\n",
    "        # Pass through LSTM\n",
    "        # using initial hidden state and cell state as zeros\n",
    "        out, _ = self.lstm(x_reversed)\n",
    "        # Reverse the output sequence\n",
    "        out_reversed = torch.flip(out, [0])\n",
    "        # return output shape (seq_len, batch, hidden_size)\n",
    "        \n",
    "        return out_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 2 : combiner -----------------------------\n",
    "#\n",
    "# this combines the latent variable at time t-1\n",
    "# with the hidden state from the backward LSTM at time t,\n",
    "# to compute a tX_DIM = 1 # Dimension of the observation space\n",
    "Z_DIM = 16 # Dimension of the latent space\n",
    "H_DIM = 16 # Dimension of the hidden state of the LSTM network(s)\n",
    "G_DIM = 8 # Dimension of the output of the combiner\n",
    "INTERMEDIATE_LAYER_DIM = 16 # Dimension of the intermediate layers of the MLPsensor g at time t, that will be used\n",
    "# to compute the parameters of the approximate posterior distribution\n",
    "# of the latent variable\n",
    "#\n",
    "\n",
    "class CombinerMLP(nn.Module):\n",
    "    \"\"\"Combiner module. Takes the hidden state of the backward LSTM at time t\n",
    "    and the latent variable at time t-1, to compute a tensor g at time t,\n",
    "    that will be used to compute the parameters of the approximate posterior\n",
    "    distribution of the latent variable.\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, \n",
    "                 hidden_dim=H_DIM, \n",
    "                 output_dim=G_DIM,\n",
    "                 layers_dim = None,  # list of layers dimensions, without the input dimnesion, without the output dimension\n",
    "                 activation = 'tanh',\n",
    "                 inter_dim = INTERMEDIATE_LAYER_DIM,\n",
    "                 ):\n",
    "        super(CombinerMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        self.inter_dim = inter_dim\n",
    "        self.layers_dim = layers_dim\n",
    "        \n",
    "        if self.layers_dim is None:\n",
    "            self.layers_dim = [self.inter_dim]\n",
    "        else:\n",
    "            self.layers_dim = layers_dim\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(self.layers_dim):\n",
    "            if i==0:  #first layer, latent_dim + hidden_dim => layers_dim[0]\n",
    "                layers.append(nn.Linear(latent_dim + hidden_dim, dim))\n",
    "            else:  # all other layers\n",
    "                layers.append(nn.Linear(self.layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "        # last layer : layers_dim[-1] => output_dim\n",
    "        layers.append(nn.Linear(self.layers_dim[-1], output_dim))\n",
    "            \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "            \n",
    "        \n",
    "    def forward(self, h, z):\n",
    "        \"\"\"\n",
    "        Forward pass of the combiner module.\n",
    "        Args:\n",
    "            h: hidden state of the backward LSTM at time t\n",
    "            shape (batch, hidden_dim)\n",
    "            z: latent variable at time t-1\n",
    "            shape (batch, latent_dim)\n",
    "        Returns:\n",
    "            g: tensor g at time t\n",
    "            shape (batch, output_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Concatenate the hidden state and the latent variable on their dimension\n",
    "        x = torch.cat((h, z), dim=-1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        g = self.mlp(x)\n",
    "        \n",
    "        return g     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c62086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 3 : Encoder -----------------------------\n",
    "#\n",
    "# This computes the parameters of the approximate posterior distribution\n",
    "# of the latent vatiable at time t.\n",
    "# The approximate posterior distribution is a Gaussian distribution,\n",
    "# we use a MLP to compute the mean and the log of the variance.\n",
    "#\n",
    "\n",
    "class EncoderMLP(nn.Module):\n",
    "    \"\"\"Encoder module. Computes the parameters of the approximate posterior\n",
    "    distribution of the latent variable at time t. The approximate posterior\n",
    "    distribution is a Gaussian distribution, we use a MLP to compute the mean\n",
    "    and the log of the variance.\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 combiner_dim=G_DIM, # Dimension of the combiner output\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 layers_dim = None, # Dimension of the MLP layers (without inout nor output)\n",
    "                 activation = 'tanh', # Activation function\n",
    "    ):\n",
    "        super(EncoderMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.combiner_dim = combiner_dim\n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        self.inter_dim = inter_dim\n",
    "        \n",
    "        if layers_dim is None:\n",
    "            self.layers_dim = [self.inter_dim]\n",
    "        else:\n",
    "            self.layers_dim = layers_dim\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(self.layers_dim):\n",
    "            if i==0:\n",
    "                layers.append(nn.Linear(combiner_dim, dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "            \n",
    "        # last layer is linear, no activation\n",
    "        layers.append(nn.Linear(self.layers_dim[-1], 2 * latent_dim)) \n",
    "                    \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, g):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder module.\n",
    "        \n",
    "        Args:\n",
    "            g: tensor g at time t\n",
    "            shape (batch, combiner_dim)\n",
    "            \n",
    "        Returns:\n",
    "            mu: mean of the approximate posterior distribution\n",
    "            shape (batch, latent_dim)\n",
    "            logvar: log of the variance of the approximate posterior distribution\n",
    "            shape (batch, latent_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass through MLP\n",
    "        out = self.mlp(g)\n",
    "        \n",
    "        # Split the output into mean and log variance\n",
    "        # each with shape (batch, latent_dim)\n",
    "        mu, logvar = out[:, :self.latent_dim], out[:, self.latent_dim:]\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2609c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 4 : Latent Space Transition -----------------------------       \n",
    "#\n",
    "# This computes the parameters of the transition distribution\n",
    "# of the latent variable at time t. Ie the prior distribution, \n",
    "# before inference.\n",
    "# The transition distribution is a Gaussian distribution,\n",
    "# we use a MLP to compute the mean and the log of the variance.\n",
    "#\n",
    "\n",
    "class LatentSpaceTransitionMLP(nn.Module):\n",
    "    \"\"\"Latent space transition module. Computes the parameters of the\n",
    "    transition distribution of the latent variable at time t. The transition\n",
    "    distribution is a Gaussian distribution, we use a MLP to compute the mean\n",
    "    and the log of the variance.\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 layers_dim = None, # Dimension of the MLP layers\n",
    "                 activation = 'tanh', # Activation function\n",
    "    ):\n",
    "        super(LatentSpaceTransitionMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        self.inter_dim = inter_dim\n",
    "        \n",
    "        if layers_dim is None:\n",
    "            layers_dim = [self.inter_dim]\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(layers_dim):\n",
    "            if i==0:\n",
    "                layers.append(nn.Linear(latent_dim, dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "            \n",
    "        # last layer is linear, no activation\n",
    "        layers.append(nn.Linear(layers_dim[-1], 2 * latent_dim)) \n",
    "                    \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "               \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass of the latent space transition module.\n",
    "        \n",
    "        Args:\n",
    "            z: latent variable at time t-1\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "            \n",
    "        Returns:\n",
    "            mu: mean of the transition distribution\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "            logvar: log of the variance of the transition distribution\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass through MLP\n",
    "        out = self.mlp(z)\n",
    "        \n",
    "        # Split the output into mean and log variance\n",
    "        # each with shape (batch, latent_dim)\n",
    "        mu, logvar = out[:, :, :self.latent_dim], out[:, :, self.latent_dim:]\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- brick 5 : Decoder (ie Observation Model) -----------------------------\n",
    "#\n",
    "# This computes the parameters of the distribution of \n",
    "# the observed variable 'x', given the latent variable 'z'.\n",
    "# The distribution is a Gaussian distribution,\n",
    "# we use a MLP to compute the mean and the log of the variance.\n",
    "#\n",
    "\n",
    "class DecoderMLP(nn.Module):\n",
    "    \"\"\"Decoder module. Computes the parameters of the distribution of the\n",
    "    observed variable 'x', given the latent variable 'z'. The distribution is\n",
    "    a Gaussian distribution, we use a MLP to compute the mean and the log of\n",
    "    the variance.\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 observation_dim=X_DIM, # Dimension of the observation space\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 layers_dim = None, # Dimension of the MLP layers\n",
    "                 activation = 'tanh', # Activation function\n",
    "    ):\n",
    "        super(DecoderMLP, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.observation_dim = observation_dim\n",
    "        self.inter_dim = inter_dim\n",
    "        \n",
    "        if activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function {activation} not supported. Use 'tanh' or 'relu'.\")\n",
    "        \n",
    "        if layers_dim is None:\n",
    "            layers_dim = [self.inter_dim] # one layer per default\n",
    "            \n",
    "        # explicitly define the MLP layers\n",
    "        layers = []\n",
    "        for i, dim in enumerate(layers_dim):\n",
    "            if i==0:\n",
    "                layers.append(nn.Linear(latent_dim, dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(layers_dim[i-1], dim))\n",
    "            layers.append(self.activation_fn)\n",
    "            \n",
    "        # last layer is linear, no activation\n",
    "        layers.append(nn.Linear(layers_dim[-1], 2 * self.observation_dim)) \n",
    "                    \n",
    "        # build the MLP\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder module.\n",
    "        Args:\n",
    "            z: latent variable at time t\n",
    "            shape (seq_len, batch, latent_dim)\n",
    "        Returns:\n",
    "            mu: mean of the distribution of the observed variable\n",
    "            shape (seq_len, batch, observation_dim)\n",
    "            logvar: log of the variance of the distribution of the observed variable\n",
    "            shape (seq_len, batch, observation_dim)\n",
    "        \"\"\"\n",
    "        # Pass through MLP\n",
    "        out = self.mlp(z)\n",
    "        \n",
    "        # Split the output into mean and log variance\n",
    "        # each with shape (batch, observation_dim)\n",
    "        mu, logvar = out[:, :, :self.observation_dim], out[:, :, self.observation_dim:]\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- brick 6 : Sampler with reparameterization trick -----------------------------\n",
    "#\n",
    "# This samples from a normal distribution of given mean and log variance\n",
    "# using the reparameterization trick.\n",
    "\n",
    "class Sampler(nn.Module):\n",
    "    \"\"\"Sampler module. Samples from a normal distribution of given mean and\n",
    "    log variance using the reparameterization trick.\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Sampler, self).__init__()\n",
    "        \n",
    "    def forward(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Forward pass of the sampler module.\n",
    "        \n",
    "        Args:\n",
    "            mu: mean of the distribution\n",
    "            shape (batch, dim)\n",
    "            logvar: log of the variance of the distribution\n",
    "            shape (batch, dim)\n",
    "            \n",
    "        Returns:\n",
    "            v: sampled variables\n",
    "            shape (batch, dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample from a normal distribution using the reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)  # standard deviation\n",
    "        eps = torch.randn_like(std)  # random noise\n",
    "        v = mu + eps * std  # sampled variables\n",
    "        \n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea75e3",
   "metadata": {},
   "source": [
    "### Class DeepKalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ddc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepKalmanFilter(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Kalman Filter (DKF) module. Implements the DKF algorithm.\n",
    "    \n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "        \n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dim=X_DIM, # Dimension of the observation space\n",
    "                 latent_dim=Z_DIM, # Dimension of the latent space\n",
    "                 hidden_dim=H_DIM, # Dimension of the hidden state of the LSTM network\n",
    "                 combiner_dim=G_DIM, # Dimension of the combiner output\n",
    "                 inter_dim=INTERMEDIATE_LAYER_DIM, # Dimension of the intermediate layers\n",
    "                 activation='tanh', # Activation function\n",
    "                 num_layers=1, # Number of layers of the LSTM network\n",
    "                 device='cpu' # Device to use (cpu or cuda)\n",
    "                 ):\n",
    "        super(DeepKalmanFilter, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.combiner_dim = combiner_dim\n",
    "        self.inter_dim = inter_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # define the modules\n",
    "        \n",
    "        self.backward_lstm = BackwardLSTM(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        self.combiner = CombinerMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=self.combiner_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "            inter_dim=self.inter_dim\n",
    "        )\n",
    "        \n",
    "        self.encoder = EncoderMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            combiner_dim=self.combiner_dim,\n",
    "            inter_dim=self.inter_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "        )\n",
    "        \n",
    "        self.latent_space_transition = LatentSpaceTransitionMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            inter_dim=self.inter_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "        )\n",
    "        \n",
    "        self.decoder = DecoderMLP(\n",
    "            latent_dim=self.latent_dim,\n",
    "            observation_dim=self.input_dim,\n",
    "            inter_dim=self.inter_dim,\n",
    "            activation=activation,\n",
    "            layers_dim=None, # list of layers dimensions, without the input dimension, without the output dimension\n",
    "        )\n",
    "        \n",
    "        self.sampler = Sampler()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Deep Kalman Filter. Runs one step inference\n",
    "        \n",
    "        Args:\n",
    "            x: input sequence\n",
    "            shape (seq_len, batch, input_dim)\n",
    "        Returns:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # we assume that the input sequence is of shape (seq_len, batch, input_dim)\n",
    "        seq_len, batch_size, input_dim = x.shape\n",
    "        assert input_dim == self.input_dim, f\"Input dimension {input_dim} does not match the expected dimension {self.input_dim}\"\n",
    "        \n",
    "        # initialize the latent variable at time t=0\n",
    "        # NB : in INRIA code : self.register_buffer\n",
    "        # \"If you have parameters in your model, which should be saved and restored in the state_dict, \n",
    "        # but not trained by the optimizer, you should register them as buffers.\n",
    "        # Buffers won’t be returned in model.parameters(), \n",
    "        # so that the optimizer won’t have a change to update them.#\n",
    "        z0 = torch.zeros(batch_size, self.latent_dim).to(self.device)\n",
    "        # initialize the hidden state of the backward LSTM at time t=0\n",
    "        # NB : they are not used in a first version of this code\n",
    "        h0 = torch.zeros(batch_size, self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(batch_size, self.hidden_dim).to(self.device)\n",
    "        # initialize the outputs\n",
    "        # mu_x_s, logvar_x_s = torch.zeros(seq_len, batch_size, self.input_dim).to(self.device), torch.zeros(seq_len, batch_size, self.input_dim).to(self.device)\n",
    "        mu_z_s, logvar_z_s = torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device), torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device)\n",
    "        # mu_z_transition_s, logvar_z_transition_s = torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device), torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device)\n",
    "        \n",
    "        # run the backward LSTM on the input sequence\n",
    "        # outputs are the hidden states, shape (seq_len, batch, hidden_dim)\n",
    "        h_t_s = self.backward_lstm(x)\n",
    "        \n",
    "        # loop to compute the approximate posterior distribution of the latent variables z_t\n",
    "        # given the observations x_t\n",
    "        # initialize the sequence of sampled latent variables z_t\n",
    "        sampled_z_t_s = torch.zeros(seq_len, batch_size, self.latent_dim).to(self.device)\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # at time t, get z_t-1 and h_t\n",
    "            if t == 0:\n",
    "                sampled_z_t_1 = z0\n",
    "            else:\n",
    "                sampled_z_t_1 = sampled_z_t_s[t-1]\n",
    "            h_t = h_t_s[t]\n",
    "            # compute g_t\n",
    "            g_t = self.combiner(h_t, sampled_z_t_1)\n",
    "            # compute the parameters of the approximate posterior distribution\n",
    "            mu_z, logvar_z = self.encoder(g_t)\n",
    "            mu_z_s[t], logvar_z_s[t] = mu_z, logvar_z\n",
    "            # sample z_t and store it\n",
    "            sampled_z_t = self.sampler(mu_z, logvar_z)\n",
    "            sampled_z_t_s[t] = sampled_z_t\n",
    "            \n",
    "        # compute the parameters of the transition distribution\n",
    "        z_t_lagged = torch.cat([z0.unsqueeze(0), sampled_z_t_s[:-1]])  # lagged z_t\n",
    "        mu_z_transition_s, logvar_z_transition_s = self.latent_space_transition(z_t_lagged)\n",
    "        \n",
    "        # compute the parameters of the observation distribution\n",
    "        mu_x_s, logvar_x_s = self.decoder(sampled_z_t_s)\n",
    "            \n",
    "        # return the outputs\n",
    "        return x, mu_x_s, logvar_x_s, mu_z_s, logvar_z_s, mu_z_transition_s, logvar_z_transition_s\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        msg = f\"DeepKalmanFilter(input_dim={self.input_dim}, latent_dim={self.latent_dim}, hidden_dim={self.hidden_dim}, combiner_dim={self.combiner_dim}, inter_dim={self.inter_dim})\"\n",
    "        msg += f\"\\n{self.backward_lstm}\"\n",
    "        msg += f\"\\n{self.combiner}\"\n",
    "        msg += f\"\\n{self.encoder}\"\n",
    "        msg += f\"\\n{self.latent_space_transition}\"\n",
    "        msg += f\"\\n{self.decoder}\"\n",
    "        msg += f\"\\n{self.sampler}\"\n",
    "        \n",
    "        return msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4654938",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff334c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, x_hat_logvar, z_mean, z_logvar,\n",
    "                  z_transition_mean, z_transition_logvar, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute the total loss for a variational autoencoder (VAE) with a weighted \n",
    "    reconstruction loss and a Kullback-Leibler (KL) divergence term.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : torch.Tensor\n",
    "        Ground truth data with shape (seq_len, batch_size, x_dim).\n",
    "    x_hat : torch.Tensor\n",
    "        Reconstructed data from the VAE with shape\n",
    "        (seq_len, batch_size, x_dim).\n",
    "    x_hat_logvar : torch.Tensor\n",
    "        Log variance of the reconstructed data with shape\n",
    "        (seq_len, batch_size, x_dim).\n",
    "    z_mean : torch.Tensor\n",
    "        Mean of the latent variable distribution with shape \n",
    "        (seq_len, batch_size, x_dim).\n",
    "    z_logvar : torch.Tensor\n",
    "        Log variance of the latent variable distribution with shape \n",
    "        (seq_len, batch_size, x_dim).\n",
    "    z_transition_mean : torch.Tensor\n",
    "        Mean of the transition distribution in the latent space with shape \n",
    "        (seq_len, batch_size, x_dim).\n",
    "    z_transition_logvar : torch.Tensor\n",
    "        Log variance of the transition distribution in the latent space with \n",
    "        shape (seq_len, batch_size, x_dim).\n",
    "    beta : float\n",
    "        Weighting factor for the KL divergence term.\n",
    "    loss_type : str\n",
    "        Type of reconstruction loss to use. Options:\n",
    "        - 'mse': Mean Squared Error (MSE) loss.\n",
    "        - 'weighted_mse': Weighted Mean Squared Error (MSE) loss.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    total_loss : torch.Tensor\n",
    "        The total loss, which is the sum of the reconstruction loss and the \n",
    "        KL divergence loss.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The \"reconstruction loss\" is based on formula above\n",
    "    - The KL divergence loss measures the difference between the latent\n",
    "      variable distribution and the transition distribution in the latent space.\n",
    "    - Both losses are normalized by the sequence length (`seq_len`) and\n",
    "      averaged over the batch.\n",
    "    - The total loss is a combination of the reconstruction loss and the \n",
    "      KL divergence loss, weighted by the `beta` parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    seq_len, batch_size, x_dim = x.shape\n",
    "    \n",
    "    # Compute the reconstruction loss\n",
    "    var = x_hat_logvar.exp()\n",
    "    loss = torch.div((x - x_hat)**2, var)\n",
    "            \n",
    "    loss += x_hat_logvar\n",
    "    loss = loss.sum(dim=2)  # Sum over the x_dim\n",
    "    loss = loss.sum(dim=0)  # Sum over the sequence length\n",
    "    loss = loss.mean()  # Mean over the batch\n",
    "    reconstruction_loss = loss / seq_len\n",
    "           \n",
    "    # Compute the KL divergence loss\n",
    "    kl_loss = (z_transition_logvar - z_logvar +\n",
    "               torch.div((z_logvar.exp() + \n",
    "                         (z_transition_mean - z_mean).pow(2)),\n",
    "                         z_transition_logvar.exp()))\n",
    "    \n",
    "    kl_loss = kl_loss.sum(dim=2)  # Sum over the z_dim\n",
    "    kl_loss = kl_loss.sum(dim=0)  # Sum over the sequence length\n",
    "    kl_loss = kl_loss.mean()  # Mean over the batch\n",
    "    kl_loss = kl_loss / seq_len\n",
    "                \n",
    "    # Combine the reconstruction loss and the KL divergence loss\n",
    "    total_loss = reconstruction_loss + beta * kl_loss\n",
    "    \n",
    "    return reconstruction_loss, kl_loss, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca53cc",
   "metadata": {},
   "source": [
    "# Toy Case : Data Generation for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ce750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps, noise=0.05):\n",
    "    \"\"\"Utility function to generate time series data.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): number of time series to generate (btach size)\n",
    "        n_steps (_type_): length of each time series\n",
    "    \"\"\"\n",
    "    \n",
    "    f1,f2,o1,o2 = np.random.rand(4, batch_size, 1)  # return 4 values for each time series\n",
    "    time = np.linspace(0, 1, n_steps)  # time vector\n",
    "    \n",
    "    series = 0.8 * np.sin((time - o1) * (f1 * 100 + 10)) # first sine wave\n",
    "    series += 0.2 * np.sin((time - o1) * (f1 * 20 + 20)) # second sine wave\n",
    "    series += noise * (np.random.randn(batch_size, n_steps) - 0.5)  # add noise\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64391527",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 500\n",
    "n_series = 10000\n",
    "s = generate_time_series(n_series, n_steps+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cdb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "fig, axs = plt.subplots(N, 1, figsize=(16, 3 * N))\n",
    "for i in range(N):\n",
    "    axs[i].plot(s[i], color='blue', marker=\"x\", linewidth=1)\n",
    "    axs[i].set_title(f\"Time series {i+1}\")\n",
    "    axs[i].set_xlabel(\"Time\")\n",
    "    axs[i].set_ylabel(\"Value\")\n",
    "    axs[i].grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(0.8 * n_series)\n",
    "\n",
    "X_train, y_train = s[:cutoff,:n_steps], s[:cutoff,-1]\n",
    "X_valid, y_valid = s[cutoff:,:n_steps], s[cutoff:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c067913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form datasets, dataloaders, etc\n",
    "\n",
    "BATCH_SIZE = 8192\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X).to(device)\n",
    "        self.y = torch.tensor(y).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "valid_dataset = TimeSeriesDataset(X_valid, y_valid)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea0e76",
   "metadata": {},
   "source": [
    "Baseline metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted value is the last value of the time series\n",
    "\n",
    "y_pred = X_valid[:,-1]\n",
    "print(f\"{np.mean(np.sqrt((y_valid - y_pred) ** 2)):.4f} RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "fig, axs = plt.subplots(N, 1, figsize=(16, 2 * N))\n",
    "for i in range(N):\n",
    "    input = torch.tensor(X_valid[i], device=device)\n",
    "    target = torch.tensor(y_valid[i], device=device)\n",
    "    output = y_pred[i]\n",
    "    target = target.cpu().detach().numpy()\n",
    "    axs[i].plot(input.cpu().detach().numpy(), color='blue', marker=\"x\", linewidth=1, label=\"input\")\n",
    "    axs[i].scatter(n_steps, target, color='red', marker=\"o\", linewidth=1, label=\"ground truth\")\n",
    "    axs[i].scatter(n_steps, output, color='green', marker=\"*\", linewidth=1, label=\"prediction\")\n",
    "    axs[i].set_title(f\"Time series {i+1}\")\n",
    "    axs[i].set_xlabel(\"Time\")\n",
    "    axs[i].set_ylabel(\"Value\")\n",
    "    axs[i].legend()\n",
    "    axs[i].grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54c5d6",
   "metadata": {},
   "source": [
    "### Training DKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = 1\n",
    "latent_dim = 16\n",
    "h_dim = 16\n",
    "combiner_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkf = DeepKalmanFilter(\n",
    "    input_dim = xdim,\n",
    "    latent_dim = latent_dim,\n",
    "    hidden_dim = h_dim,\n",
    "    combiner_dim = combiner_dim,\n",
    "    num_layers = 1,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "print(dkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(dkf.parameters(), lr=5e-4)\n",
    "loss_fn = loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step : perform training for one epoch\n",
    "\n",
    "def train_step(model, optimizer, criterion, train_loader=train_loader, device=device):\n",
    "    ### training step\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    ### loop on training data\n",
    "    rec_loss = 0\n",
    "    kl_loss = 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for input, _ in train_loader:\n",
    "        input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "        input = input.permute(1, 0, 2)  # permute to (seq_len, batch_size, input_dim)\n",
    "\n",
    "        _, mu_x_s, logvar_x_s, mu_z_s, logvar_z_s, mu_z_transition_s, logvar_z_transition_s = model(input)\n",
    "        \n",
    "        rec_loss, kl_loss, total_loss = criterion(input, mu_x_s, logvar_x_s, mu_z_s, logvar_z_s, mu_z_transition_s, logvar_z_transition_s)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "              \n",
    "        rec_loss += rec_loss.item()\n",
    "        kl_loss += kl_loss.item()\n",
    "        epoch_loss += total_loss.item()\n",
    "        \n",
    "    epoch_loss /= len(train_loader)\n",
    "    rec_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    \n",
    "    return rec_loss, kl_loss, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23628e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_losses = []\n",
    "kl_losses = []\n",
    "epoch_losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    # run the training step\n",
    "    rec_loss, kl_loss, epoch_loss = train_step(dkf, optimizer, loss_fn)\n",
    "    # log results\n",
    "    rec_losses.append(rec_loss)\n",
    "    kl_losses.append(kl_loss)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    # Print the losses for this epoch\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"Epoch {i+1:>5}/{num_epochs} - Rec Loss: {rec_loss:.4e}, KL Loss: {kl_loss:.4e}, Total Loss: {epoch_loss:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "axs[0].plot(torch.tensor(rec_losses).cpu().detach(), label='Rec Loss', color='blue')\n",
    "axs[0].set_title('Reconstruction Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "axs[1].plot(torch.tensor(kl_losses).cpu().detach(), label='KL Loss', color='orange')\n",
    "axs[1].set_title('KL Loss')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "axs[2].plot(torch.tensor(epoch_losses).cpu().detach(), label='Total Loss', color='green')\n",
    "axs[2].set_title('Total Loss')\n",
    "axs[2].set_xlabel('Epochs')\n",
    "axs[2].set_ylabel('Loss')\n",
    "axs[2].legend()\n",
    "axs[2].grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7818d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af9115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_step(model, criterion, valid_loader=valid_loader):\n",
    "#     ### testing step\n",
    "#     model.eval()\n",
    "#     epoch_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for input, target in valid_loader:\n",
    "#             input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "#             target = target.to(device).view(-1, 1)\n",
    "#             output = model(input)\n",
    "#             loss = criterion(output, target)\n",
    "#             epoch_loss += loss.item()\n",
    "#     epoch_loss /= len(valid_loader)\n",
    "#     return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecabe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_rnn_model(model, num_epochs=20, batch_size=32):\n",
    "#     print(f\"Start training RNN model for {num_epochs} epochs\")\n",
    "#     for i in range(num_epochs):\n",
    "#         # loop on training data\n",
    "#         train_step_loss = train_step(model, optimizer, criterion)\n",
    "#         train_losses.append(train_step_loss)\n",
    "#         # test step\n",
    "#         test_step_loss = test_step(model, criterion)\n",
    "#         valid_losses.append(test_step_loss)\n",
    "#         print(f\"epoch {i+1}/{num_epochs}, training loss = {train_step_loss:.4e}, validation loss = {test_step_loss:.4e}\")\n",
    "#     print(\"\\nTraining finished\")\n",
    "#     return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = RNNModel(\n",
    "#     input_dim=1,\n",
    "#     output_dim=1,\n",
    "#     hidden_dim=64,\n",
    "#     num_layers=1,\n",
    "#     batch_first=True,\n",
    "#     device=device,\n",
    "#     dtype=dtype\n",
    "# ).to(device)\n",
    "\n",
    "# print(rnn)\n",
    "\n",
    "# lr = 1e-5\n",
    "# optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "# criterion = nn.MSELoss()\n",
    "# train_losses = []\n",
    "# valid_losses = []\n",
    "# num_epochs = 50\n",
    "\n",
    "# train_losses, valid_losses = train_rnn_model(rnn, num_epochs=num_epochs, batch_size=32)\n",
    "\n",
    "# plt.plot(train_losses, label=\"train\")\n",
    "# plt.plot(valid_losses, label=\"valid\")\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ab7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rnn(torch.tensor(X_valid).to(device).unsqueeze(-1))\n",
    "# y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "# print(f\"\\n{np.mean(np.sqrt((y_valid - y_pred) ** 2)):.4f} RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445771ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 5\n",
    "# fig, axs = plt.subplots(N, 1, figsize=(16, 3 * N))\n",
    "# for i in range(N):\n",
    "#     input = torch.tensor(X_valid[i], device=device).unsqueeze(1).unsqueeze(0)\n",
    "#     # print(f\"input has shape {input.shape}\")\n",
    "#     target = torch.tensor(y_valid[i], device=device).view(-1,1)\n",
    "#     # print(f\"target has shape {target.shape}\")\n",
    "#     output = rnn(input)\n",
    "#     output = output.cpu().detach().numpy()\n",
    "#     # print(f\"output has shape {output.shape}\")\n",
    "#     target = target.cpu().detach().numpy()\n",
    "#     axs[i].plot(input.squeeze().cpu().detach().numpy(), color='blue', marker=\"x\", linewidth=1, label=\"input\")\n",
    "#     axs[i].scatter(n_steps, target, color='red', marker=\"o\", linewidth=1, label=\"ground truth\")\n",
    "#     axs[i].scatter(n_steps, output, color='green', marker=\"*\", linewidth=1, label=\"prediction\")\n",
    "#     axs[i].set_title(f\"Time series {i+1}\")\n",
    "#     axs[i].set_xlabel(\"Time\")\n",
    "#     axs[i].set_ylabel(\"Value\")\n",
    "#     axs[i].legend()\n",
    "#     axs[i].grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f258d",
   "metadata": {},
   "source": [
    "### Forecast N steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce510e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_AHEAD = 20\n",
    "# n_series = 50000\n",
    "# cutoff = int(n_series * 0.8)\n",
    "\n",
    "# series = generate_time_series(n_series, n_steps + N_AHEAD)\n",
    "\n",
    "# X_train, y_train = series[:cutoff, :n_steps], series[:cutoff, -N_AHEAD:]\n",
    "# X_test, y_test = series[cutoff:, :n_steps], series[cutoff:, -N_AHEAD:]\n",
    "\n",
    "# print(f\"X_train shape: {X_train.shape}\")\n",
    "# print(f\"y_train shape: {y_train.shape}\")    \n",
    "# print(f\"X_test shape: {X_test.shape}\")\n",
    "# print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "# test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNNModelLookAhead(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, hidden_dim, n_ahead=N_AHEAD, num_layers=1, batch_first=True, device=device, dtype=dtype):\n",
    "#         \"\"\"Constructor for RNN.\n",
    "\n",
    "#         Args:\n",
    "#             input_dim (_type_): dimensionality of the input\n",
    "#             hidden_dim (_type_): dimensionality of the hidden state\n",
    "#             n_ahead (_type_, optional): number of time steps to predict. Defaults to N_AHEAD.\n",
    "#             output_dim (_type_, optional): dimensionality of the output.\n",
    "#             num_layers (int, optional): number of recurrent layers. Defaults to 1.\n",
    "#             batch_first (bool, optional): whether batch dim is first or not. Defaults to True.\n",
    "#                 1. batch_first=True: (batch, seq, feature_dimension)\n",
    "#                 2. batch_first=False: (seq, batch, feature_dimension)\n",
    "#             bidirectional (bool, optional): if True, becomes a bidriectional RNN. Defaults to False.\n",
    "#                 1. bidirectional=True: num_directions=2, (batch, seq, hidden_dim * 2)\n",
    "#                 2. bidirectional=False: num_directions=1, (batch, seq, hidden_dim)\n",
    "#             device (_type_, optional): _description_. Defaults to device.\n",
    "#             dtype (_type_, optional): _description_. Defaults to dtype.\n",
    "#         \"\"\"\n",
    "#         super(RNNModelLookAhead, self).__init__()\n",
    "        \n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.num_layers = num_layers\n",
    "#         self.batch_first = batch_first\n",
    "#         self.bidirectional = False\n",
    "#         self.n_ahead = n_ahead\n",
    "        \n",
    "#         self.rnn = nn.RNN(\n",
    "#             input_size=input_dim,\n",
    "#             hidden_size=hidden_dim,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=batch_first,\n",
    "#             bidirectional=self.bidirectional\n",
    "#         )\n",
    "#         self.fc = nn.Linear(hidden_dim, n_ahead*output_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # first, initialize the hidden state\n",
    "#         h0 = torch.zeros((self.num_layers, x.size(0), self.hidden_dim), requires_grad=True).to(device)\n",
    "#         # INPUT : x : (batch, sequence_length, input_feature_dimension)\n",
    "#         x, _ = self.rnn(x, h0) \n",
    "#         # OUTPUT: N = 10\n",
    "# fig, ax  = plt.subplots(N, 1, figsize=(16, 3 * N))\n",
    "# x_shift = X_test.shape[-1]\n",
    "\n",
    "# for i in range(N):\n",
    "#     input = torch.tensor(X_test[i], device=device).unsqueeze(0).unsqueeze(-1)\n",
    "#     # print(f\"input has shape {input.shape}\")\n",
    "#     target = torch.tensor(y_test[i], device=device).view(-1, N_AHEAD, 1)\n",
    "#     # print(f\"target has shape {target.shape}\")\n",
    "#     output = rnn(input)\n",
    "#     output = output.cpu().detach().numpy()\n",
    "#     # print(f\"output has shape {output.shape}\")\n",
    "#     target = target.cpu().detach().numpy()\n",
    "    \n",
    "#     ax[i].plot(input.squeeze().cpu().detach().numpy(), color='blue', marker=\"x\", linewidth=1, label=\"input\")\n",
    "#     ax[i].plot(np.arange(len(target.squeeze()))+x_shift, target.squeeze(), color='red', marker=\"o\", linewidth=1, label=\"ground truth\")\n",
    "#     ax[i].plot(np.arange(len(target.squeeze()))+x_shift, output.squeeze(), color='green', marker=\"*\", linewidth=1, label=\"prediction\")\n",
    "#     ax[i].set_title(f\"Time series {i+1}\")\n",
    "#     ax[i].set_xlabel(\"Time\")\n",
    "#     ax[i].set_ylabel(\"Value\")\n",
    "#     ax[i].legend()\n",
    "#     ax[i].grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "#         # - output : (batch, sequence_length, hidden_dimension * num_directions)\n",
    "#         # - h_n : (num_layers * num_directions, batch, hidden_dimension) (hidden state for last time step)\n",
    "#         x = self.fc(x[:, -1, :])  # take the last time step\n",
    "#         x = x.view(-1, self.n_ahead, self.output_dim)\n",
    "#         # OUTPUT: x : (batch, output_dimension)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = RNNModelLookAhead(\n",
    "#     input_dim=1,\n",
    "#     output_dim=1,\n",
    "#     n_ahead=N_AHEAD,\n",
    "#     hidden_dim=128,\n",
    "#     num_layers=4,\n",
    "#     batch_first=True,\n",
    "#     device=device,\n",
    "#     dtype=dtype\n",
    "# ).to(device)\n",
    "\n",
    "# print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test dimensions\n",
    "\n",
    "# x = torch.randn(32, 50, 1).to(device)\n",
    "# y = rnn(x)\n",
    "# print(f\"input shape: {x.shape}\")\n",
    "# print(f\"output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-5\n",
    "# optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "# criterion = nn.MSELoss()\n",
    "# num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d13c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = []\n",
    "# valid_losses = []\n",
    "\n",
    "# print(f\"Start training RNN model for {num_epochs} epochs\")\n",
    "\n",
    "# for i in range(num_epochs):\n",
    "#     # loop on training data\n",
    "#     rnn.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     ### loop on training data\n",
    "#     epoch_loss = 0\n",
    "#     for input, target in train_loader:\n",
    "#         input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "#         # print(f\"input has shape {input.shape}\")\n",
    "#         target = target.to(device).view(-1, N_AHEAD, 1)\n",
    "#         # print(f\"target has shape {target.shape}\")\n",
    "#         output = rnn(input)\n",
    "#         # print(F\"output has shape {output.shape}\")\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#     epoch_loss /= len(train_loader) \n",
    "#     train_losses.append(epoch_loss)\n",
    "    \n",
    "#     # test step\n",
    "#     rnn.eval()\n",
    "#     epoch_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for input, target in test_loader:\n",
    "#             input = input.to(device).unsqueeze(-1)  # add a feature dimension\n",
    "#             target = target.to(device).view(-1, N_AHEAD, 1)\n",
    "#             output = rnn(input)\n",
    "#             loss = criterion(output, target)\n",
    "#             epoch_loss += loss.item()\n",
    "#     epoch_loss /= len(test_loader)\n",
    "#     valid_losses.append(epoch_loss)\n",
    "    \n",
    "#     # report out\n",
    "#     print(f\"epoch {i+1:>4}/{num_epochs}, training loss = {train_losses[-1]:.4e}, validation loss = {valid_losses[-1]:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(16, 3))\n",
    "# ax.plot(train_losses, label=\"train\")\n",
    "# ax.plot(valid_losses, label=\"valid\")\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"Epoch\")\n",
    "# ax.set_xticks(np.arange(0, num_epochs+1, 2))\n",
    "# ax.set_xticklabels(np.arange(0, num_epochs+1, 2))\n",
    "# ax.set_ylabel(\"Loss\")\n",
    "# ax.set_title(\"Training and Validation Loss\")\n",
    "# ax.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45923f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rnn(torch.tensor(X_test).to(device).unsqueeze(-1))\n",
    "# y_pred = y_pred.cpu().detach().numpy().squeeze()\n",
    "# # print(y_pred.shape)\n",
    "# # print(y_test.shape)\n",
    "\n",
    "# print(f\"\\n{np.mean(np.sqrt((y_test - y_pred) ** 2)):.4f} RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 10\n",
    "# fig, ax  = plt.subplots(N, 1, figsize=(16, 3 * N))\n",
    "# x_shift = X_test.shape[-1]\n",
    "\n",
    "# for i in range(N):\n",
    "#     input = torch.tensor(X_test[i], device=device).unsqueeze(0).unsqueeze(-1)\n",
    "#     # print(f\"input has shape {input.shape}\")\n",
    "#     target = torch.tensor(y_test[i], device=device).view(-1, N_AHEAD, 1)\n",
    "#     # print(f\"target has shape {target.shape}\")\n",
    "#     output = rnn(input)\n",
    "#     output = output.cpu().detach().numpy()\n",
    "#     # print(f\"output has shape {output.shape}\")\n",
    "#     target = target.cpu().detach().numpy()\n",
    "    \n",
    "#     ax[i].plot(input.squeeze().cpu().detach().numpy(), color='blue', marker=\"x\", linewidth=1, label=\"input\")\n",
    "#     ax[i].plot(np.arange(len(target.squeeze()))+x_shift, target.squeeze(), color='red', marker=\"o\", linewidth=1, label=\"ground truth\")\n",
    "#     ax[i].plot(np.arange(len(target.squeeze()))+x_shift, output.squeeze(), color='green', marker=\"*\", linewidth=1, label=\"prediction\")\n",
    "#     ax[i].set_title(f\"Time series {i+1}\")\n",
    "#     ax[i].set_xlabel(\"Time\")\n",
    "#     ax[i].set_ylabel(\"Value\")\n",
    "#     ax[i].legend()\n",
    "#     ax[i].grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c11c49",
   "metadata": {},
   "source": [
    "### Bidirectionnal RNN\n",
    "\n",
    "https://www.geeksforgeeks.org/bidirectional-recurrent-neural-network/\n",
    "\n",
    "https://www.kaggle.com/code/amansherjadakhan/introduction-to-bidirectional-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c9e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf149d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cdc284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
