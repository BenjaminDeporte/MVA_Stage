\section{DVAE and Stochastic Differential Equations}\label{DVAEs and SDEs}

% ----- DEFINITION D'UN PROCESSUS STOCHASTIQUE

\begin{frame}{Stochastic calculus survival kit - Stochastic process}
    
\begin{definition}
    A \textbf{stochastic process} is defined as:
\begin{align}
    X &= (\Omega, \mathcal{F}, (\mathcal{F}_t)_{t \in T}, (X_t)_{t \in T}, \mathbb{P})
    %(\Omega, \mathcal{F}, (X_t)_{t \in T}, \mathbb{P}) \\
\end{align}
where:
    \begin{itemize}
        \item $\Omega$ is a set (universe of possibles).
        \item $\mathcal{F}$ is a $\sigma$-algebra of parts of $\Omega$
        \item $\mathbb{P}$ is a probability measure on $(\Omega, \mathcal{F})$
        \item $T \subset \mathbb{R}_+$ represents time
        \item $(\mathcal{F}_t)_{t \in T}$ is a \textbf{filtration}, ie an increasing family of sub-$\sigma$-algebras of $\mathcal{F}$ indexed by $t$ : $\forall 0 \leq s \leq t \in T$, $\mathcal{F}_s \subset \mathcal{F}_t \subset \mathcal{F}$.
        \item $(X_t)_{t \in T}$ is a family of RV defined on $(\Omega, \mathcal{F})$ with values in a measurable space $(E, \mathcal{E})$ or more simply $(E, \mathcal{B}(E))$ (set $E$ endowed with its Borelian $\sigma$-algebra).
        \item $(X_t)_{t \in T}$ is assumed \textbf{adapted to the filtration} $(\mathcal{F}_t)_{t \in T}$, meaning $\forall t \in T$, $X_t$ is $\mathcal{F}_t$-measurable
    \end{itemize}
\end{definition}

A filtration $\mathcal{F}_{t\geq 0}$ is often viewed and introduced as the \textit{set of information available at time $t$}. 

\end{frame}


% ---  BROWNIAN MOTION -------------


\begin{frame}{Stochastic calculus survival kit - Brownian motion}
\begin{definition}
A stochastic process $B = \brownian$ with values in $\mathbb{R}^d$ is called \textbf{Brownian motion} iff:
\begin{itemize}
    \item $B_0 = 0$ $\mathbb{P}$-a.s.
    \item $\forall 0 \leq s \leq t$, the random variable $B_t-B_s$ is independent from $\mathcal{F}_t$.
    \item $\forall 0 \leq s \leq t$, $B_t - B_s \sim \mathcal{N}(0,Q(t-s))$
    \item $B$ is continuous \footnote{or more exactly there exists a continuous version of $B$, see \cite{mouvement-brownien-calcul-ito}}
\end{itemize}
where the matrix $Q \in \mathbb{S}^{++}_d$ is called the \textbf{diffusion matrix}.
\end{definition}

% Meaning : the process $B$ starts from 0, its increments are independent from the past, its increments over disjoint time intervals are independent of each other, 
% its increments follow a centered normal law of variance equal to the length of the time interval multiplied by the diffusion matrix.
% NB : some authors choose the define the diffusion matrix (or scalar) outside of the Brownian motion.

A core result is that the quadratic variation of the Brownian motion over an interval $[s,t]$ (equiped
with a subdivison $\pi = \{s=t_0 < t_1 < ...< t_k <... < t_n=t\}$), and defined as the limit when $\vert \pi \vert \rightarrow 0$ 
of $V_{\pi}^{(2)} = \sum_{k=0}^{n-1} \vert f(t_{k+1})-f(t_k)\vert^{2}$, is:

\begin{align}
    &\underset{\vert \pi \vert \rightarrow 0}{\text{lim}}\,\, V_{\pi}^{(2)} = Q(t-s) \,\, \text{in} \,\, L^{2}
\end{align}

% Or, heuristically, 
% \begin{align}
%     \label{dB_square_is_dt}
%     \mathbb{E}(dB_t dB_t^T) = Q dt
% \end{align}
\end{frame}

% ------ STOCHASTIC INTEGRALS ----------------

\begin{frame}{Stochastic calculus survival kit - Stochastic Integrals}
    Ito then proceeds to define \textbf{stochastic integrals}, starting with elementary processes:

\begin{definition}
A stochastic process $X = (X_s)_{s \in [a,b]}$ is called \textbf{elementary} if there exists a subdivision $a = t_0 < t_1 < ... < t_n = b$ of $[a,b]$, such that:
\begin{align*}
    \forall t \in [a,b], \forall \omega \in \Omega, X_t(\omega) = \sum_{i=0}^{n-1} X_i(\omega) \textbf{1}_{[t_i, t_{i+1}[}(t)
\end{align*}
with $\forall i \in \{0,1,..,n-1\}, X_i$ is $\mathcal{F}_{t_i}$-measurable.

This means that, in each interval $[t_i, t_{i+1}[$, $X_t(\omega)$ is independent of $t$ and $X_t(\omega) = X_i(\omega)$.

We define $\mathcal{E}$ (resp. $\mathcal{E}_n, n>0$) the set of all elementary processes on $[a,b]$ (resp. the subset of the $X \in \mathcal{E}$) such that all $X_i$ have a finite moment $\mathbb{E}X_i <\infty$ (resp $\mathbb{E}(\vert X_i\vert^n) < \infty$).
\end{definition}
\end{frame}

\begin{frame}{Stochastic calculus survival kit - Stochastic Integrals 2}
\begin{definition}
Let $X \in \mathcal{E}$, ie
\begin{align*}
X_t(\omega) = \sum_{i=0}^{n-1} X_i(\omega) \textbf{1}_{[t_i, t_{i+1}[}(t)
\end{align*}
\textbf{The stochastic integral of $X$ is the real random variable} :
\begin{align*}
\int_a^b X_t dB_t := \sum_{i=0}^{n-1} X_i (B_{t_{i+1}} - B_{t_{i}})
\end{align*}
\end{definition}

The notion is then extended to other stochastic processes (in spaces of square integrable processes, see the annex).
\end{frame}


\begin{frame}{Stochastic calculus survival kit - Ito's process}
    \begin{definition}
    A process $X = (X_t)_{t \in [0, T]}$ is called a \textbf{Ito's process} if it can be written as:
    \begin{align}
        \label{ito sde definition}
        X_t &= X_0 + \int_{0}^{t}a_s ds + \int_{0}^{t} b_s dB_s \,\,\, \forall t \in [0,T]
    \end{align}
    where $a$ and $b$ are two stochastic processes such that the integrals exist (ie $a \in  \Lambda^1$ and 
    $b \in \Lambda^2$).\\
    Equivalently, we write $X_t$ as the soltuion to the \textbf{Stochastic Differential Equation}:
    \begin{align*}
        dX_t = a_t dt + b_t dB_t
    \end{align*}
    \end{definition}
\end{frame}

%
% ----- ITO FORMULA ------------------
%

\begin{frame}{Stochastic calculus survival kit - Ito's formula}
    
\begin{theorem}
An Itô's process remains an Itô's process when it is transformed by a deterministic function that is "smooth enough".

Let $X$ be a Itô's process on $[0,T]$ : $dX_t = a_tdt + b_t dB_t$.

Let $f : \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}, (x,t) \mapsto f(x,t)$ be 
$\mathcal{C}^{2,1}$ : $\mathcal{C}^2$ in $x$, and $\mathcal{C}^1$ in $t$.

Then $(f(X_t,t))_{t \in [0,T]}$ is also an Itô's process and:
\begin{align}
    d\left( f(X_t,t) \right) = \frac{\partial f}{\partial t}(X_t,t) dt + \frac{\partial f}{\partial x}(X_t,t) dX_t + \frac{1}{2}\frac{\partial^2 f}{\partial x^2}(X_t,t)b_t^2 dt
\end{align}
The last term is Itô's complementary term.\\
In dimension $d > 1$:
\begin{align}
    d\left( f(X_t,t) \right) = \frac{\partial f}{\partial t}(X_t,t) dt + (\nabla f)^T (X_t,t) dX_t + \frac{1}{2}\text{Tr} \left( (\nabla \nabla^T f) dX_t dX_t^T \right)
\end{align}
\end{theorem}
\end{frame}

%
% --- SDE defintion
%

\begin{frame}{Defintion of a Stochastic Differential Equation}
    \begin{definition}
            Let:
    \begin{itemize}
        \item $B$ be a Brownian motion $B_t \in \mathbb{R}^S$, of diffusion matrix $Q$
        \item $F$ be a deterministic function "drift" $F : \mathbb{R}^D \times \mathbb{R}\rightarrow \mathbb{R}^{D \times D}$
        \item $L$ be a deterministic function "dispersion" $L : \mathbb{R}^D \times \mathbb{R}\rightarrow \mathbb{R}^{D \times S}$ 
    \end{itemize}

    The \gls{sde} is:
    \begin{align}
        \label{generic_sde}
        dX_t &= F(X_t,t) dt + L(X_t,t) dB_t \\
        X_{t_0} &= X_0
    \end{align}
    where $X_0$ can be a scalar constant or a random variable.
    A stochastic process $X$ is said to be solution of \ref{generic_sde} if it verifies:
    \begin{align*}
        \forall t, \,\, X_t = X_0 + \int_{0}^{t} F(X_u, u)du + \int_{0}^{t} L(X_u,u) dB_u
    \end{align*}
    \end{definition}
\end{frame}

\begin{frame}{A solution to an SDE is a Markov Process}
\begin{itemize}
    \item As for \gls{ode}, a solution to \ref{generic_sde} might not exist. Also, results similar to Cauchy-Lipschitz 
exist for existence and unicity, based on assumptions on $F$ and $L$. 
    \item Intuitively, we can see that an "infinitesimal increment" of $X_t$ to $X_{t+\Delta_t}$ verifies :
$\Delta {X_t} \approx F(X_t, t) \Delta t + L(X_t,t) dB_t$. But $dB_t$ is a Brownian increment independent of $X_t$,
This suggests that $X_{t+ \Delta_t}$ depends on the past only by $X_t$. 
    \item In other words, $X_t \vert \mathcal{F}_s = X_t \vert X_s$ 
for any $0 < s < t$. ie : \textbf{the solution of a \gls{sde} is a Markov process}. (The formal proof is given in \cite{mouvement-brownien-calcul-ito}.)
\end{itemize}
\end{frame}

\begin{frame}{Transition Kernels}
    \begin{itemize}
        \item Formally, a Markov process is caracterized by its \textbf{transition kernels}. 
        \item That is, for any $s < t$, and any $A \in \mathcal{B}_{\mathbb{R}^{D}}$, a Markov process verifies 
$\mathbb{P}(X_t \in A \vert \mathcal{F}_s) = \mathbb{P}(X_t \in A \vert X_s)$.
        \item the transition kernels of $X$ are the applications $P_{s,t} : \mathbb{R}^{D} \times \mathcal{B}_{\mathbb{R}^{D}} \rightarrow [0,1]$, 
            such that for any $f : \mathbb{R}^{D} \rightarrow \mathbb{R}$ measurable and bounded, we have:
            \begin{align}
                P_{s,t}f(x) = \int_{{\mathbb{R}^{D}}} P_{s,t}(x,dy) f(y)
            \end{align}
        So $P_{s,t}$ actually is the probability measure of starting from $x$ at time $s$, and reach $y \in dy$ at time $t$.
    \end{itemize}
    
When the transition kernels have densities $p(x,t \vert y,s)$ (ie starting from $y$ at time $s$, and
reaching $x$ at time $t$), then a fundamental result is the \textbf{Fokker Plank Kolmogorov} equation 
(also known as forward Kolomogorov) :
\begin{align}
    \label{FPK}
    \frac{\partial p}{\partial y} &= \mathcal{A}^{*}p \\
    \mathcal{A}^{*}(\bullet) &= - \sum_{i=1}^{D} \frac{\partial}{\partial x_i} (F_i(x,t)(\bullet)) + \
        \frac{1}{2} \sum_{i,j=1}^{D} \frac{\partial^{2}}{\partial x_i \partial x_j} (L(x,t)QL(x,t)^{T}\vert_{i,j} (\bullet))
\end{align}
\end{frame}

\begin{frame}{Linear SDE}
    A particularly useful flavor of \gls{sde} is the linear \gls{sde}, that allows some close-form (or at least nicer) solutions:

    \begin{definition}
        With the same notaions as \ref{generic_sde}:

        The linear \gls{sde} is:
        \begin{align}
            \label{linear_sde}
            dX_t &= F(t) X_t dt + L(t) dB_t \\
            X_{t_0} &= X_0 \sim \mathcal{N}(m_0, P_0)
        \end{align}
    \end{definition}
\end{frame}

\begin{frame}{Transition kernels for linear SDEs}
In this case, the transition kernels family can be characterized as:
\begin{align}
    \Psi &: \mathbb{R}^{2 } \rightarrow \mathbb{R}^{D} \\
    \frac{\partial \Psi (\tau, t)}{\partial \tau} &= F(\tau) \Psi(\tau, t) \\
    \frac{\partial \Psi (\tau, t)}{\partial t} &= - \Psi(\tau, t) F(t)  \\
    \Psi(\tau, t) &= \Psi(\tau, s) \Psi(s, t) \,\,\, (\text{Chapman-Kolmogorov}) \\
    \Psi(\tau, t) &= \Psi(t, \tau)^{-1} \\ 
    \Psi(t,t) &= I_d
\end{align}

% \begin{proposition}
\textbf{The solution to a linear SDE \ref{linear_sde} is a Gaussian Process}:
\begin{align}
    \label{solution_linear_sde}
    X_t &= \Psi(t,t_0) X_0 + \int_{t_0}^{t} \Psi(t, \tau) L(\tau) dB_{\tau} \\
    X_{t_0} &= X_0 \sim \mathcal{N}(m_0, P_0)
\end{align}
% \end{proposition}

\end{frame}